var documenterSearchIndex = {"docs":
[{"location":"buffer/#Use-a-buffer","page":"Use a buffer function","title":"Use a buffer","text":"","category":"section"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"We already illustrated the use of Stopping for optimization algorithm, however, in the case where one algorithm/solver is not Stopping-compatible, a buffer solver is required to unify the formalism. We illustrate this situation here with the Ipopt solver.","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"Remark in the buffer function: in case the solver stops with success but the stopping condition is not satisfied, one option is to iterate and reduce the various tolerances.","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"Documentation for Ipopt options can be found here: https://coin-or.github.io/Ipopt/OPTIONS.html#OPTIONS_REF","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"using Ipopt, NLPModels, NLPModelsIpopt, Stopping\n\ninclude(\"../test-stopping/rosenbrock.jl\")\nx0  = 1.5 * ones(6)\nnlp = ADNLPModel(rosenbrock,  x0)","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"The traditional way to solve an optimization problem using NLPModelsIpopt https://github.com/JuliaSmoothOptimizers/NLPModelsIpopt.jl","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"printstyled(\"Oth scenario:\\n\")\n\nstats = ipopt(nlp, print_level = 0, x0 = x0)","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"Use y0 (general), zL (lower bound), zU (upper bound) for initial guess of Lagrange multipliers.","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"@show stats.solution, stats.status","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"Using Stopping, the idea is to create a buffer function","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"function solveIpopt(stp :: NLPStopping)\n\n #xk = solveIpopt(stop.pb, stop.current_state.x)\n stats = ipopt(nlp, print_level     = 0,\n                    tol             = stp.meta.rtol,\n                    x0              = stp.current_state.x,\n                    max_iter        = stp.meta.max_iter,\n                    max_cpu_time    = stp.meta.max_time,\n                    dual_inf_tol    = stp.meta.atol,\n                    constr_viol_tol = stp.meta.atol,\n                    compl_inf_tol   = stp.meta.atol)\n\n #Update the meta boolean with the output message\n if stats.status == :first_order stp.meta.suboptimal      = true end\n if stats.status == :acceptable  stp.meta.suboptimal      = true end\n if stats.status == :infeasible  stp.meta.infeasible      = true end\n if stats.status == :small_step  stp.meta.stalled         = true end\n if stats.status == :max_iter    stp.meta.iteration_limit = true end\n if stats.status == :max_time    stp.meta.tired           = true end\n\n stp.meta.nb_of_stop = stats.iter\n #stats.elapsed_time\n\n x = stats.solution\n\n #Not mandatory, but in case some entries of the State are used to stop\n fill_in!(stp, x)\n\n stop!(stp)\n\n return stp\nend","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"nlp_at_x = NLPAtX(x0)\nstop = NLPStopping(nlp, unconstrained_check, nlp_at_x)","category":"page"},{"location":"buffer/#st-scenario,-we-solve-again-the-problem-with-the-buffer-solver","page":"Use a buffer function","title":"1st scenario, we solve again the problem with the buffer solver","text":"","category":"section"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"printstyled(\"1st scenario:\\n\")\nsolveIpopt(stop)\n@show stop.current_state.x, status(stop)\nnbiter = stop.meta.nb_of_stop","category":"page"},{"location":"buffer/#nd-scenario:-we-check-that-we-control-the-maximum-iterations.","page":"Use a buffer function","title":"2nd scenario: we check that we control the maximum iterations.","text":"","category":"section"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"printstyled(\"2nd scenario:\\n\")\n#rstate is set as true to allow reinit! modifying the State\nreinit!(stop, rstate = true, x = x0)\nstop.meta.max_iter = max(nbiter-4,1)\n\nsolveIpopt(stop)\n#Final status is :IterationLimit\n@show stop.current_state.x, status(stop)","category":"page"},{"location":"howtostop/#How-to-Stop","page":"How to Stop","title":"How to Stop","text":"","category":"section"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The Stopping structure eases the implementation of algorithms and the stopping criterion. We illustrate here the basic features of Stopping.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"-> the case where a Stopping is a sub-Stopping is treated in the next tutorial.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"using Test, Stopping","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"x0 = ones(2)\npb = nothing","category":"page"},{"location":"howtostop/#I.-Initialize-a-Stopping","page":"How to Stop","title":"I. Initialize a Stopping","text":"","category":"section"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The lazy way to initialize the stopping is to provide an initial point:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"stop1 = GenericStopping(pb, x0, rtol = 1e-1)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The more sophisticated way is to first build a State:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"state1 = GenericState(ones(2))","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"then, use it to create a Stopping:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"stop2 = GenericStopping(pb, state1, rtol = 1e-1)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Both ways give the same result:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test stop1.current_state.x == stop2.current_state.x\n@test stop1.current_state.current_time == stop2.current_state.current_time","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Keywords given in the Stopping creator are forwarded to the StoppingMeta.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test stop1.meta.rtol == 1e-1","category":"page"},{"location":"howtostop/#II.-Check-the-status","page":"How to Stop","title":"II. Check the status","text":"","category":"section"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"To ask the Stopping what is the current situation, we have the status function:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test status(stop1) == :Unknown #nothing happened yet.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The status function check the boolean values in the Meta: unbounded, unboundedpb, tired, stalled, iterationlimit, resources, optimal, infeasible, main_pb, domainerror, suboptimal","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"stop1.meta.unbounded  = true\nstop1.meta.suboptimal = true","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"By default the status function prioritizes a status:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test status(stop1) == :SubOptimal","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"while you can access the list of status by turning the keyword list as true:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test status(stop1, list =true) == [:SubOptimal, :Unbounded]","category":"page"},{"location":"howtostop/#III.-Analyze-the-situation:-start!","page":"How to Stop","title":"III. Analyze the situation: start!","text":"","category":"section"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Two functions are designed to ask Stopping to analyze the current situation mainly described by the State: start!, stop! start! is designed to be used right at the beginning of the algorithm:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"start!(stop1) #we will compare with stop2","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"this call initializes a few entries: a) start_time in the META","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test isnan(stop2.meta.start_time)\n@test !isnan(stop1.meta.start_time)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"b) optimality0 in the META (used to check the relative error)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test stop2.meta.optimality0 == 1.0 #default value was 1.0\n@test stop1.meta.optimality0 == Inf #GenericStopping has no specified measure","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"c) the time measured is also updated in the State (if void)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test stop1.current_state.current_time != nothing","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"d) in the case where optimality0 is NaN, meta.domainerror becomes true","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test stop1.meta.domainerror == false","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"e) the problem would be already solved if optimality0 pass a null_test Since optimality0 is Inf, any value would pass the relative error check:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test Stopping._null_test(stop1, Inf) == true\n@test stop1.meta.optimal == true\n@test :Optimal in status(stop1, list = true)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The Stopping determines the optimality by testing a score at zero. The test at zero is controlled by the function meta.tol_check which takes 3 arguments: atol, rtol, optimality0. By default it check if the score is less than: max(atol, rtol * opt0)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"stop1.meta.tol_check = (atol, rtol, opt0) -> atol\n@test Stopping._null_test(stop1, Inf) == false","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"This can be determined in the initialization of the Stopping","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"stop3 = GenericStopping(pb, state1, tol_check = (atol, rtol, opt0) -> atol)\n@test Stopping._null_test(stop3, Inf) == false","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The function _optimalitycheck providing the score returns Inf by default and must be specialized for specialized Stopping. If State entries have to be specified before the start!, you can use the function updateand_start! instead of a update! and then a start!","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"update_and_start!(stop3, x = zeros(2), current_time = -1.0)\n@test stop3.meta.optimal == false\n@test stop3.current_state.current_time == -1.0\n@test stop3.meta.start_time != nothing\n@test stop3.current_state.x == zeros(2)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Once the iterations begins #stop! is the main function. if needed an update is needed first, we can use updateandstop!","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"OK = stop!(stop3) #update the Stopping and return  a boolean\n@test OK == false #no reason to stop just yet!","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The stop! call check the following:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"meta.domainerror: check if the score is NaN\nmeta.optimal: the score passes the _null_test\nmeta.unbounded: check if state.x is too large\nmeta.unbounded_pb: false by default\nmeta.tired: check if time is exhausted\nmeta.resources: false by default\nmeta.iteration_limit: check the number of iterations\nmeta.stalled: false by default\nmeta.main_pb: false by default -> see Stopping as a subproblem tutorial","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Note that 1 and 2 are also done by start!.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"check unboundedness of x:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test update_and_stop!(stop3, x = (stop3.meta.unbounded_x + 1.0) * x0 )\n@test stop3.meta.unbounded == true","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"check time","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"stop3.meta.start_time = 0.0 #too  force the time limit.\nstop!(stop3)\n@test stop3.meta.tired == true","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Stopping the number of iterations by the number of calls to stop!","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test stop3.meta.nb_of_stop == 3 #We called stop3 3 times already\nstop3.meta.max_iter = 3\nstop!(stop3)\n@test stop3.meta.iteration_limit == true #as stop3.meta.nb_of_stop > 3.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Overall we activated three flags:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test status(stop3, list = true) == [:Unbounded, :IterationLimit, :Tired]","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Once we are done with an algorithm and want to reuse a stopping, we need to reinitialize all the entries.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"reinit!(stop3)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"the status boolean are back to false","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test !stop3.meta.iteration_limit && !stop3.meta.tired && !stop3.meta.unbounded","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"reinitialize also the entries updated by the start!","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test isnan(stop3.meta.start_time) && (stop3.meta.optimality0 == 1.0)\n@test stop3.meta.nb_of_stop == 0 #and the counter of stop","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Note that by default reinit! does not reinitialize the currentstate. This can be done by switching the keyword rstate to true. In this case, keywords are forwarded to the reinit! of currentstate.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"reinit!(stop3, rstate =  true, x = zeros(2))\n@test stop3.current_state.current_time == nothing\n@test stop3.current_state.x == zeros(2)","category":"page"},{"location":"fixed-point/#Example-of-a-fixed-point-algorithm","page":"A fixed point algorithm","title":"Example of a fixed point algorithm","text":"","category":"section"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"Stopping can also be used for fixed point methods Example here concerns the AlternatingDirections Algorithm to find a feasible point in the intersection of 2 convex sets A and B. This algorithm relies on a fixed point argument, hence it stopped if it finds a fixed point.","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"Example: A={ (x,y) | x=y} and B = {(x,y) | y=0} Clearly the unique intersection point is (0,0)","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"Note that in this case the projection on A and the projection on B are trivial","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"Takeaway: the 2nd scenario illustrates a situation where the algorithm stalls as it reached a personal success. (optimalsubpb is true)","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"using LinearAlgebra, NLPModels, Stopping, Test","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"Main algorithm","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"function AlternatingDirections(stp)\n\n xk = stp.current_state.x\n OK = update_and_start!(stp, cx = cons(stp.pb, x0))\n @show OK, xk\n\n while !OK\n\n  #First projection\n  xk1 = 0.5 * (xk[1] + xk[2]) * ones(2)\n  #Second projection\n  xk2 = [xk1[1],0.0]\n\n  #check if we have a fixed point\n  Fix = dot(xk-xk2,xk-xk2)\n  if Fix <= min(eps(Float64),stp.meta.atol) stp.meta.suboptimal = true end\n  #call the stopping\n  OK = update_and_stop!(stp, x = xk2, cx = cons(stp.pb, xk2))\n\n  xk = xk2\n  @show OK, xk\n end\n\n return stp\nend","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"We model the problem using the NLPModels without objective function Formulate the problem with NLPModels","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"c(x) = [x[1] - x[2], x[2]]\nlcon = [0.0, 0.0]\nucon = [0.0, 0.0]\nnlp = ADNLPModel(x->0.0, zeros(2), c=c, lcon=lcon, ucon=ucon)","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"1st scenario: we solve the problem","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"printstyled(\"1st scenario:\\n\")\n#Prepare the Stopping\nx0 = [0.0, 5.0]\nstate = NLPAtX(x0)\n#Recall that for the optimality_check function x is the pb and y is the state\n#Here we take the infinite norm of the residual.\nstop = NLPStopping(nlp, (x,y) -> norm(y.cx,Inf), state)\n\nAlternatingDirections(stop)\n@show status(stop)\n@test status(stop) == :Optimal","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"2nd scenario: the user gives an irrealistic optimality condition","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"printstyled(\"2nd scenario:\\n\")\nreinit!(stop, rstate = true, x = x0)\nstop.optimality_check = (x,y) -> norm(y.cx,Inf)+0.5\n\nAlternatingDirections(stop)\n#In this scenario, the algorithm stops because it attains a fixed point\n#Hence, status is :SubOptimal.\n@show status(stop)\n@test status(stop) == :SubOptimal","category":"page"},{"location":"howtostate/#How-to-State","page":"How to State","title":"How to State","text":"","category":"section"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"The data used through the algorithmic process in the Stopping framework are stored in a State.","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"We illustrate here the GenericState and its features.","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"using Test, Stopping","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"The GenericState contains only two entries:  a Vector x, and a Float current_time","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"state1 = GenericState(ones(2)) #takes a Vector as a mandatory input\nstate2 = GenericState(ones(2), current_time = 1.0)","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"By default if a non-mandatory entry is not specified it is void:","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"@test state1.current_time == nothing\n@test state2.current_time == 1.0","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"The GenericState has two functions: update! and reinit!. update! is used to update entries of the State:","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"update!(state1, current_time = 1.0)\n@test state1.current_time == 1.0","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"Note that the update select the relevant entries:","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"update!(state1, fx = 1.0) #does nothing as there are no fx entry\n@test state1.current_time == 1.0 && state1.x == ones(2)","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"The update! can be done only if the new entry is void or has the same type as the existing one.","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"update!(state1, current_time = 2) #does nothing as it is the wrong type\n@test state1.current_time == 1.0","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"One can force the update even if the type is not the same by turning the keyword convert as true (it is false by default).","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"update!(state1, convert = true, current_time = 2)\n@test state1.current_time == 2","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"Non-required entry in the State can always be set as void without convert.","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"update!(state1, current_time = nothing)\n@test state1.current_time == nothing","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"A shorter way to empty the State is to use the reinit! function. This function is particularly useful, when there are many entries.","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"reinit!(state2)\n@test state2.x == ones(2) && state2.current_time == nothing","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"If one wants to use reinit! with a different value of the mandatory entry:","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"reinit!(state2, zeros(2))\n@test state2.x == zeros(2) && state2.current_time == nothing","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"After reinitializing the State reinit! can update entries passed as keywords. either in the default call:","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"reinit!(state2, current_time = 1.0)\n@test state2.x == zeros(2) && state2.current_time == 1.0","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"or in the one changing x:","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"reinit!(state2, ones(2), current_time = 1.0)\n@test state2.x == ones(2) && state2.current_time == 1.0","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"The State has also a private function guaranteeing there are no NaN.","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"OK = Stopping._domain_check(state1) #function returns a boolean\n@test OK == false #no NaN\n\nupdate!(state1, current_time = NaN)\n@test Stopping._domain_check(state1) == true\n\n@test Stopping._domain_check(state2) == false\nupdate!(state2, x=[NaN, 0.0])\n@test Stopping._domain_check(state2) == true","category":"page"},{"location":"penalty/#Quadratic-penalty-algorithm","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"","category":"section"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"In this test problem we consider a quadratic penalty method. This example features an algorithm with the 3 steps: the penalization - the unconstrained min - the 1d min","category":"page"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"Note that there is no optimization of the evaluations here. The penalization gives an approximation of the gradients, multipliers...","category":"page"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"Note the use of a structure for the algorithmic parameters which is forwarded to all the 3 steps. If a parameter is not mentioned, then the default entry in the algorithm will be taken.","category":"page"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"include(\"uncons.jl\")","category":"page"},{"location":"penalty/#Quadratic-penalty-algorithm-2","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"","category":"section"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"fill_in! used instead of update! (works but usually more costly in evaluations) subproblems are solved via Newton method","category":"page"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"function penalty(stp :: NLPStopping; rho0 = 1.0, rho_min = 1e-10,\n                                     rho_update = 0.5, prms = nothing)\n\n #algorithm's parameters\n rho = rho0\n\n #First call to the stopping\n #Becareful here, some entries must be filled in first.\n fill_in!(stp, stp.current_state.x)\n OK = start!(stp)\n\n #prepare the subproblem stopping:\n sub_nlp_at_x = NLPAtX(stp.current_state.x)\n sub_pb  = ADNLPModel(x -> obj(stp.pb, x)\n                      + 1/rho * norm(max.(cons(stp.pb, x) - stp.pb.meta.ucon, 0.0))^2\n                      + 1/rho * norm(max.(- cons(stp.pb, x) + stp.pb.meta.lcon, 0.0))^2,  x0)\n sub_stp = NLPStopping(sub_pb, unconstrained_check,\n                               sub_nlp_at_x, main_stp = stp)\n\n #main loop\n while !OK\n\n  #solve the subproblem\n  reinit!(sub_stp)\n  sub_stp.meta.atol = min(rho, sub_stp.meta.atol)\n  global_newton(sub_stp, prms)\n\n  #Update all the entries of the State\n  fill_in!(stp, sub_stp.current_state.x)\n\n  #Either stop! is true OR the penalty parameter is too small\n  if rho < rho_min stp.meta.suboptimal = true end\n  OK = stop!(stp)\n\n  @show stp.meta.nb_of_stop, OK, rho\n\n  #update the penalty parameter if necessary\n  if !OK\n   rho = rho * rho_update\n   sub_stp.pb  = ADNLPModel(x -> obj(stp.pb, x)\n                            + 1/rho * norm(max.(cons(stp.pb, x) - stp.pb.meta.ucon, 0.0))^2\n                            + 1/rho * norm(max.(- cons(stp.pb, x) + stp.pb.meta.lcon, 0.0))^2,  x0)\n  end\n end\n\n return stp\nend","category":"page"},{"location":"penalty/#Quadratic-penalty-algorithm:-buffer-function","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm: buffer function","text":"","category":"section"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"function penalty(stp :: NLPStopping, prms)\n\n #extract required values in the prms file\n r0 = :rho0       ∈ fieldnames(typeof(prms)) ? prms.rho0       : 1.0\n rm = :rho_min    ∈ fieldnames(typeof(prms)) ? prms.rho_min    : 1e-10\n ru = :rho_update ∈ fieldnames(typeof(prms)) ? prms.rho_update : 0.5\n\n return penalty(stp, rho0 = r0, rho_min = rm, ru = 0.5, prms = prms)\nend","category":"page"},{"location":"penalty/#Algorithmic-parameters-structure","page":"Quadratic penalty algorithm","title":"Algorithmic parameters structure","text":"","category":"section"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"mutable struct Param\n\n    #parameters for the penalty\n    rho0       :: Float64 #initial value of the penalty parameter\n    rho_min    :: Float64 #smallest possible parameter\n    rho_update :: Float64 #update of the penalty parameter\n\n    #parameters of the unconstrained minimization\n    armijo_prm  :: Float64 #Armijo parameter\n    wolfe_prm   :: Float64 #Wolfe parameter\n    onedsolve   :: Function #1D solver\n    ls_func     :: Function\n\n    #parameters of the 1d minimization\n    back_update :: Float64 #backtracking update\n\n    function Param(;rho0        :: Float64 = 1.0,\n                    rho_min     :: Float64 = sqrt(eps(Float64)),\n                    rho_update  :: Float64 = 0.5,\n                    armijo_prm  :: Float64 = 0.01,\n                    wolfe_prm   :: Float64 = 0.99,\n                    onedsolve   :: Function = backtracking_ls,\n                    ls_func     :: Function = (x,y)-> armijo(x,y, τ₀ = armijo_prm),\n                    back_update :: Float64 = 0.5)\n        return new(rho0, rho_min, rho_update,\n                   armijo_prm, wolfe_prm, onedsolve, ls_func,\n                   back_update)\n    end\nend","category":"page"},{"location":"api/#State","page":"API","title":"State","text":"","category":"section"},{"location":"api/#Types","page":"API","title":"Types","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Stopping.GenericState\nStopping.ListStates\nStopping.NLPAtX\nStopping.LSAtT","category":"page"},{"location":"api/#Stopping.GenericState","page":"API","title":"Stopping.GenericState","text":"Type: GenericState\n\nMethods: update!, reinit!\n\nA generic State to describe the state of a problem at a point x.\n\nTracked data include:\n\nx             : current iterate\nd [opt]       : search direction\nres [opt]     : residual\ncurrent_time  : time\ncurrent_score : score\n\nConstructors:  GenericState(:: T, :: S; d :: T = _init_field(T), res :: T = _init_field(T), current_time :: Float64 = NaN) where {S, T <:AbstractVector}\n\nGenericState(:: T; d :: T = _init_field(T), res :: T = _init_field(T), current_time :: Float64 = NaN, current_score :: Union{T,eltype(T)} = _init_field(eltype(T))) where T <:AbstractVector\n\nNote: \n\nBy default, unknown entries are set using _init_field.\nBy default the type of current_score is eltype(x) and cannot be changed once the State is created.  To have a vectorized current_score of length n, try something like GenericState(x, Array{eltype(x),1}(undef, n)).\n\nExamples:   GenericState(x)     GenericState(x, Array{eltype(x),1}(undef, length(x)))      GenericState(x, current_time = 1.0)      GenericState(x, current_score = 1.0)   \n\nSee also: Stopping, NLPAtX\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.ListStates","page":"API","title":"Stopping.ListStates","text":"Type: list of States\n\nConstructor:\n\nListStates(:: AbstractState)\n\nNote:\n\nIf n != -1, then it stores at most n AbstractState.\nadd additional methods following https://docs.julialang.org/en/v1/base/collections/\nListStates recursively handles sub-list of states as the attribute list is\n\nan array of pair whose first component is a, AbstractState and the second component is a ListStates (or nothing).\n\nExamples: ListStates(state) ListStates(state, n = 2) ListStates(-1) ListStates(-1, [(state1, VoidListStates), (state2, VoidListStates)], 2) ListStates(-1, [(state1, another_list)], 1)\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.NLPAtX","page":"API","title":"Stopping.NLPAtX","text":"Type: NLPAtX\n\nMethods: update!, reinit!\n\nNLPAtX contains the information concerning a nonlinear optimization model at the iterate x.\n\nmin_{x ∈ ℜⁿ} f(x) subject to lcon <= c(x) <= ucon, lvar <= x <= uvar.\n\nTracked data include:\n\nx             : the current iterate\nfx [opt]      : function evaluation at x\ngx [opt]      : gradient evaluation at x\nHx [opt]      : hessian evaluation at x\nmu [opt]      : Lagrange multiplier of the bounds constraints\ncx [opt]      : evaluation of the constraint function at x\nJx [opt]      : jacobian matrix of the constraint function at x\nlambda        : Lagrange multiplier of the constraints\nd [opt]       : search direction\nres [opt]     : residual\ncurrent_time  : time\ncurrent_score : score\nevals [opt]   : number of evaluations of the function\n\n(import the type NLPModels.Counters)\n\nConstructors:  NLPAtX(:: T, :: T, :: S; fx :: eltype(T) = _init_field(eltype(T)), gx :: T = _init_field(T), Hx :: Matrix{eltype(T)} = _init_field(Matrix{eltype(T)}), mu :: T = _init_field(T), cx :: T = _init_field(T), Jx :: Matrix{eltype(T)} = _init_field(Matrix{eltype(T)}), d :: T = _init_field(T), res :: T = _init_field(T), current_time :: Float64 = NaN, evals :: Counters = Counters()) where {S, T <: AbstractVector}\n\nNLPAtX(:: T; fx :: eltype(T) = _init_field(eltype(T)), gx :: T = _init_field(T), Hx :: Matrix{eltype(T)} = _init_field(Matrix{eltype(T)}), mu :: T = _init_field(T), current_time :: Float64 = NaN, current_score :: Union{T,eltype(T)} = _init_field(eltype(T)), evals :: Counters  = Counters()) where {T <: AbstractVector}\n\nNLPAtX(:: T, :: T; fx :: eltype(T) = _init_field(eltype(T)), gx :: T = _init_field(T), Hx :: Matrix{eltype(T)} = _init_field(Matrix{eltype(T)}), mu :: T = _init_field(T), cx :: T = _init_field(T), Jx :: Matrix{eltype(T)} = _init_field(Matrix{eltype(T)}), d :: T = _init_field(T), res :: T = _init_field(T), current_time :: Float64  = NaN, current_score :: Union{T,eltype(T)} = _init_field(eltype(T)), evals :: Counters = Counters()) where T <: AbstractVector\n\nNote:\n\nBy default, unknown entries are set using _init_field (except evals).  \nBy default the type of current_score is eltype(x) and cannot be changed once the State is created.    To have a vectorized current_score of length n, try something like GenericState(x, Array{eltype(x),1}(undef, n)).  \nAll these information (except for x and lambda) are optionnal and need to be update when  required. The update is done through the update! function.  \nx and lambda are mandatory entries. If no constraints lambda = [].  \nThe constructor check the size of the entries.  \n\nSee also: GenericState, update!, update_and_start!, update_and_stop!, reinit!\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.LSAtT","page":"API","title":"Stopping.LSAtT","text":"Type: LSAtT\n\nMethods: update!, reinit!, copy\n\nA structure designed to track line search information from one iteration to another. Given f : ℜⁿ → ℜ, define h(θ) = f(x + θ*d) where x and d are vectors of same dimension and θ is a scalar, more specifically the step size.\n\nTracked data can include:\n\nx             : the current step size\nht [opt]      : h(θ) at the current iteration\ngt [opt]      : h'(θ)\nh₀ [opt]      : h(0)\ng₀ [opt]      : h'(0)\ncurrent_time  :  the time at which the line search algorithm started.\ncurrent_score : the score at which the line search algorithm started.\n\nConstructors:  LSAtT(:: T, :: S; ht :: T = _init_field(T), gt :: T = _init_field(T), h₀ :: T = _init_field(T), g₀ :: T = _init_field(T), current_time :: Float64 = NaN) where {S, T <: Number}\n\nLSAtT(:: T; ht :: T = _init_field(T), gt :: T = _init_field(T), h₀ :: T = _init_field(T), g₀ :: T = _init_field(T), current_time :: Float64 = NaN, current_score :: T = _init_field(T))  where T <: Number\n\nNote: \n\nBy default, unknown entries are set using _init_field.  \nBy default the type of current_score is eltype(x) and cannot be changed once the State is created.  To have a vectorized current_score of length n, try something like GenericState(x, Array{eltype(x),1}(undef, n)).\n\n\n\n\n\n","category":"type"},{"location":"api/#General-Functions","page":"API","title":"General Functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Stopping.update!\nStopping.reinit!\nStopping.copy,\nStopping.compress_state!,\nStopping.copy_compress_state\nStopping.add_to_list!\nStopping.length\nStopping.print","category":"page"},{"location":"api/#Stopping.update!","page":"API","title":"Stopping.update!","text":"update!: generic update function for the State\n\nupdate!(:: AbstractState; convert = false, kwargs...)\n\nThe function compares the kwargs and the entries of the State. If the type of the kwargs is the same as the entry, then it is updated.\n\nSet kargs convert to true to update even incompatible types.\n\nExamples: update!(state1) update!(state1, current_time = 2.0) update!(state1, convert = true, current_time = 2.0)\n\nSee also: GenericState, reinit!, update_and_start!, update_and_stop!\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.reinit!","page":"API","title":"Stopping.reinit!","text":"reinit!: function that set all the entries at _init_field except the mandatory x.\n\nreinit!(:: AbstractState, :: Iterate; kwargs...)\n\nNote: If x is given as a kargs it will be prioritized over the second argument.\n\nExamples: reinit!(state2, zeros(2)) reinit!(state2, zeros(2), current_time = 1.0)\n\nThere is a shorter version of reinit! reusing the x in the state\n\nreinit!(:: AbstractState; kwargs...)\n\nExamples: reinit!(state2) reinit!(state2, current_time = 1.0)\n\n\n\n\n\nreinit!: function that set all the entries at void except the mandatory x\n\nreinit!(:: NLPAtX, x :: AbstractVector, l :: AbstractVector; kwargs...)\n\nreinit!(:: NLPAtX; kwargs...)\n\nNote: if x, lambda or evals are given as keyword arguments they will be prioritized over the existing x, lambda and the default Counters.\n\n\n\n\n\nreinit!: reinitialize the MetaData in the Stopping.\n\nreinit!(:: AbstractStopping; rstate :: Bool = false, kwargs...)\n\nNote:\n\nIf rstate is set as true it reinitializes the current State\n\n(with the kwargs).\n\nIf rlist is set as true the list of states is also reinitialized, either\n\nset as nothing if rstate is true, and a list containing only the current state if rstate is false.\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.add_to_list!","page":"API","title":"Stopping.add_to_list!","text":"add_to_list!: add a State to the list of maximal size n. If a n+1-th State is added, the first one in the list is removed. The given is State is compressed before being added in the list (via State.copy_compress_state).\n\nadd_to_list!(:: AbstractListStates, :: AbstractState; kwargs...)\n\nNote: \n\nkwargs are passed to the compress_state call.\ndoes nothing for VoidListStates\n\nsee also: ListStates, State.compress_state, State.copy_compress_state\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.length","page":"API","title":"Base.length","text":"length: return the number of States in the list.\n\nlength(:: ListStates)\n\nsee also: print, addtolist!, ListStates\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.print","page":"API","title":"Base.print","text":"print: output formatting. return a DataFrame.\n\nprint(:: ListStates; verbose :: Bool = true, print_sym :: Union{Nothing,Array{Symbol,1}})\n\nNote:\n\nset verbose to false to avoid printing.\nif print_sym is an Array of Symbol, only those symbols are printed. Note that\n\nthe returned DataFrame still contains all the columns.\n\nMore information about DataFrame: http://juliadata.github.io/DataFrames.jl\n\nsee also: add_to_list!, length, ListStates\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping","page":"API","title":"Stopping","text":"","category":"section"},{"location":"api/#Types-2","page":"API","title":"Types","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Stopping.GenericStopping\nStopping.NLPStopping\nStopping.LS_Stopping\nStopping.LAStopping\nStopping.LACounters\nStopping.StoppingMeta","category":"page"},{"location":"api/#Stopping.GenericStopping","page":"API","title":"Stopping.GenericStopping","text":"Type: GenericStopping\n\nMethods: start!, stop!, update_and_start!, update_and_stop!, fill_in!, reinit!, status\n\nA generic Stopping to solve instances with respect to some  optimality conditions. Optimality is decided by computing a score, which is then  tested to zero.\n\nTracked data include:\n\npb         : A problem\nstate      : The information relative to the problem, see GenericState\n(opt) meta : Metadata relative to a stopping criterion, see StoppingMeta.\n(opt) main_stp : Stopping of the main loop in case we consider a Stopping                      of a subproblem.                      If not a subproblem, then nothing.\n(opt) listofstates : ListStates designed to store the history of States.\n(opt) stoppinguserstruct : Contains any structure designed by the user.\n\nConstructor: GenericStopping(:: Any, :: AbstractState; meta :: AbstractStoppingMeta = StoppingMeta(), main_stp :: Union{AbstractStopping, Nothing} = nothing, stopping_user_struct :: Any = nothing, kwargs...)\n\nNote: Metadata can be provided by the user or created with the Stopping        constructor via kwargs. If a specific StoppingMeta is given and        kwargs are provided, the kwargs have priority.\n\nExamples:  GenericStopping(pb, GenericState(ones(2)), rtol = 1e-1)\n\nBesides optimality conditions, we consider classical emergency exit:        - domain error        (for instance: NaN in x)        - unbounded problem   (not implemented)        - unbounded x         (x is too large)        - tired problem       (time limit attained)        - resources exhausted (not implemented)        - stalled problem     (not implemented)        - iteration limit     (maximum number of iteration (i.e. nb of stop) attained)        - main_pb limit       (tired or resources of main problem exhausted)\n\nThere is an additional default constructor which creates a Stopping with a default State.\n\nGenericStopping(:: Any, :: Union{Number, AbstractVector}; kwargs...)\n\nNote: Keywords arguments are forwarded to the classical constructor.\n\nExamples:  GenericStopping(pb, x0, rtol = 1e-1)\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.NLPStopping","page":"API","title":"Stopping.NLPStopping","text":"Type: NLPStopping\n\nMethods: start!, stop!, update_and_start!, update_and_stop!, fill_in!, reinit!, status KKT, unconstrained_check, unconstrained2nd_check, optim_check_bounded\n\nSpecialization of GenericStopping. Stopping structure for non-linear programming problems using NLPModels.\n\nAttributes:\n\npb         : an AbstractNLPModel\nstate      : The information relative to the problem, see GenericState\n(opt) meta : Metadata relative to stopping criterion, see StoppingMeta.\n(opt) main_stp : Stopping of the main loop in case we consider a Stopping                         of a subproblem.                         If not a subproblem, then nothing.\n(opt) listofstates : ListStates designed to store the history of States.\n(opt) stoppinguserstruct : Contains any structure designed by the user.\n\nNLPStopping(:: AbstractNLPModel, :: AbstractState; meta :: AbstractStoppingMeta = StoppingMeta(), max_cntrs :: Dict = _init_max_counters(), main_stp :: Union{AbstractStopping, Nothing} = nothing, list :: Union{ListStates, Nothing} = nothing, stopping_user_struct :: Any = nothing, kwargs...)\n\nNote:\n\ndesigned for NLPAtX State. Constructor checks that the State has the\n\nrequired entries.\n\nThere is an additional default constructor creating a Stopping where the State is by default and the  optimality function is the function KKT().\n\nNLPStopping(pb :: AbstractNLPModel; kwargs...)\n\nNote: Kwargs are forwarded to the classical constructor.\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.LS_Stopping","page":"API","title":"Stopping.LS_Stopping","text":"Type: LS_Stopping (specialization of GenericStopping)\n\nMethods: start!, stop!, update_and_start!, update_and_stop!, fill_in!, reinit!, status, armijo, wolfe, armijo_wolfe, shamanskii_stop, goldstein\n\nSpecialization of GenericStopping. LS_Stopping is designed to handle the stopping criterion of line search problems. Let f:R→Rⁿ, then h(t) = f(x+td) where x and d are vectors and t is a scalar. h is such that h:R→R.\n\nStopping structure for 1D non-linear programming problems. Input :\n\npb         : an Any\nstate      : The information relative to the problem, see GenericState\n(opt) meta : Metadata relative to stopping criterion.\n(opt) main_stp : Stopping of the main loop in case we consider a Stopping                         of a subproblem.                         If not a subproblem, then nothing.\n(opt) listofstates : ListStates designed to store the history of States.\n(opt) stoppinguserstruct : Contains any structure designed by the user.\n\nLS_Stopping(:: Any, :: LSAtT; meta :: AbstractStoppingMeta = StoppingMeta(), main_stp :: Union{AbstractStopping, Nothing} = nothing, stopping_user_struct :: Any = nothing, kwargs...)\n\nNote:\n\nThe pb can be a LineModel defined in SolverTools.jl (https://github.com/JuliaSmoothOptimizers/SolverTools.jl)\nIt is possible to define those stopping criterion in a NLPStopping except NLPStopping uses vectors operations. LS_Stopping and it's admissible functions (Armijo and Wolfe are provided with Stopping.jl) uses scalar operations.\noptimality_check(pb, state; kwargs...) -> Float64 is by default armijo For instance, the armijo condition is: h(t)-h(0)-τ₀th'(0) ⩽ 0 therefore armijo(h, hatt) returns the maximum between h(t)-h(0)-τ₀th'(0) and 0.\n\nSee also GenericStopping, NLPStopping, LSAtT\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.LAStopping","page":"API","title":"Stopping.LAStopping","text":"Type: LAStopping\n\nMethods: start!, stop!, update_and_start!, update_and_stop!, fillin!, reinit!, status linear\\system_check, normal_equation_check\n\nSpecialization of GenericStopping. Stopping structure for linear algebra solving either\n\nAx = b\n\nor\n\nmin_x tfrac12Ax - b^2.\n\nAttributes:\n\npb         : a problem using LLSModel (designed for linear least square problem, see https://github.com/JuliaSmoothOptimizers/NLPModels.jl/blob/master/src/lls_model.jl )\nstate      : The information relative to the problem, see GenericState\n(opt) meta : Metadata relative to stopping criterion, see StoppingMeta.\n(opt) main_stp : Stopping of the main loop in case we consider a Stopping                         of a subproblem.                         If not a subproblem, then nothing.\n(opt) listofstates : ListStates designed to store the history of States.\n(opt) stoppinguserstruct : Contains any structure designed by the user.\n\nLAStopping(:: LLSModel, :: AbstractState; meta :: AbstractStoppingMeta = StoppingMeta() main_stp :: Union{AbstractStopping, Nothing} = nothing, stopping_user_struct :: Any = nothing, kwargs...)\n\nNote:\n\nKwargs are forwarded to the classical constructor.\nNot specific State targeted\nState don't necessarily keep track of evals\nEvals are checked only for pb.A being a LinearOperator\nzero_start is true if 0 is the initial guess (not check automatically)\nLLSModel counter follow NLSCounters (see initmaxcountersNLS in NLPStoppingmod.jl)\nBy default, meta.max_cntrs is initialized with an NLSCounters\n\nThere is additional constructors:\n\nLAStopping(:: Union{AbstractLinearOperator, AbstractMatrix}, :: AbstractVector, kwargs...)\n\nLAStopping(:: Union{AbstractLinearOperator, AbstractMatrix}, :: AbstractVector, :: AbstractState, kwargs...)\n\nSee also GenericStopping, NLPStopping, LS_Stopping, linear_system_check, normal_equation_check\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.LACounters","page":"API","title":"Stopping.LACounters","text":"Type: LACounters\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.StoppingMeta","page":"API","title":"Stopping.StoppingMeta","text":"Type: StoppingMeta\n\nMethods: no methods.\n\nAttributes:\n\natol : absolute tolerance.\nrtol : relative tolerance.\noptimality0 : optimality score at the initial guess.\ntol_check : Function of atol, rtol and optimality0 testing a score to zero.\ntolcheckneg : Function of atol, rtol and optimality0 testing a score to zero.\ncheck_pos : pre-allocation for positive tolerance\ncheck_neg : pre-allocation for negative tolerance\nretol : true if tolerances are updated\noptimality_check : a stopping criterion via an admissibility function\nunbounded_threshold : threshold for unboundedness of the problem.\nunbounded_x : threshold for unboundedness of the iterate.\nmax_f :  maximum number of function (and derivatives) evaluations.\nmax_cntrs  : Dict contains the maximum number of evaluations\nmax_eval :  maximum number of function (and derivatives) evaluations.\nmax_iter : threshold on the number of stop! call/number of iteration.\nmax_time : time limit to let the algorithm run.\nnb_of_stop : keep track of the number of stop! call/iteration.\nstart_time : keep track of the time at the beginning.\nfail_sub_pb : status.\nunbounded : status.\nunbounded_pb : status.\ntired : status.\nstalled : status.\niteration_limit : status.\nresources : status.\noptimal : status.\ninfeasible : status.\nmain_pb : status.\ndomainerror : status.\nsuboptimal : status.\nstopbyuser : status\nmetauserstruct :  Any\nusercheckfunc! : Function (AbstractStopping, Bool) -> callback.\n\nStoppingMeta(;atol :: Number = 1.0e-6, rtol :: Number = 1.0e-15, optimality0 :: Number = 1.0, tol_check :: Function = (atol,rtol,opt0) -> max(atol,rtol*opt0), unbounded_threshold :: Number = 1.0e50, unbounded_x :: Number = 1.0e50, max_f :: Int = typemax(Int), max_eval :: Int = 20000, max_iter :: Int = 5000, max_time :: Number = 300.0, start_time :: Float64 = NaN, meta_user_struct :: Any = nothing, kwargs...)\n\nNote:\n\nIt is a mutable struct, therefore we can modify elements of a StoppingMeta.\nThe nb_of_stop is incremented everytime stop! or update_and_stop! is called\nThe optimality0 is modified once at the beginning of the algorithm (start!)\nThe start_time is modified once at the beginning of the algorithm (start!)     if not precised before.\nThe different status: fail_sub_pb, unbounded, unbounded_pb, tired, stalled,     iteration_limit, resources, optimal, main_pb, domainerror, suboptimal, infeasible\nfail_sub_pb, suboptimal, and infeasible are modified by the algorithm.\noptimality_check takes two inputs (AbstractNLPModel, NLPAtX)\n\nand returns a Number or an AbstractVector to be compared to 0.\n\noptimality_check does not necessarily fill in the State.\n\nExamples: StoppingMeta()\n\n\n\n\n\n","category":"type"},{"location":"api/#General-Functions-2","page":"API","title":"General Functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Stopping.start!\nStopping.update_and_start!\nStopping.stop!\nStopping.update_and_stop!\nStopping.reinit!\nStopping.fill_in!\nStopping.status","category":"page"},{"location":"api/#Stopping.start!","page":"API","title":"Stopping.start!","text":"Update the Stopping and return true if we must stop.\n\nstart!(:: AbstractStopping; no_start_opt_check :: Bool = false, kwargs...)\n\nPurpose is to know if there is a need to even perform an optimization algorithm  or if we are at an optimal solution from the beginning.   Set no_start_opt_check to true avoid checking optimality and domain errors.\n\nThe function start! successively calls: _domain_check(stp, x),  _optimality_check!(stp, x), _null_test(stp, x) and   _user_check!(stp, x, true).\n\nNote: - start! initializes stp.meta.start_time (if not done before),  stp.current_state.current_time and stp.meta.optimality0   (if no_start_opt_check is false).           - Keywords argument are passed to the _optimality_check! call.           - Compatible with the StopRemoteControl.   \n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.update_and_start!","page":"API","title":"Stopping.update_and_start!","text":"update_and_start!: update values in the State and initialize the Stopping. Returns the optimality status of the problem as a boolean.\n\nupdate_and_start!(:: AbstractStopping; kwargs...)\n\nNote: Kwargs are forwarded to the update! call.\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.stop!","page":"API","title":"Stopping.stop!","text":"stop!: update the Stopping and return a boolean true if we must stop.\n\nstop!(:: AbstractStopping; kwargs...)\n\nIt serves the same purpose as start! in an algorithm; telling us if we stop the algorithm (because we have reached optimality or we loop infinitely, etc).\n\nThe function stop! successively calls: _domain_check, _optimality_check, _null_test, _unbounded_check!, _tired_check!, _resources_check!, _stalled_check!, _iteration_check!, _main_pb_check!, add_to_list!\n\nNote:\n\nKwargs are sent to the _optimality_check! call.\nIf listofstates != VoidListStates, call add_to_list! to update the list of State.\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.update_and_stop!","page":"API","title":"Stopping.update_and_stop!","text":"update_and_stop!: update the values in the State and return the optimality status of the problem as a boolean.\n\nupdate_and_stop!(stp :: AbstractStopping; kwargs...)\n\nNote: Kwargs are forwarded to the update! call.\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.fill_in!","page":"API","title":"Stopping.fill_in!","text":"fill_in!: fill in the unspecified values of the AbstractState.\n\nfill_in!(:: AbstractStopping, x :: Union{Number, AbstractVector})\n\nNote: NotImplemented for Abstract/Generic-Stopping.\n\n\n\n\n\nfill_in!: (NLPStopping version) a function that fill in the required values in the NLPAtX\n\nfill_in!( :: NLPStopping, :: Iterate; fx :: Iterate = nothing, gx :: Iterate = nothing, Hx :: Iterate = nothing, cx :: Iterate = nothing, Jx :: Iterate = nothing, lambda :: Iterate = nothing, mu :: Iterate = nothing, matrix_info :: Bool = true, kwargs...)\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.status","page":"API","title":"Stopping.status","text":"status: returns the status of the algorithm:\n\nstatus(:: AbstractStopping; list = false)\n\nThe different status are:\n\nOptimal: reached an optimal solution.\nUnbounded: current iterate too large in norm.\nUnboundedPb: unbouned problem.\nStalled: stalled algorithm.\nIterationLimit: too many iterations of the algorithm.\nTimeLimit: time limit.\nEvaluationLimit: too many ressources used,                         i.e. too many functions evaluations.\nResourcesOfMainProblemExhausted: in the case of a substopping, EvaluationLimit or TimeLimit for the main stopping.\nInfeasible: default return value, if nothing is done the problem is              considered feasible.\nStopByUser: stopped by the user.\nDomainError: there is a NaN somewhere.\n\nNote:\n\nSet keyword argument list to true, to get an Array with all the status.\nThe different status correspond to boolean values in the MetaData, see StoppingMeta.\n\n\n\n\n\n","category":"function"},{"location":"api/#Non-linear-admissibility-functions","page":"API","title":"Non-linear admissibility functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Stopping.KKT\nStopping.unconstrained_check\nStopping.unconstrained2nd_check\nStopping.optim_check_bounded","category":"page"},{"location":"api/#Stopping.KKT","page":"API","title":"Stopping.KKT","text":"KKT: verifies the KKT conditions\n\nKKT( :: AbstractNLPModel, :: NLPAtX; pnorm :: Float64 = Inf, kwargs...)\n\nNote: state.gx is mandatory + if bounds state.mu + if constraints state.cx, state.Jx, state.lambda.\n\nSee also unconstrained_check, unconstrained2nd_check, optimcheckbounded\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.unconstrained_check","page":"API","title":"Stopping.unconstrained_check","text":"unconstrained: return the infinite norm of the gradient of the objective function\n\nunconstrained_check( :: AbstractNLPModel, :: NLPAtX; pnorm :: Float64 = Inf, kwargs...)\n\nrequired: state.gx (filled if nothing)\n\nSee also unconstrained2nd_check, optimcheckbounded, KKT\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.unconstrained2nd_check","page":"API","title":"Stopping.unconstrained2nd_check","text":"unconstrained 2nd: check the norm of the gradient and the smallest                    eigenvalue of the hessian.\n\nunconstrained2nd_check( :: AbstractNLPModel, :: NLPAtX; pnorm :: Float64 = Inf, kwargs...)\n\nNote: required are state.gx, state.Hx (filled if nothing).\n\nSee also unconstrained_check, optimcheckbounded, KKT\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.optim_check_bounded","page":"API","title":"Stopping.optim_check_bounded","text":"optim_check_bounded: gradient of the objective function projected\n\noptim_check_bounded( :: AbstractNLPModel, :: NLPAtX; pnorm :: Float64 = Inf, kwargs...)\n\nNote: required is state.gx (filled if nothing)\n\nSee also unconstrained_check, unconstrained2nd_check, KKT\n\n\n\n\n\n","category":"function"},{"location":"api/#Linear-algebra-admissibility-functions","page":"API","title":"Linear algebra admissibility functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Stopping.linear_system_check\nStopping.normal_equation_check","category":"page"},{"location":"api/#Stopping.linear_system_check","page":"API","title":"Stopping.linear_system_check","text":"linear_system_check: return ||Ax-b||_p\n\nlinear_system_check(:: Any, :: AbstractState; pnorm :: Float64 = Inf, kwargs...)\n\nNote:\n\nReturns the p-norm of state.res\nstate.res is filled in if nothing.\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.normal_equation_check","page":"API","title":"Stopping.normal_equation_check","text":"linear_system_check: return ||A'Ax-A'b||_p\n\nlinear_system_check(:: Any, :: AbstractState; pnorm :: Float64 = Inf, kwargs...)\n\nNote: pb must have A and b entries\n\n\n\n\n\n","category":"function"},{"location":"api/#Line-search-admissibility-functions","page":"API","title":"Line search admissibility functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Stopping.armijo\nStopping.wolfe\nStopping.armijo_wolfe\nStopping.shamanskii_stop\nStopping.goldstein","category":"page"},{"location":"api/#Stopping.armijo","page":"API","title":"Stopping.armijo","text":"armijo: check if a step size is admissible according to the Armijo criterion.\n\nArmijo criterion: f(x + θd) - f(x) - τ₀ θ ∇f(x+θd)d < 0\n\narmijo(h :: Any, h_at_t :: LSAtT; τ₀ :: Float64 = 0.01, kwargs...)\n\nNote: ht, h₀ and g₀ are required in the LSAtT\n\nSee also wolfe, armijo_wolfe, shamanskii_stop, goldstein\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.wolfe","page":"API","title":"Stopping.wolfe","text":"wolfe: check if a step size is admissible according to the Wolfe criterion.\n\nStrong Wolfe criterion: |∇f(x+θd)| < τ₁||∇f(x)||.\n\nwolfe(h :: Any, h_at_t :: LSAtT; τ₁ :: Float64 = 0.99, kwargs...)\n\nNote: gt and g₀ are required in the LSAtT\n\nSee also armijo, armijo_wolfe, shamanskii_stop, goldstein\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.armijo_wolfe","page":"API","title":"Stopping.armijo_wolfe","text":"armijo_wolfe: check if a step size is admissible according to the Armijo and Wolfe criteria.\n\narmijo_wolfe(h :: Any, h_at_t :: LSAtT; τ₀ :: Float64 = 0.01, τ₁ :: Float64 = 0.99, kwargs...)\n\nNote: ht, h₀, gt and g₀ are required in the LSAtT\n\nSee also armijo, wolfe, shamanskii_stop, goldstein\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.shamanskii_stop","page":"API","title":"Stopping.shamanskii_stop","text":"shamanskii_stop: check if a step size is admissible according to the \"Shamanskii\" criteria. This criteria was proposed in: Lampariello, F., & Sciandrone, M. (2001). Global convergence technique for the Newton method with periodic Hessian evaluation. Journal of optimization theory and applications, 111(2), 341-358.\n\nshamanskii_stop(h :: Any, h_at_t :: LSAtT; γ :: Float64 = 1.0e-09, kwargs...)\n\nNote: * h.d accessible (specific LineModel)       * ht, h₀ are required in the LSAtT\n\nSee also armijo, wolfe, armijo_wolfe, goldstein\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.goldstein","page":"API","title":"Stopping.goldstein","text":"goldstein: check if a step size is admissible according to the Goldstein criteria.\n\ngoldstein(h :: Any, h_at_t :: LSAtT; τ₀ :: Float64 = 0.0001, τ₁ :: Float64 = 0.9999, kwargs...)\n\nNote: ht, h₀ and g₀ are required in the LSAtT\n\nSee also armijo, wolfe, armijo_wolfe, shamanskii_stop\n\n\n\n\n\n","category":"function"},{"location":"uncons/#Unconstrained-solver","page":"Unconstrained optimization algorithm","title":"Unconstrained solver","text":"","category":"section"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"In this test problem, we consider a globalized Newton method. The scenario considers two different stopping criteria to solve the linesearch.","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"i) This example illustrates how the \"structure\" handling the algorithmic parameters can be passed to the solver of the subproblem.","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"ii) This algorithm handles a sub-stopping defined by passing the stopping as a keyword argument. Note that when a stopping is used multiple times, it has to be reinitialized.","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"iii) It also shows how we can reuse the information and avoid unnecessary evals. Here, the objective function of the main problem and sub-problem are the same. Warning: the structure onedoptim however does not allow keeping the gradient of the main problem. This issue can be corrected by using a specialized State.","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"contains the rosenbrock and backtracking_ls functions, and the onedoptim struct:","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"include(\"backls.jl\")","category":"page"},{"location":"uncons/#Newton-method-with-LineSearch","page":"Unconstrained optimization algorithm","title":"Newton method with LineSearch","text":"","category":"section"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"function global_newton(stp       :: NLPStopping,\n                       onedsolve :: Function,\n                       ls_func   :: Function;\n                       prms = nothing)\n\n    #Notations\n    state = stp.current_state; nlp = stp.pb\n    #Initialization\n    xt = state.x; d = zeros(size(xt))\n\n    #First call\n    OK = update_and_start!(stp, x = xt, fx = obj(nlp, xt),\n                                gx = grad(nlp, xt), Hx = hess(nlp, xt))\n\n    #Initialize the sub-Stopping with the main Stopping as keyword argument\n    h = onedoptim(x -> obj(nlp, xt + x * d),\n                  x -> dot(d, grad(nlp, xt + x * d)))\n    lsstp = LS_Stopping(h, ls_func, LSAtT(1.0), main_stp = stp)\n\n    #main loop\n    while !OK\n        #Compute the Newton direction\n        d = (state.Hx + state.Hx' - diagm(0 => diag(state.Hx))) \\ (-state.gx)\n\n        #Prepare the substopping\n        #We reinitialize the stopping before each new use\n        #rstate = true, force a reinialization of the State as well\n        reinit!(lsstp, rstate = true, x = 1.0, g₀=-dot(state.gx,d), h₀=state.fx)\n        lsstp.pb = onedoptim(x -> obj(nlp, xt + x * d),\n                             x -> dot(d, grad(nlp, xt + x * d)))\n\n        #solve subproblem\n        onedsolve(lsstp, prms)\n\n        if status(lsstp) == :Optimal\n         alpha = lsstp.current_state.x\n         #update\n         xt = xt + alpha * d\n         #Since the onedoptim and the nlp have the same objective function,\n         #we save one evaluation.\n         update!(stp.current_state, fx = lsstp.current_state.ht)\n        else\n         stp.meta.fail_sub_pb = true\n        end\n\n        OK = update_and_stop!(stp, x = xt, gx = grad(nlp, xt), Hx = hess(nlp, xt))\n\n    end\n\n    return stp\nend","category":"page"},{"location":"uncons/#Newton-method-with-LineSearch-2","page":"Unconstrained optimization algorithm","title":"Newton method with LineSearch","text":"","category":"section"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"Buffer version","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"function global_newton(stp :: NLPStopping, prms)\n\n lf = :ls_func   ∈ fieldnames(typeof(prms)) ? prms.ls_func : armijo\n os = :onedsolve ∈ fieldnames(typeof(prms)) ? prms.onedsolve : backtracking_ls\n\n return global_newton(stp, os, lf; prms = prms)\nend","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"mutable struct PrmUn\n\n    #parameters of the unconstrained minimization\n    armijo_prm  :: Float64 #Armijo parameter\n    wolfe_prm   :: Float64 #Wolfe parameter\n    onedsolve   :: Function #1D solver\n    ls_func     :: Function\n\n    #parameters of the 1d minimization\n    back_update :: Float64 #backtracking update\n\n    function PrmUn(;armijo_prm  :: Float64 = 0.01,\n                    wolfe_prm   :: Float64 = 0.99,\n                    onedsolve   :: Function = backtracking_ls,\n                    ls_func     :: Function = (x,y)-> armijo(x,y, τ₀ = armijo_prm),\n                    back_update :: Float64 = 0.5)\n        return new(armijo_prm,wolfe_prm,onedsolve,ls_func,back_update)\n    end\nend","category":"page"},{"location":"linear-algebra/#Stopping-for-Linear-Algebra","page":"Solve linear algebra","title":"Stopping for Linear Algebra","text":"","category":"section"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"The Stopping structure eases the implementation of algorithms and the stopping criterion.","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"The following examples illustrate solver for linear algebra: Ax = b with A an m x n matrix.","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"This tutorial illustrates the different step in preparing the resolution of a new problem.","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"we create a LinearAlgebraPRoblem (that stores A, b)\nwe use the GennericState storing x and the current_time\nwe create a LinearAlgebraStopping\nthe optimality function linearsystemcheck!","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"using LinearAlgebra, Stopping, Test","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"m, n = 400, 200 #size of A: m x n\nA    = 100 * rand(m, n)\nxref = 100 * rand(n)\nb    = A * xref\n\n#Our initial guess\nx0 = zeros(n)","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"mutable struct LinearAlgebraProblem\n    A :: Any #matrix type\n    b :: Vector\nend","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"la_pb = LinearAlgebraProblem(A, b)\nla_state = GenericState(xref)\n\n@test norm(la_pb.A * xref - la_pb.b) <= 1e-6","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"mutable struct LinearAlgebraStopping <: AbstractStopping\n\n        # problem\n        pb :: LinearAlgebraProblem\n\n        # stopping criterion\n        optimality_check :: Function\n\n        # Common parameters\n        meta :: AbstractStoppingMeta\n\n        # current state of the problem\n        current_state :: AbstractState\n\n        # Stopping of the main problem, or nothing\n        main_stp :: Union{AbstractStopping, Nothing}\n\n        function LinearAlgebraStopping(pb               :: LinearAlgebraProblem,\n                                       optimality_check :: Function,\n                                       current_state    :: AbstractState; kwargs...)\n         return new(pb, linear_system_check!, StoppingMeta(; kwargs...), la_state, nothing)\n        end\nend\n\nimport Stopping._optimality_check\n\nfunction _optimality_check(stp  :: LinearAlgebraStopping; kwargs...)\n\n optimality = stp.optimality_check(stp.pb, stp.current_state; kwargs...)\n\n return optimality\nend\n","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"function linear_system_check!(pb    :: LinearAlgebraProblem,\n                              state :: AbstractState; kwargs...)\n return norm(pb.A * state.x - pb.b)\nend\n\n@test linear_system_check!(la_pb, la_state) == 0.0\nupdate!(la_state, x = x0)\n@test linear_system_check!(la_pb, la_state) != 0.0\n\nla_stop = LinearAlgebraStopping(la_pb, linear_system_check!, la_state,\n                                max_iter = 150000, rtol = 1e-6)","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"Randomized block Kaczmarz","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"function RandomizedBlockKaczmarz(stp :: AbstractStopping; kwargs...)\n\n    A,b = stp.pb.A, stp.pb.b\n    x0  = stp.current_state.x\n\n    m,n = size(A)\n    xk  = x0\n\n    OK = start!(stp)\n\n    while !OK\n\n     i  = Int(floor(rand() * m)+1) #rand a number between 1 and m\n     Ai = A[i,:]\n     xk  = Ai == 0 ? x0 : x0 - (dot(Ai,x0)-b[i])/dot(Ai,Ai) * Ai\n\n     OK = update_and_stop!(stp, x = xk)\n     x0  = xk\n\n    end\n\n return stp\nend","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"RandomizedBlockKaczmarz(la_stop)\n@test status(la_stop) == :Optimal","category":"page"},{"location":"howtostop-nlp/#How-to-Stop-for-NLPs","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"","category":"section"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"The Stopping structure eases the implementation of algorithms and the stopping criterion.","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"We illustrate here the basic features of NLPStopping, which is a specialized version of the Stopping to the case where: pb is an AbstractNLPModel state shares the structure of the NLPAtX.","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"NLPModels is a package to handle non-linear (constrained) optimization. NLPStopping is following this approach.","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"using Test, NLPModels, Stopping","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"We first create a toy problem","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"f(x) = sum(x.^2)\nx0 = zeros(5)\nnlp = ADNLPModel(f, x0)\nnlp2 = ADNLPModel(f, x0, lvar = zeros(5), uvar = Inf * ones(5))\nnlp_at_x = NLPAtX(x0)\nx1 = ones(5)","category":"page"},{"location":"howtostop-nlp/#)-Initialize-the-NLPStopping.","page":"How to Stop for NLPs","title":"1) Initialize the NLPStopping.","text":"","category":"section"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"The specificity here is that the NLPStopping requires another mandatory input: optimality_check which is the function later used to compute the score. Recall that the score is then tested at 0, to declare optimality. Stopping provides a default KKT function.","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"stop_nlp = NLPStopping(nlp, (x,y) -> KKT(x,y), nlp_at_x)","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"Another approach is to use the lazy way:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"stop_nlp_lazy = NLPStopping(nlp2) #use nlp.meta.x0 as initial point\n@test stop_nlp_lazy.current_state.x == nlp2.meta.x0","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"###2) Fill in Before calling start! and stop! one should fill in current information in the State. -> the optimalitycheck then exploits this knowledge. As seen before, we by hand use updateandstart and updateandstop. Another way is to call the fillin! function:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"fill_in!(stop_nlp, x1, matrix_info = false)\n@test stop_nlp.current_state.x  == x1\n@test stop_nlp.current_state.fx == 5.\n@test stop_nlp.current_state.Hx == nothing","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"Note that since there are no constraints, c(x) and J(x) are not called:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"@test stop_nlp.current_state.Jx == nothing\n@test stop_nlp.current_state.cx == nothing","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"Since there are no bounds on x, the Lagrange multiplier is not updated:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"@test stop_nlp.current_state.mu == nothing","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"would give Hx if matrix_info = true","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"fill_in!(stop_nlp_lazy, x1)\n@test stop_nlp_lazy.current_state.Hx != nothing\n#stop_nlp_lazy.pb has bounds, so mu is a vector of size x\n@test size(x0) == size(stop_nlp_lazy.current_state.mu)","category":"page"},{"location":"howtostop-nlp/#)-Evaluations","page":"How to Stop for NLPs","title":"3) Evaluations","text":"","category":"section"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"Another particularity is that the NLPModels has a counter keeping track of the evaluations of each function. Similarly the NLPStopping has a dictionary keeping all the maximum number of evaluations:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"@test typeof(stop_nlp.max_cntrs) <: Dict\n#For instance the limit in evaluations of objective and gradient:\n@test stop_nlp.max_cntrs[:neval_obj] == 20000\n@test stop_nlp.max_cntrs[:neval_grad] == 20000","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"Limit can be set using _initmaxcounters function:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"stop_nlp.max_cntrs = Stopping._init_max_counters(obj = 3, grad = 0, hess = 0)\n@test stop_nlp.max_cntrs[:neval_obj] == 3\n@test stop_nlp.max_cntrs[:neval_grad] == 0\n\nOK = update_and_stop!(stop_nlp, evals = stop_nlp.pb.counters)\n@test OK == true\n@test stop_nlp.meta.resources == true\n@test status(stop_nlp) == :ResourcesExhausted","category":"page"},{"location":"howtostop-nlp/#)-Unbounded-problem","page":"How to Stop for NLPs","title":"4) Unbounded problem","text":"","category":"section"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"An additional feature of the NLPStopping is to provide an _unboundedproblemcheck whenever \\|c(x)\\| or -f(x) become too large.","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"stop_nlp.meta.unbounded_threshold = - 1.0 #by default 1.0e50\nstop!(stop_nlp)\n@test stop_nlp.meta.unbounded_pb == true\n@test stop_nlp.current_state.fx > stop_nlp.meta.unbounded_threshold\n@test stop_nlp.meta.resources == true #still true as the state has not changed","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"An advanced feature is the possibility to send keywords to optimality_check:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"optimality_fct_test = (x,y;a = 1.0) -> a","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"In this case, the optimality_check function used to compute the score may depend on a parameter (algorithm-dependent for instance)","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"stop_nlp_2 = NLPStopping(nlp, optimality_fct_test, nlp_at_x)\nfill_in!(stop_nlp_2, x0)\n\nOK = stop!(stop_nlp_2, a = 0.0)\n@test OK == true\n@test stop_nlp_2.meta.optimal == true","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"However, note that the same cannot be achieved with updateandstop!:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"reinit!(stop_nlp_2)\nOK = update_and_stop!(stop_nlp_2, a = 0.0)\n@test OK == false","category":"page"},{"location":"backls/#Backtracking-Linesearch","page":"Backtracking linesearch algorithm","title":"Backtracking Linesearch","text":"","category":"section"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"In this test problem, we consider a backtracking algorithm for 1D optimization. The scenario considers three different stopping criterion to solve a specific problem.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"This example illustrates how to use a \"structure\" to handle the algorithmic parameters and unify the input. The function backtrackingls(stp :: LSStopping, prms) serves as a buffer for the real algorithm in the function backtrackingls(stp :: LSStopping; back_update :: Float64 = 0.5, prms = nothing)","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"It also shows that obsolete information in the State (after an update of x) must be removed by the algorithm. Otherwise, the optimality_check function cannot make the difference between valid and invalid entries.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"We create a basic structure to handle 1D optimization.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"We can also use the LineModel available in https://github.com/JuliaSmoothOptimizers/SolverTools.jl","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"mutable struct onedoptim\n    f :: Function\n    g :: Function\nend","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"We specialize three optimality_check functions for 1D optimization to the onedoptim type of problem.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"The default functions do not fill in automatically the necessary entries.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"import Stopping: armijo, wolfe, armijo_wolfe\n\nfunction armijo(h :: onedoptim, h_at_t :: LSAtT; τ₀ :: Float64 = 0.01, kwargs...)\n\n h_at_t.ht = h_at_t.ht == nothing ? h.f(h_at_t.x) : h_at_t.ht\n h_at_t.h₀ = h_at_t.h₀ == nothing ? h.f(0) : h_at_t.h₀\n h_at_t.g₀ = h_at_t.g₀ == nothing ? h.g(0) : h_at_t.g₀\n\n hgoal = h_at_t.ht - h_at_t.h₀ - h_at_t.g₀ * h_at_t.x * τ₀\n\n return max(hgoal, 0.0)\nend\n\nfunction wolfe(h :: onedoptim, h_at_t :: LSAtT; τ₁ :: Float64 = 0.99, kwargs...)\n\n h_at_t.gt = h_at_t.gt == nothing ? h.g(h_at_t.x) : h_at_t.gt\n h_at_t.g₀ = h_at_t.g₀ == nothing ? h.g(0) : h_at_t.g₀\n\n wolfe = τ₁ .* h_at_t.g₀ - abs(h_at_t.gt)\n return max(wolfe, 0.0)\nend\n\nfunction armijo_wolfe(h :: onedoptim, h_at_t :: LSAtT; τ₀ :: Float64 = 0.01, τ₁ :: Float64 = 0.99, kwargs...)\n\n h_at_t.ht = h_at_t.ht == nothing ? h.f(h_at_t.x) : h_at_t.ht\n h_at_t.h₀ = h_at_t.h₀ == nothing ? h.f(0) : h_at_t.h₀\n h_at_t.gt = h_at_t.gt == nothing ? h.g(h_at_t.x) : h_at_t.gt\n h_at_t.g₀ = h_at_t.g₀ == nothing ? h.g(0) : h_at_t.g₀\n\n return max(armijo(h, h_at_t, τ₀ = τ₀),wolfe(h, h_at_t, τ₁ = τ₁), 0.0)\nend","category":"page"},{"location":"backls/#backtracking-LineSearch","page":"Backtracking linesearch algorithm","title":"backtracking LineSearch","text":"","category":"section"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"The problem (stp.pb) is the 1d objective function","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"Requirement: g0 and h0 have been filled in the State.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"function backtracking_ls(stp :: LS_Stopping;\n                         back_update :: Float64 = 0.5,\n                         prms = nothing)\n\n state = stp.current_state; xt = state.x;\n\n #First call to stopping\n OK = start!(stp)\n\n #main loop\n while !OK\n\n  xt = xt * back_update\n\n  #after update the infos in the State are no longer valid (except h₀, g₀)\n  reinit!(state, xt, h₀ = stp.current_state.h₀, g₀ = stp.current_state.g₀)\n\n  #we call the stop!\n  OK = stop!(stp)\n\n end\n\n return stp\nend","category":"page"},{"location":"backls/#Buffer-to-handle-a-structure-containing-the-algorithmic-parameters.","page":"Backtracking linesearch algorithm","title":"Buffer to handle a structure containing the algorithmic parameters.","text":"","category":"section"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"function backtracking_ls(stp :: LS_Stopping, prms)\n\n #extract required values in the prms file\n bu = :back_update   ∈ fieldnames(typeof(prms)) ? prms.back_update : 0.5\n\n return backtracking_ls(stp :: LS_Stopping, back_update = bu; prms = prms)\nend","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"Scenario: optimization of the rosenbrock function at x0 along the opposite of the gradient.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"We also store all the algorithmic parameters in a structure.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"mutable struct ParamLS\n\n    #parameters of the 1d minimization\n    back_update :: Float64 #backtracking update\n\n    function ParamLS(;back_update :: Float64 = 0.1)\n        return new(back_update)\n    end\nend","category":"page"},{"location":"active-set/#Active-set-algorithm","page":"Active set algorithm","title":"Active set algorithm","text":"","category":"section"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"In this test problem we consider an active-set method.","category":"page"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"Note that there is no optimization of the evaluations here.","category":"page"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"Note the use of a structure for the algorithmic parameters which is forwarded to all the 3 steps. If a parameter is not mentioned, then the default entry in the algorithm will be taken.","category":"page"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"include(\"penalty.jl\")","category":"page"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"First, we create a subtype of AbstractNLPModel to represent the unconstrained subproblem we \"solve\" at each iteration of the activeset.","category":"page"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"import NLPModels: obj, grad, hess, hprod\n\nmutable struct ActifNLP <: AbstractNLPModel\n nlp :: AbstractNLPModel\n x0  :: Vector #reference vector\n I   :: Vector #set of active indices\n Ic  :: Vector #set of inactive indices\n meta :: AbstractNLPModelMeta\n counters :: Counters\nend\n\nfunction obj(anlp :: ActifNLP, x :: Vector) t=anlp.x0;t[anlp.Ic]=x; return obj(anlp.nlp, t) end\nfunction grad(anlp :: ActifNLP, x :: Vector) t=anlp.x0;t[anlp.Ic]=x; return grad(anlp.nlp, t)[anlp.Ic] end\nfunction hess(anlp :: ActifNLP, x :: Vector) t=anlp.x0;t[anlp.Ic]=x; return hess(anlp.nlp, t)[anlp.Ic,anlp.Ic] end\nfunction hprod(anlp :: ActifNLP, x :: Vector, v :: Vector, y :: Vector) return hess(anlp, x) * v end","category":"page"},{"location":"active-set/#Active-set-algorithm-for-bound-constraints-optimization","page":"Active set algorithm","title":"Active-set algorithm for bound constraints optimization","text":"","category":"section"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"fill_in! used instead of update! (works but usually more costly in evaluations) subproblems are solved via Newton method","category":"page"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"function activeset(stp :: NLPStopping;\n                   active :: Float64 = stp.meta.tol_check(stp.meta.atol,stp.meta.rtol,stp.meta.optimality0),\n                   prms = nothing)\n\n xt = stp.current_state.x; n = length(xt); all = findall(xt .== xt)\n\n if maximum(vcat(max.(xt  - stp.pb.meta.uvar,0.0),max.(- xt  + stp.pb.meta.lvar,0.0))) > 0.0\n  #OK = true; stp.meta.fail_sub_pb = true\n  #xt is not feasible\n  xt = max.(min.(stp.current_state.x,  stp.pb.meta.uvar),  stp.pb.meta.lvar)\n end\n\n fill_in!(stp, xt)\n OK = start!(stp)\n\n Il = findall(abs.(- xt  + stp.pb.meta.lvar).<= active)\n Iu = findall(abs.(  xt  - stp.pb.meta.uvar).<= active)\n I = union(Il, Iu); Ic = setdiff(all, I)\n nI = max(0, length(xt) - length(Il) - length(Iu)) #lvar_i != uvar_i\n@show xt, I\nwhile !OK\n\n   #prepare the subproblem stopping:\n   subpb = ActifNLP(nlp, xt, I, Ic, NLPModelMeta(nI), Counters())\n   #the subproblem stops if he solved the unconstrained nlp or iterate is infeasible\n   feas(x,y) = maximum(vcat(max.(y.x  - stp.pb.meta.uvar[Ic],0.0),max.(- y.x  + stp.pb.meta.lvar[Ic],0.0)))\n   check_func(x,y) = feas(x,y) > 0.0 ? 0.0 : unconstrained_check(x,y)\n   substp = NLPStopping(subpb, check_func, NLPAtX(xt[Ic]), main_stp = stp)\n\n   #we solve the unconstrained subproblem:\n   global_newton(substp, prms)\n   @show status(substp, list = true)\n\n   if feas(substp.pb, substp.current_state) > 0.0 #new iterate is infeasible\n     #then we need to project\n     xt[Ic] = max.(min.(substp.current_state.x,  stp.pb.meta.uvar[Ic]),  stp.pb.meta.lvar[Ic])\n     #we keep track of the new active indices\n     Inew = setdiff(union(findall(abs.(- xt  + stp.pb.meta.lvar).<= active), findall(abs.(  x0  - stp.pb.meta.uvar).<= active)), I)\n   else\n     Inew = []\n   end\n\n   fill_in!(stp, xt) #the lazy update\n\n   OK = update_and_stop!(stp, evals = stp.pb.counters)\n\n   if !OK #we use a relaxation rule based on an approx. of Lagrange multipliers\n     Irmv = findall(stp.current_state.mu .<0.0)\n     I = union(setdiff(I, Irmv), Inew)\n     Ic = setdiff(all, I)\n   end\n @show xt, I\n end #end of main loop\n\n return stp\nend","category":"page"},{"location":"howtostop-2/#How-to-Stop-2","page":"How to Stop 2","title":"How to Stop 2","text":"","category":"section"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"The Stopping structure eases the implementation of algorithms and the stopping criterion. We illustrate here the features of Stopping when the algorithm is used a subStopping.","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"using Test, Stopping","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"Assume we want to solve \"pb\" starting from \"x0\" and solving at each step of the algorithm the subproblem \"subpb\".  We can use this additional info to improve the stopping criterion.","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"x0 = ones(2)\npb = nothing\nsubpb = nothing\nsubsubpb = nothing","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"Initialize a Stopping for the main pb","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"main_stop = GenericStopping(pb, x0)","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"We can then, initialize another stopping to the subproblem, and providing the main_stop as a keyword argument:","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"sub_stop = GenericStopping(subpb, x0, main_stp = main_stop, tol_check = (atol, rtol, opt0) -> atol)","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"Note that by default main_stp is void","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"@test main_stop.main_stp == nothing","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"The only difference appears in the event of a call to stop!, which now also check the time and resources of the main_pb.","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"OK = start!(sub_stop)\n@test OK == false #no reason to stop just yet.","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"Assume time is exhausted for the main_stop","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"main_stop.meta.start_time = 0.0 #force a timing failure in the main problem\nstop!(sub_stop)\n\n@test status(sub_stop, list = true) == [:ResourcesOfMainProblemExhausted]\n@test sub_stop.meta.tired == false\n@test sub_stop.meta.main_pb == true","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"The same applies if there is now a third subproblem","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"reinit!(main_stop)\nreinit!(sub_stop)\nsubsub_stop = GenericStopping(subsubpb, x0, main_stp = sub_stop, tol_check = (atol, rtol, opt0) -> atol)\nmain_stop.meta.start_time = 0.0 #force a timing failure in the main problem\nstop!(subsub_stop)\n\n@test status(subsub_stop, list = true) == [:ResourcesOfMainProblemExhausted]\n@test subsub_stop.meta.tired   == false\n@test subsub_stop.meta.main_pb == true\n@test status(sub_stop, list = true) == [:ResourcesOfMainProblemExhausted]\n@test sub_stop.meta.tired   == false\n@test sub_stop.meta.main_pb == true\n@test status(main_stop, list = true) == [:Tired]\n@test main_stop.meta.tired   == true\n@test main_stop.meta.main_pb == false","category":"page"},{"location":"run-optimsolver/#Run-optimization-algorithms","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"","category":"section"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"The Stopping structure eases the implementation of algorithms and the stopping criterion.","category":"page"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"The following examples illustrate solver for optimization:","category":"page"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"a backtracking 1D optimization solver\na globalized Newton for unconstrained optimization solver\na bound constraint active-set algorithm\na quadratic penalty algorithm for non-linear optimization","category":"page"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"using LinearAlgebra, NLPModels, Stopping, Test\n\ninclude(\"../test-stopping/rosenbrock.jl\")","category":"page"},{"location":"run-optimsolver/#Part-1/4","page":"Run optimization algorithms","title":"Part 1/4","text":"","category":"section"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"printstyled(\"How to solve 1D optim problem: \\n\", color = :red)\ninclude(\"backls.jl\")","category":"page"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"printstyled(\"1D Optimization: backtracking tutorial.\\n\", color = :green)\n\nx0 = 1.5*ones(6)\nnlp = ADNLPModel(rosenbrock,  x0)\ng0 = grad(nlp,x0)\nh = onedoptim(x -> obj(nlp, x0 - x * g0), x -> - dot(g0,grad(nlp,x0 - x * g0)))","category":"page"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"SCENARIO: We create 3 stopping: Define the LSAtT with mandatory entries g₀ and h₀.","category":"page"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"lsatx  = LSAtT(1.0, h₀ = obj(nlp, x0), g₀ = -dot(grad(nlp, x0),grad(nlp, x0)))\nlsstp  = LS_Stopping(h, (x,y)-> armijo(x,y, τ₀ = 0.01), lsatx)\nlsatx2 = LSAtT(1.0, h₀ = obj(nlp, x0), g₀ = -dot(grad(nlp, x0),grad(nlp, x0)))\nlsstp2 = LS_Stopping(h, (x,y)-> wolfe(x,y, τ₁ = 0.99), lsatx2)\nlsatx3 = LSAtT(1.0, h₀ = obj(nlp, x0), g₀ = -dot(grad(nlp, x0),grad(nlp, x0)))\nlsstp3 = LS_Stopping(h, (x,y)-> armijo_wolfe(x,y, τ₀ = 0.01, τ₁ = 0.99), lsatx3)\n\nparameters = ParamLS(back_update = 0.5)\n\nprintstyled(\"backtracking line search with Armijo:\\n\", color = :green)\nbacktracking_ls(lsstp, parameters)\n@show status(lsstp)\n@show lsstp.meta.nb_of_stop\n@show lsstp.current_state.x\n\nprintstyled(\"backtracking line search with Wolfe:\\n\", color = :green)\nbacktracking_ls(lsstp2, parameters)\n@show status(lsstp2)\n@show lsstp2.meta.nb_of_stop\n@show lsstp2.current_state.x\n\nprintstyled(\"backtracking line search with Armijo-Wolfe:\\n\", color = :green)\nbacktracking_ls(lsstp3, parameters)\n@show status(lsstp3)\n@show lsstp3.meta.nb_of_stop\n@show lsstp3.current_state.x","category":"page"},{"location":"run-optimsolver/#Part-2/4","page":"Run optimization algorithms","title":"Part 2/4","text":"","category":"section"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"printstyled(\"How to solve unconstrained optim problem: \\n\", color = :red)\ninclude(\"uncons.jl\")\n\nprintstyled(\"Unconstrained Optimization: globalized Newton.\\n\", color = :green)\n\nx0 = 1.5*ones(6)\nnlp = ADNLPModel(rosenbrock,  x0)\n\n# We use the default builder using the KKT optimality function (which does not\n# automatically fill in the State)\nstop_nlp = NLPStopping(nlp)\nparameters = PrmUn()\n\nprintstyled(\"Newton method with Armijo linesearch.\\n\", color = :green)\nglobal_newton(stop_nlp, parameters)\n@show status(stop_nlp)\n#We can check afterwards, the score\n@show Stopping.KKT(stop_nlp.pb, stop_nlp.current_state)\n@show stop_nlp.meta.nb_of_stop\n\nprintstyled(\"Newton method with Armijo-Wolfe linesearch.\\n\", color = :green)\nreinit!(stop_nlp, rstate = true, x = x0)\nreset!(stop_nlp.pb) #reinitialize the counters of the NLP\nparameters.ls_func = (x,y)-> armijo_wolfe(x,y, τ₀ = parameters.armijo_prm,\n                                               τ₁ = parameters.wolfe_prm)\n\nglobal_newton(stop_nlp, parameters)\n@show status(stop_nlp)\n#We can check afterwards, the score\n@show Stopping.KKT(stop_nlp.pb, stop_nlp.current_state)\n@show stop_nlp.meta.nb_of_stop","category":"page"},{"location":"run-optimsolver/#Part-3/4","page":"Run optimization algorithms","title":"Part 3/4","text":"","category":"section"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"printstyled(\"How to solve bound constrained optim problem: \\n\", color = :red)\ninclude(\"activeset.jl\")\n\nprintstyled(\"Constrained optimization: active-set algorithm tutorial.\\n\", color = :green)\nx0 = 1.5*ones(6);x0[6]=1.0\nnlp_bnd = ADNLPModel(rosenbrock,  x0,\n                 lvar = fill(-10.0,size(x0)), uvar = fill(1.5,size(x0)))\n\nnlp_bnd_at_x = NLPAtX(x0)\nstop_nlp_c = NLPStopping(nlp_bnd, max_iter = 10)\n\nactiveset(stop_nlp_c)\n@show status(stop_nlp_c)","category":"page"},{"location":"run-optimsolver/#Part-4/4","page":"Run optimization algorithms","title":"Part 4/4","text":"","category":"section"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"printstyled(\"How to solve nonlinear optim problem: \\n\", color = :red)\ninclude(\"penalty.jl\")\n\nprintstyled(\"Constrained optimization: quadratic penalty tutorial.\\n\", color = :green)\nx0 = 1.5*ones(6)\nc(x) = [sum(x)]\nnlp2 = ADNLPModel(rosenbrock,  x0,\n                 lvar = fill(-10.0,size(x0)), uvar = fill(10.0,size(x0)),\n                 y0 = [0.0], c = c, lcon = [-Inf], ucon = [5.])\n\nnlp_at_x_c = NLPAtX(x0, zeros(nlp2.meta.ncon))\nstop_nlp_c = NLPStopping(nlp2, (x,y) -> KKT(x,y), nlp_at_x_c, atol = 1e-3,\n                                max_cntrs = Main.Stopping._init_max_counters(obj = 400000, cons = 800000, sum = 1000000))\n\npenalty(stop_nlp_c)\n@show status(stop_nlp_c)\n\n#We can check afterwards, the score\n@show KKT(stop_nlp_c.pb, stop_nlp_c.current_state)","category":"page"},{"location":"howtostate-nlp/#How-to-State-for-NLPs","page":"How to State for NLPs","title":"How to State for NLPs","text":"","category":"section"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"The data used through the algorithmic process in the Stopping framework are stored in a State. We illustrate here the NLPAtX which is a specialization of the State for non-linear programming.","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"using Test, NLPModels, Stopping","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"Formulate the problem with NLPModels:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"include(\"../test-stopping/rosenbrock.jl\")\nx0   = ones(6)\ny0   = ones(1)\nc(x) = [x[1] - x[2]]\nlcon = [0.0]\nucon = [0.0]","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"We can create a NLPAtX for constrained optimization. Here we provide y0 = [1.0]. Note that the default value is [0.0].","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"nlp = ADNLPModel(x -> rosenbrock(x), x0, y0 = y0,\n                 c = c, lcon = lcon, ucon = ucon,\n                 lvar = zeros(6), uvar = Inf * ones(6))","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"We can create a NLPAtX for bounds-constrained optimization:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"nlp2 = ADNLPModel(x -> rosenbrock(x), x0,\n                 lvar = zeros(6), uvar = Inf * ones(6))","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"We can create a NLPAtX for unconstrained optimization:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"nlp3 = ADNLPModel(x -> rosenbrock(x), x0)","category":"page"},{"location":"howtostate-nlp/#I.-Initialize-a-NLPAtX:","page":"How to State for NLPs","title":"I. Initialize a NLPAtX:","text":"","category":"section"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"There are two main constructor for the States. The unconstrained:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"state_unc = NLPAtX(x0)","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"The constrained:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"state_con = NLPAtX(x0, y0)","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"By default, all the values in the State are set to nothing except x and lambda In the unconstrained case lambda is a vector of length 0.","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"@test !(state_unc.lambda == nothing)","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"From the default initialization, all the other entries are void:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"@test state_unc.mu == nothing && state_con.mu == nothing\n@test state_unc.fx == nothing && state_con.fx == nothing","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"An exception is the counters which is initialized as a default Counters:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"@test (sum_counters(state_unc.evals) + sum_counters(state_con.evals)) == 0","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"Note that the constructor proceeds to a size checking on gx, Hx, mu, cx, Jx. It returns an error if this test fails.","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"try\n  NLPAtX(x0, Jx = ones(1,1))\n  @test false\ncatch\n  #printstyled(\"NLPAtX(x0, Jx = ones(1,1)) is invalid as length(lambda)=0\\n\")\n  @test true\nend","category":"page"},{"location":"howtostate-nlp/#II.-Update-the-entries","page":"How to State for NLPs","title":"II. Update the entries","text":"","category":"section"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"At the creation of a NLPAtX, keyword arguments populate the state:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"state_bnd = NLPAtX(x0, mu = zeros(6))\n@test state_bnd.mu == zeros(6) #initialize multipliers with bounds constraints","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"The NLPAtX has two functions: update! and reinit! The update! has the same behavior as in the GenericState:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"update!(state_bnd, fx = 1.0, blah = 1) #update! ignores unnecessary keywords\n@test state_bnd.mu == zeros(6) && state_bnd.fx == 1.0 && state_bnd.x == x0","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"reinit! by default reuse x and lambda and reset all the entries at their default values (void or empty Counters):","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"reinit!(state_bnd, mu = ones(6))\n@test state_bnd.mu == ones(6) && state_bnd.fx == nothing\n@test state_bnd.x == x0 && state_bnd.lambda == zeros(0)","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"Trying to inherit reinit!(AbstractState, Vector) would not work here as lambda is a mandatory entry.","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"try\n reinit!(state_bnd, 2 * ones(6))\n @test false\ncatch\n @test true\nend","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"However, we can specify both entries","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"reinit!(state_bnd, 2 * ones(6), zeros(0))\n@test state_bnd.x == 2*ones(6) && state_bnd.lambda == zeros(0)\n@test state_bnd.mu == nothing && sum_counters(state_bnd.evals) == 0","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"Giving a new Counters update as well:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"test = Counters(); setfield!(test, :neval_obj, 102)\nreinit!(state_bnd, evals = test)\n@test getfield(state_bnd.evals, :neval_obj) == 102\n@test sum_counters(state_bnd.evals) - 102 == 0","category":"page"},{"location":"howtostate-nlp/#III.-Domain-Error","page":"How to State for NLPs","title":"III. Domain Error","text":"","category":"section"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"Similar to the GenericState we can use domain_check to verify there are no NaN","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"@test Stopping._domain_check(state_bnd) == false\nupdate!(state_bnd, fx = NaN)\n@test Stopping._domain_check(state_bnd) == true","category":"page"},{"location":"howtostate-nlp/#IV.-Use-the-NLPAtX","page":"How to State for NLPs","title":"IV. Use the NLPAtX","text":"","category":"section"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"For algorithmic use, it might be conveninent to fill in all the entries of then State. In this case, we can use the Stopping:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"stop = NLPStopping(nlp, (x,y) -> unconstrained_check(x,y), state_unc)","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"Note that the fillin! can receive known informations via keywords. If we don't want to store the hessian matrix, we turn the keyword matrixinfo as false.","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"fill_in!(stop, x0, matrix_info = false)","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"@test stop.current_state.Hx == nothing","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"We can now use the updated step in the algorithmic procedure","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"@test start!(stop) #return true","category":"page"},{"location":"benchmark/#Benchmark","page":"Benchmark optimization algorithms","title":"Benchmark","text":"","category":"section"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"https://juliasmoothoptimizers.github.io/SolverBenchmark.jl/latest/tutorial/ In this tutorial we illustrate the main uses of SolverBenchmark.","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"using LinearAlgebra, NLPModels, Stopping\n\ninclude(\"backls.jl\")\ninclude(\"uncons.jl\")","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"using DataFrames, Printf, SolverBenchmark","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"CUTEst is a collection of test problems","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"using CUTEst","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"problems_unconstrained = CUTEst.select(contype=\"unc\")\nn = length(problems_unconstrained) #240","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"printstyled(\"Benchmark solvers: \\n\", color = :green)\n\n#Names of 3 solvers:\nnames = [:armijo, :wolfe, :armijo_wolfe]\np1 = PrmUn(); p2 = PrmUn(ls_func = wolfe); p3 = PrmUn(ls_func = armijo_wolfe)\nparamDict = Dict(:armijo => p1, :wolfe => p2, :armijo_wolfe => p3)\n#Initialization of the DataFrame for n problems.\nstats = Dict(name => DataFrame(:id => 1:n,\n         :name => [@sprintf(\"prob%s\", problems_unconstrained[i]) for i = 1:n],\n         :nvar => zeros(Int64, n),\n         :status => [:Unknown for i = 1:n],\n         :f => NaN*ones(n),\n         :t => NaN*ones(n),\n         :iter => zeros(Int64, n),\n         :eval_f => zeros(Int64, n),\n         :eval_g => zeros(Int64, n),\n         :eval_H => zeros(Int64, n),\n         :score => NaN*ones(n)) for name in names)","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"for i=1:n\n  nlp_cutest = CUTEst.CUTEstModel(problems_unconstrained[i])\n  @show i, problems_unconstrained[i], nlp_cutest.meta.nvar\n  #update the stopping with the new problem\n  stop_nlp = NLPStopping(nlp_cutest,\n                         unconstrained_check,\n                         NLPAtX(nlp_cutest.meta.x0),\n                         max_iter = 20)\n\n  for name in names\n\n    #solve the problem\n    global_newton(stop_nlp, paramDict[name])\n\n    #update the stats from the Stopping\n    stats[name].nvar[i] = nlp_cutest.meta.nvar\n    stats[name].status[i] = status(stop_nlp)\n    stats[name].f[i] = stop_nlp.current_state.fx == nothing ? NaN : stop_nlp.current_state.fx\n    stats[name].t[i] = stop_nlp.current_state.current_time == nothing ? NaN : stop_nlp.current_state.current_time - stop_nlp.meta.start_time\n    stats[name].iter[i] = stop_nlp.meta.nb_of_stop\n    stats[name].score[i] = unconstrained_check(nlp_cutest, stop_nlp.current_state)\n    stats[name].eval_f[i] = getfield(stop_nlp.current_state.evals, :neval_obj)\n    stats[name].eval_g[i] = getfield(stop_nlp.current_state.evals, :neval_grad)\n    stats[name].eval_H[i] = getfield(stop_nlp.current_state.evals, :neval_hess)\n\n    #reinitialize the Stopping and the nlp\n    reinit!(stop_nlp, rstate = true, x = nlp_cutest.meta.x0)\n    reset!(stop_nlp.pb)\n  end\n\n  #finalize nlp\n  finalize(nlp_cutest)\nend #end of main loop","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"for name in names\n@show stats[name]\nend","category":"page"},{"location":"#Stopping.jl","page":"Home","title":"Stopping.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for Stopping.jl","category":"page"},{"location":"#Purpose","page":"Home","title":"Purpose","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Tools to ease the uniformization of stopping criteria in iterative solvers.","category":"page"},{"location":"","page":"Home","title":"Home","text":"When a solver is called on an optimization model, four outcomes may happen:","category":"page"},{"location":"","page":"Home","title":"Home","text":"the approximate solution is obtained, the problem is considered solved\nthe problem is declared unsolvable (unboundedness, infeasibility ...)\nthe maximum available resources are not sufficient to compute the solution\nsome algorithm dependent failure happens","category":"page"},{"location":"","page":"Home","title":"Home","text":"This tool eases the first three items above. It defines a type","category":"page"},{"location":"","page":"Home","title":"Home","text":"mutable struct GenericStopping <: AbstractStopping\n    problem       :: Any                  # an arbitrary instance of a problem\n    meta          :: AbstractStoppingMeta # contains the used parameters and stopping status\n    current_state :: AbstractState        # Current information on the problem\n    main_stp :: Union{AbstractStopping, Nothing} # Stopping of the main problem, or nothing\n    listofstates :: Union{ListStates, Nothing}   # History of states\n    user_specific_struct :: Any                  # User-specific structure","category":"page"},{"location":"","page":"Home","title":"Home","text":"The StoppingMeta provides default tolerances, maximum resources, ...  as well as (boolean) information on the result.","category":"page"},{"location":"#Your-Stopping-your-way","page":"Home","title":"Your Stopping your way","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The GenericStopping (with GenericState) provides a complete structure to handle stopping criteria. Then, depending on the problem structure, you can specialize a new Stopping by redefining a State and some functions specific to your problem.","category":"page"},{"location":"","page":"Home","title":"Home","text":"We provide some specialization of the GenericStopping for optimization:","category":"page"},{"location":"","page":"Home","title":"Home","text":"NLPStopping with NLPAtX as a specialized State: for non-linear programming (based on NLPModels);\nLAStopping with GenericState: for linear algebra problems.\nLS_Stopping with LSAtT as a specialized State: for 1d optimization;\nmore to come...","category":"page"},{"location":"#Functions","page":"Home","title":"Functions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The tool provides two main functions:","category":"page"},{"location":"","page":"Home","title":"Home","text":"start!(stp :: AbstractStopping) initializes the time and the tolerance at the starting point and check wether the initial guess is optimal.\nstop!(stp :: AbstractStopping) checks optimality of the current guess as well as failure of the system (unboundedness for instance) and maximum resources (number of evaluations of functions, elapsed time ...)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Stopping uses the informations furnished by the State to evaluate its functions. Communication between the two can be done through the following functions:","category":"page"},{"location":"","page":"Home","title":"Home","text":"update_and_start!(stp :: AbstractStopping; kwargs...) updates the states with informations furnished as kwargs and then call start!.\nupdate_and_stop!(stp :: AbstractStopping; kwargs...) updates the states with informations furnished as kwargs and then call stop!.\nfill_in!(stp :: AbstractStopping, x :: Iterate) a function that fill in all the State with all the informations required to correctly evaluate the stopping functions. This can reveal useful, for instance, if the user do not trust the informations furnished by the algorithm in the State.\nreinit!(stp :: AbstractStopping) reinitialize the entries of","category":"page"},{"location":"","page":"Home","title":"Home","text":"the Stopping to reuse for another call.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Consult the HowTo tutorial to learn more about the possibilities offered by Stopping.","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can also access other examples of algorithms in the test/examples folder, which for instance illustrate the strenght of Stopping with subproblems:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Consult the OptimSolver tutorial for more on how to use Stopping with nested algorithms.\nCheck the Benchmark tutorial to see how Stopping can combined with SolverBenchmark.jl.\nStopping can be adapted to closed solvers via a buffer function as in Buffer tutorial for an instance with Ipopt via NLPModelsIpopt.","category":"page"},{"location":"#How-to-install","page":"Home","title":"How to install","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Install and test the Stopping package with the Julia package manager:","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add Stopping\npkg> test Stopping","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can access the most up-to-date version of the Stopping package using:","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add https://github.com/vepiteski/Stopping.jl\npkg> test Stopping\npkg> status Stopping","category":"page"},{"location":"#Example","page":"Home","title":"Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"As an example, a naive version of the Newton method is provided here. First we import the packages:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using LinearAlgebra, NLPModels, Stopping","category":"page"},{"location":"","page":"Home","title":"Home","text":"We consider a quadratic test function, and create an uncontrained quadratic optimization problem using NLPModels:","category":"page"},{"location":"","page":"Home","title":"Home","text":"A = rand(5, 5); Q = A' * A;\nf(x) = 0.5 * x' * Q * x\nnlp = ADNLPModel(f,  ones(5))","category":"page"},{"location":"","page":"Home","title":"Home","text":"We now initialize the NLPStopping. First create a State.","category":"page"},{"location":"","page":"Home","title":"Home","text":"nlp_at_x = NLPAtX(ones(5))","category":"page"},{"location":"","page":"Home","title":"Home","text":"We use unconstrained_check as an optimality function","category":"page"},{"location":"","page":"Home","title":"Home","text":"stop_nlp = NLPStopping(nlp, nlp_at_x, optimality_check = unconstrained_check)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that, since we used a default State, an alternative would have been:","category":"page"},{"location":"","page":"Home","title":"Home","text":"stop_nlp = NLPStopping(nlp)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Now a basic version of Newton to illustrate how to use Stopping.","category":"page"},{"location":"","page":"Home","title":"Home","text":"function newton(stp :: NLPStopping)\n\n    #Notations\n    pb = stp.pb; state = stp.current_state;\n    #Initialization\n    xt = state.x\n\n    #First, call start! to check optimality and set an initial configuration\n    #(start the time counter, set relative error ...)\n    OK = update_and_start!(stp, x = xt, gx = grad(pb, xt), Hx = hess(pb, xt))\n\n    while !OK\n        #Compute the Newton direction (state.Hx only has the lower triangular)\n        d = (state.Hx + state.Hx' - diagm(0 => diag(state.Hx))) \\ (- state.gx)\n        #Update the iterate\n        xt = xt + d\n        #Update the State and call the Stopping with stop!\n        OK = update_and_stop!(stp, x = xt, gx = grad(pb, xt), Hx = hess(pb, xt))\n    end\n\n    return stp\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"Finally, we can call the algorithm with our Stopping:","category":"page"},{"location":"","page":"Home","title":"Home","text":"stop_nlp = newton(stop_nlp)","category":"page"},{"location":"","page":"Home","title":"Home","text":"and consult the Stopping to know what happened","category":"page"},{"location":"","page":"Home","title":"Home","text":"#We can then ask stop_nlp the final status\n@test :Optimal in status(stop_nlp, list = true)\n#Explore the final values in stop_nlp.current_state\nprintstyled(\"Final solution is $(stop_nlp.current_state.x)\", color = :green)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We reached optimality, and thanks to the Stopping structure this simple looking algorithm verified at each step of the algorithm:","category":"page"},{"location":"","page":"Home","title":"Home","text":"time limit has been respected;\nevaluations of the problem are not excessive;\nthe problem is not unbounded (w.r.t. x and f(x));\nthere is no NaN in x, f(x), g(x), H(x);\nthe maximum number of iteration (call to stop!) is limited.","category":"page"},{"location":"#Long-Term-Goals","page":"Home","title":"Long-Term Goals","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Stopping is aimed as a tool for improving the reusability and robustness in the implementation of iterative algorithms. We warmly welcome any feedback or comment leading to potential improvements.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Future work will address more sophisticated problems such as mixed-integer optimization problems, optimization with uncertainty. The list of suggested optimality functions will be enriched with state of the art conditions.","category":"page"},{"location":"tutorial/#Tutorials-and-examples","page":"Examples and tutorials","title":"Tutorials and examples","text":"","category":"section"},{"location":"tutorial/","page":"Examples and tutorials","title":"Examples and tutorials","text":"Many tutorials and example are available here, among them :","category":"page"},{"location":"tutorial/","page":"Examples and tutorials","title":"Examples and tutorials","text":"a basic Julia implementation of a Newton method using Stopping,\na Julia implementation of a penalty algorithm,\nhow to use Stopping to simplify benchmarking of algorithm and  \nhow to converting existing algorithms to Stopping.","category":"page"},{"location":"tutorial/","page":"Examples and tutorials","title":"Examples and tutorials","text":"If you encounter any problems with Stopping, please post an issue on Github. Issues and pull requests will help improve Stopping as well as the documentation.  ","category":"page"}]
}
