var documenterSearchIndex = {"docs":
[{"location":"buffer/#Use-a-buffer","page":"Use a buffer function","title":"Use a buffer","text":"","category":"section"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"We already illustrated the use of Stopping for optimization algorithm, however, in the case where one algorithm/solver is not Stopping-compatible, a buffer solver is required to unify the formalism. We illustrate this situation here with the Ipopt solver.","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"Remark in the buffer function: in case the solver stops with success but the stopping condition is not satisfied, one option is to iterate and reduce the various tolerances.","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"Documentation for Ipopt options can be found here: https://coin-or.github.io/Ipopt/OPTIONS.html#OPTIONS_REF","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"using Ipopt, NLPModels, NLPModelsIpopt, Stopping\n\ninclude(\"../test-stopping/rosenbrock.jl\")\nx0  = 1.5 * ones(6)\nnlp = ADNLPModel(rosenbrock,  x0)","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"The traditional way to solve an optimization problem using NLPModelsIpopt https://github.com/JuliaSmoothOptimizers/NLPModelsIpopt.jl","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"printstyled(\"Oth scenario:\\n\")\n\nstats = ipopt(nlp, print_level = 0, x0 = x0)","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"Use y0 (general), zL (lower bound), zU (upper bound) for initial guess of Lagrange multipliers.","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"@show stats.solution, stats.status","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"Using Stopping, the idea is to create a buffer function","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"function solveIpopt(stp :: NLPStopping)\n\n #xk = solveIpopt(stop.pb, stop.current_state.x)\n stats = ipopt(nlp, print_level     = 0,\n                    tol             = stp.meta.rtol,\n                    x0              = stp.current_state.x,\n                    max_iter        = stp.meta.max_iter,\n                    max_cpu_time    = stp.meta.max_time,\n                    dual_inf_tol    = stp.meta.atol,\n                    constr_viol_tol = stp.meta.atol,\n                    compl_inf_tol   = stp.meta.atol)\n\n #Update the meta boolean with the output message\n if stats.status == :first_order stp.meta.suboptimal      = true end\n if stats.status == :acceptable  stp.meta.suboptimal      = true end\n if stats.status == :infeasible  stp.meta.infeasible      = true end\n if stats.status == :small_step  stp.meta.stalled         = true end\n if stats.status == :max_iter    stp.meta.iteration_limit = true end\n if stats.status == :max_time    stp.meta.tired           = true end\n\n stp.meta.nb_of_stop = stats.iter\n #stats.elapsed_time\n\n x = stats.solution\n\n #Not mandatory, but in case some entries of the State are used to stop\n fill_in!(stp, x)\n\n stop!(stp)\n\n return stp\nend","category":"page"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"nlp_at_x = NLPAtX(x0)\nstop = NLPStopping(nlp, unconstrained_check, nlp_at_x)","category":"page"},{"location":"buffer/#st-scenario,-we-solve-again-the-problem-with-the-buffer-solver","page":"Use a buffer function","title":"1st scenario, we solve again the problem with the buffer solver","text":"","category":"section"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"printstyled(\"1st scenario:\\n\")\nsolveIpopt(stop)\n@show stop.current_state.x, status(stop)\nnbiter = stop.meta.nb_of_stop","category":"page"},{"location":"buffer/#nd-scenario:-we-check-that-we-control-the-maximum-iterations.","page":"Use a buffer function","title":"2nd scenario: we check that we control the maximum iterations.","text":"","category":"section"},{"location":"buffer/","page":"Use a buffer function","title":"Use a buffer function","text":"printstyled(\"2nd scenario:\\n\")\n#rstate is set as true to allow reinit! modifying the State\nreinit!(stop, rstate = true, x = x0)\nstop.meta.max_iter = max(nbiter-4,1)\n\nsolveIpopt(stop)\n#Final status is :IterationLimit\n@show stop.current_state.x, status(stop)","category":"page"},{"location":"idcard-stopremote/#Stopping's-attributes-ID:-StopRemoteControl","page":"Stop remote control","title":"Stopping's attributes ID: StopRemoteControl","text":"","category":"section"},{"location":"idcard-stopremote/","page":"Stop remote control","title":"Stop remote control","text":"Usual instances of AbstractStopping contains a StopRemoteControl <: AbstractStopRemoteControl (stp.stop_remote), which controls the various checks run by the functions start! and stop!. An instance of StopRemoteControl contains:","category":"page"},{"location":"idcard-stopremote/","page":"Stop remote control","title":"Stop remote control","text":"unbounded_and_domain_x_check :: Bool\ndomain_check                 :: Bool\noptimality_check             :: Bool\ninfeasibility_check          :: Bool\nunbounded_problem_check      :: Bool\ntired_check                  :: Bool\nresources_check              :: Bool\nstalled_check                :: Bool\niteration_check              :: Bool\nmain_pb_check                :: Bool\nuser_check                   :: Bool\nuser_start_check             :: Bool\ncheap_check                  :: Bool","category":"page"},{"location":"idcard-stopremote/","page":"Stop remote control","title":"Stop remote control","text":"Only the last attributes, cheap_check, is not related with a specific check. Set as true, it stopped whenever one of the checks is successful and the algorithm needs to stop. It is false by default. All the other entries are set as true by default, i.e.","category":"page"},{"location":"idcard-stopremote/","page":"Stop remote control","title":"Stop remote control","text":"#initializes a remote control with all the checks on.\nsrc = StopRemoteControl()","category":"page"},{"location":"idcard-stopremote/","page":"Stop remote control","title":"Stop remote control","text":"In order to remove some checks, it suffices to use keywords:","category":"page"},{"location":"idcard-stopremote/","page":"Stop remote control","title":"Stop remote control","text":"#remove time and iteration checks.\nsrc = StopRemoteControl(tired_check = false, iteration_check = false)","category":"page"},{"location":"idcard-stopremote/#FAQ:-Is-there-performance-issues-with-all-these-checks?","page":"Stop remote control","title":"FAQ: Is there performance issues with all these checks?","text":"","category":"section"},{"location":"idcard-stopremote/","page":"Stop remote control","title":"Stop remote control","text":"Assuming that x is a vector of length n, some of these checks are indeed in O(n), which can be undesirable for some applications. In this case, you can either initialize a \"cheap\" remote control as follows","category":"page"},{"location":"idcard-stopremote/","page":"Stop remote control","title":"Stop remote control","text":"#initialize a StopRemoteControl with 0(n) checks set as false\nsrc = cheap_stop_remote_control()","category":"page"},{"location":"idcard-stopremote/","page":"Stop remote control","title":"Stop remote control","text":"or deactivate the tests by hand as shown previously.","category":"page"},{"location":"idcard-stopremote/#FAQ:-How-can-I-fine-tune-these-checks?","page":"Stop remote control","title":"FAQ: How can I fine-tune these checks?","text":"","category":"section"},{"location":"idcard-stopremote/","page":"Stop remote control","title":"Stop remote control","text":"All these checks can be fine-tuned by selecting entries in the StoppingMeta.","category":"page"},{"location":"checkpointing/#Checkpointing","page":"Checkpointing","title":"Checkpointing","text":"","category":"section"},{"location":"checkpointing/","page":"Checkpointing","title":"Checkpointing","text":"In this tutorial, we present the use of Stopping to checkpointing.","category":"page"},{"location":"checkpointing/","page":"Checkpointing","title":"Checkpointing","text":"When using an optimizer for high-scale problems, the resolution process might be extremly long. In order to analyze the progress of the algorithm or save ongoing results, an idea is to introduce checkpointing, i.e. we save the output result in the file every n-steps. Using Stopping this operation is now very simple.","category":"page"},{"location":"checkpointing/","page":"Checkpointing","title":"Checkpointing","text":"using ADNLPModels, FileIO, JLD2, LinearAlgebra, NLPModels, Printf, Random, Stopping","category":"page"},{"location":"checkpointing/","page":"Checkpointing","title":"Checkpointing","text":"In this tutorial, we will use the steepest descent method with a fixed stepsize.","category":"page"},{"location":"checkpointing/","page":"Checkpointing","title":"Checkpointing","text":"function fixed_step_steepest_descent(stp :: NLPStopping; t = 1e-5)\n\n  xk = stp.current_state.x\n\n  OK = update_and_start!(stp, gx = grad(stp.pb, xk))\n\n  @printf \"%2s %7s\\n\" \"k\" \"||∇f(x)||\"\n  @printf \"%2d %7.1e\\n\" stp.meta.nb_of_stop norm(stp.current_state.current_score)\n  while !OK\n    xk -= t * stp.current_state.gx\n    \n    OK = update_and_stop!(stp, x = xk, gx = grad(stp.pb, xk))\n\n    @printf \"%2d %7.1e\\n\" stp.meta.nb_of_stop norm(stp.current_state.current_score)\n  end\n  return stp\nend","category":"page"},{"location":"checkpointing/","page":"Checkpointing","title":"Checkpointing","text":"We now generate a regularized least squares problem using ADNLPModels.jl.","category":"page"},{"location":"checkpointing/","page":"Checkpointing","title":"Checkpointing","text":"Random.seed!(1234)\nm, n = 10_000, 10\nA  = rand(m, n)\nb  = A * ones(n)\nf(x, A, b, λ) = norm(A * x - b)^2 + λ * norm(x)^2\npb = ADNLPModel(x -> f(x, A, b, 1e-2), zeros(n))","category":"page"},{"location":"checkpointing/","page":"Checkpointing","title":"Checkpointing","text":"The final step is now to initialize the Stopping and specify user-defined structures to store the parameter n_save set to 50 so that every 50 iterations the current stopping is saved using the package JLD2.jl.","category":"page"},{"location":"checkpointing/","page":"Checkpointing","title":"Checkpointing","text":"save_check(stp, b) = begin \n  if stp.meta.nb_of_stop % stp.stopping_user_struct[:n_save] == 0\n    @save \"checkpoint_stopping_$(stp.meta.nb_of_stop).jld2\" stp\n  end\nend\nn_save = 50\nstp = NLPStopping(pb, user_struct = Dict(:n_save => n_save), \n                      user_check_func! = save_check, max_iter = 99)\n# Let's go\nfixed_step_steepest_descent(stp)","category":"page"},{"location":"checkpointing/","page":"Checkpointing","title":"Checkpointing","text":"The algorithm has now generated two files checkpoint_stopping_0.jld2 and checkpoint_stopping_50.jld2 that can be analyzed.","category":"page"},{"location":"checkpointing/","page":"Checkpointing","title":"Checkpointing","text":"stp0 = load(\"checkpoint_stopping_0.jld2\")[\"stp\"]\nstp50 = load(\"checkpoint_stopping_50.jld2\")[\"stp\"]","category":"page"},{"location":"speak-to-stopping/#Do-you-speak-Stopping?","page":"Speak to stopping","title":"Do you speak Stopping?","text":"","category":"section"},{"location":"speak-to-stopping/","page":"Speak to stopping","title":"Speak to stopping","text":"When using a Stopping-compatible algorithm, a.k.a an algorithm that takes a Stopping as an input and update it, the user is free to explore the results and influence the execution of the algorithm.","category":"page"},{"location":"speak-to-stopping/","page":"Speak to stopping","title":"Speak to stopping","text":"First, we need to create a Stopping.","category":"page"},{"location":"speak-to-stopping/","page":"Speak to stopping","title":"Speak to stopping","text":"x = ones(10)\nproblem = nothing #or your instance\nstp = GenericStopping(pb, x, max_time = 10.) #short-cut initializing a `GenericState` and a `StoppingMeta`\n@show stp.meta.max_time == 10. #by default the `kwargs...` are passed to the meta.","category":"page"},{"location":"speak-to-stopping/","page":"Speak to stopping","title":"Speak to stopping","text":"One can also creates separately a state and a meta to form a Stopping:","category":"page"},{"location":"speak-to-stopping/","page":"Speak to stopping","title":"Speak to stopping","text":"state = GenericState(x)\nmeta  = StoppingMeta(max_time = 10.)\nstp   = GenericStopping(pb, meta, state)","category":"page"},{"location":"speak-to-stopping/","page":"Speak to stopping","title":"Speak to stopping","text":"Once the Stopping has been initialized, we call the algorithm and exploit the output.","category":"page"},{"location":"speak-to-stopping/","page":"Speak to stopping","title":"Speak to stopping","text":"stp = rand_solver(stp, x) #call your favorite solver","category":"page"},{"location":"speak-to-stopping/","page":"Speak to stopping","title":"Speak to stopping","text":"To understand why the algorithm stopped we use status.","category":"page"},{"location":"speak-to-stopping/","page":"Speak to stopping","title":"Speak to stopping","text":"status(stp) #or `status(stp, rlist = true)` to have the complete list.","category":"page"},{"location":"speak-to-stopping/","page":"Speak to stopping","title":"Speak to stopping","text":"The solution as well as problem-related information can be accessed from the state.","category":"page"},{"location":"speak-to-stopping/","page":"Speak to stopping","title":"Speak to stopping","text":"sol = stp.current_state.x","category":"page"},{"location":"speak-to-stopping/#FAQ:-How-do-I-know-the-entries-in-the-Stopping,-State-or-the-Meta?","page":"Speak to stopping","title":"FAQ: How do I know the entries in the Stopping, State or the Meta?","text":"","category":"section"},{"location":"speak-to-stopping/","page":"Speak to stopping","title":"Speak to stopping","text":"You can use Julia's build-in fieldnames function.","category":"page"},{"location":"speak-to-stopping/","page":"Speak to stopping","title":"Speak to stopping","text":"fieldnames(stp)\nfieldnames(stp.current_state)\nfieldnames(stp.meta)","category":"page"},{"location":"howtostop/#How-to-Stop","page":"How to Stop","title":"How to Stop","text":"","category":"section"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The Stopping structure eases the implementation of algorithms and the stopping criterion. We illustrate here the basic features of Stopping.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"-> the case where a Stopping is a sub-Stopping is treated in the next tutorial.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"using Test, Stopping","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"x0 = ones(2)\npb = nothing","category":"page"},{"location":"howtostop/#I.-Initialize-a-Stopping","page":"How to Stop","title":"I. Initialize a Stopping","text":"","category":"section"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The lazy way to initialize the stopping is to provide an initial point:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"stop1 = GenericStopping(pb, x0, rtol = 1e-1)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The more sophisticated way is to first build a State:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"state1 = GenericState(ones(2))","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"then, use it to create a Stopping:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"stop2 = GenericStopping(pb, state1, rtol = 1e-1)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Both ways give the same result:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test stop1.current_state.x == stop2.current_state.x\n@test stop1.current_state.current_time == stop2.current_state.current_time","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Keywords given in the Stopping creator are forwarded to the StoppingMeta.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test stop1.meta.rtol == 1e-1","category":"page"},{"location":"howtostop/#II.-Check-the-status","page":"How to Stop","title":"II. Check the status","text":"","category":"section"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"To ask the Stopping what is the current situation, we have the status function:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test status(stop1) == :Unknown #nothing happened yet.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The status function check the boolean values in the Meta: unbounded, unboundedpb, tired, stalled, iterationlimit, resources, optimal, infeasible, main_pb, domainerror, suboptimal","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"stop1.meta.unbounded  = true\nstop1.meta.suboptimal = true","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"By default the status function prioritizes a status:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test status(stop1) == :SubOptimal","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"while you can access the list of status by turning the keyword list as true:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test status(stop1, list =true) == [:SubOptimal, :Unbounded]","category":"page"},{"location":"howtostop/#III.-Analyze-the-situation:-start!","page":"How to Stop","title":"III. Analyze the situation: start!","text":"","category":"section"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Two functions are designed to ask Stopping to analyze the current situation mainly described by the State: start!, stop! start! is designed to be used right at the beginning of the algorithm:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"start!(stop1) #we will compare with stop2","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"this call initializes a few entries: a) start_time in the META","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test isnan(stop2.meta.start_time)\n@test !isnan(stop1.meta.start_time)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"b) optimality0 in the META (used to check the relative error)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test stop2.meta.optimality0 == 1.0 #default value was 1.0\n@test stop1.meta.optimality0 == Inf #GenericStopping has no specified measure","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"c) the time measured is also updated in the State (if void)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test stop1.current_state.current_time != nothing","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"d) in the case where optimality0 is NaN, meta.domainerror becomes true","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test stop1.meta.domainerror == false","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"e) the problem would be already solved if optimality0 pass a null_test Since optimality0 is Inf, any value would pass the relative error check:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test Stopping._null_test(stop1, Inf) == true\n@test stop1.meta.optimal == true\n@test :Optimal in status(stop1, list = true)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The Stopping determines the optimality by testing a score at zero. The test at zero is controlled by the function meta.tol_check which takes 3 arguments: atol, rtol, optimality0. By default it check if the score is less than: max(atol, rtol * opt0)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"stop1.meta.tol_check = (atol, rtol, opt0) -> atol\n@test Stopping._null_test(stop1, Inf) == false","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"This can be determined in the initialization of the Stopping","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"stop3 = GenericStopping(pb, state1, tol_check = (atol, rtol, opt0) -> atol)\n@test Stopping._null_test(stop3, Inf) == false","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The function _optimalitycheck providing the score returns Inf by default and must be specialized for specialized Stopping. If State entries have to be specified before the start!, you can use the function updateand_start! instead of a update! and then a start!","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"update_and_start!(stop3, x = zeros(2), current_time = -1.0)\n@test stop3.meta.optimal == false\n@test stop3.current_state.current_time == -1.0\n@test stop3.meta.start_time != nothing\n@test stop3.current_state.x == zeros(2)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Once the iterations begins #stop! is the main function. if needed an update is needed first, we can use updateandstop!","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"OK = stop!(stop3) #update the Stopping and return  a boolean\n@test OK == false #no reason to stop just yet!","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"The stop! call check the following:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"meta.domainerror: check if the score is NaN\nmeta.optimal: the score passes the _null_test\nmeta.unbounded: check if state.x is too large\nmeta.unbounded_pb: false by default\nmeta.tired: check if time is exhausted\nmeta.resources: false by default\nmeta.iteration_limit: check the number of iterations\nmeta.stalled: false by default\nmeta.main_pb: false by default -> see Stopping as a subproblem tutorial","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Note that 1 and 2 are also done by start!.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"check unboundedness of x:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test update_and_stop!(stop3, x = (stop3.meta.unbounded_x + 1.0) * x0 )\n@test stop3.meta.unbounded == true","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"check time","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"stop3.meta.start_time = 0.0 #too  force the time limit.\nstop!(stop3)\n@test stop3.meta.tired == true","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Stopping the number of iterations by the number of calls to stop!","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test stop3.meta.nb_of_stop == 3 #We called stop3 3 times already\nstop3.meta.max_iter = 3\nstop!(stop3)\n@test stop3.meta.iteration_limit == true #as stop3.meta.nb_of_stop > 3.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Overall we activated three flags:","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test status(stop3, list = true) == [:Unbounded, :IterationLimit, :Tired]","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Once we are done with an algorithm and want to reuse a stopping, we need to reinitialize all the entries.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"reinit!(stop3)","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"the status boolean are back to false","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test !stop3.meta.iteration_limit && !stop3.meta.tired && !stop3.meta.unbounded","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"reinitialize also the entries updated by the start!","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"@test isnan(stop3.meta.start_time) && (stop3.meta.optimality0 == 1.0)\n@test stop3.meta.nb_of_stop == 0 #and the counter of stop","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"Note that by default reinit! does not reinitialize the currentstate. This can be done by switching the keyword rstate to true. In this case, keywords are forwarded to the reinit! of currentstate.","category":"page"},{"location":"howtostop/","page":"How to Stop","title":"How to Stop","text":"reinit!(stop3, rstate =  true, x = zeros(2))\n@test stop3.current_state.current_time == nothing\n@test stop3.current_state.x == zeros(2)","category":"page"},{"location":"gradient-lbfgs/#Mixed-algorithms:-a-ListofStates-tutorial","page":"Mix algorithms","title":"Mixed-algorithms: a ListofStates tutorial","text":"","category":"section"},{"location":"gradient-lbfgs/","page":"Mix algorithms","title":"Mix algorithms","text":"We illustrate here the use of ListofStates in dealing with a warm start procedure. The full code of this tutorial can be found here.","category":"page"},{"location":"gradient-lbfgs/","page":"Mix algorithms","title":"Mix algorithms","text":"ListofStates is designed to store the of the iteration process. In this tutorial, we compare the resolution of a convex unconstrained problem with 3 variants:","category":"page"},{"location":"gradient-lbfgs/","page":"Mix algorithms","title":"Mix algorithms","text":"a steepest descent method\nan inverse-BFGS method\na mix of 5 steps of steepest descent and then switching to a BFGS initialized with the 5 previous steps.","category":"page"},{"location":"gradient-lbfgs/","page":"Mix algorithms","title":"Mix algorithms","text":"using Stopping, NLPModels, LinearAlgebra, Test, Printf","category":"page"},{"location":"gradient-lbfgs/","page":"Mix algorithms","title":"Mix algorithms","text":"First, we introduce our two implementations that both uses an backtracking Armijo linesearch.","category":"page"},{"location":"gradient-lbfgs/","page":"Mix algorithms","title":"Mix algorithms","text":"import Stopping.armijo\nfunction armijo(xk, dk, fk, slope, f)\n  t = 1.0\n  fk_new = f(xk + dk)\n  while f(xk + t * dk) > fk + 1.0e-4 * t * slope\n    t /= 1.5\n    fk_new = f(xk + t * dk)\n  end\n  return t, fk_new\nend\n\nfunction steepest_descent(stp :: NLPStopping)\n\n  xk = stp.current_state.x\n  fk, gk = objgrad(stp.pb, xk)\n\n  OK = update_and_start!(stp, fx = fk, gx = gk)\n\n  @printf \"%2s %9s %7s %7s %7s\\n\" \"k\" \"fk\" \"||∇f(x)||\" \"t\" \"λ\"\n  @printf \"%2d %7.1e %7.1e\\n\" stp.meta.nb_of_stop fk norm(stp.current_state.current_score)\n  while !OK\n    dk = - gk\n    slope = dot(dk, gk)\n    t, fk = armijo(xk, dk, fk, slope, x->obj(stp.pb, x))\n    xk += t * dk\n    fk, gk = objgrad(stp.pb, xk)\n    \n    OK = update_and_stop!(stp, x = xk, fx = fk, gx = gk)\n\n    @printf \"%2d %9.2e %7.1e %7.1e %7.1e\\n\" stp.meta.nb_of_stop fk norm(stp.current_state.current_score) t slope\n  end\n  return stp\nend\n\nfunction bfgs_quasi_newton_armijo(stp :: NLPStopping; Hk = nothing)\n\n  xk = stp.current_state.x\n  fk, gk = objgrad(stp.pb, xk)\n  gm = gk\n\n  dk, t = similar(gk), 1.\n  if isnothing(Hk)\n    Hk = I #start from identity matrix\n  end\n\n  OK = update_and_start!(stp, fx = fk, gx = gk)\n\n  @printf \"%2s %7s %7s %7s %7s\\n\" \"k\" \"fk\" \"||∇f(x)||\" \"t\" \"cos\"\n  @printf \"%2d %7.1e %7.1e\\n\" stp.meta.nb_of_stop fk norm(stp.current_state.current_score)\n\n  while !OK\n    if stp.meta.nb_of_stop != 0\n      sk = t * dk\n      yk = gk - gm\n      ρk = 1/dot(yk, sk)\n      #we need yk'*sk > 0 for instance yk'*sk ≥ 1.0e-2 * sk' * Hk * sk\n      Hk = ρk ≤ 0.0 ? Hk : (I - ρk * sk * yk') * Hk * (I - ρk * yk * sk') + ρk * sk * sk'\n      if norm(sk) ≤ 1e-14\n        break\n      end\n      #H2 = Hk + sk * sk' * (dot(sk,yk) + yk'*Hk*yk )*ρk^2 - ρk*(Hk * yk * sk' + sk * yk'*Hk)\n    end\n    dk = - Hk * gk\n    slope = dot(dk, gk) # ≤ -1.0e-4 * norm(dk) * gnorm\n    t, fk = armijo(xk, dk, fk, slope, x->obj(stp.pb, x))\n\n    xk = xk + t * dk\n    gm = copy(gk)\n    gk = grad(stp.pb, xk)\n\n    OK = update_and_stop!(stp, x = xk, fx = fk, gx = gk)\n    @printf \"%2d %7.1e %7.1e %7.1e %7.1e\\n\" stp.meta.nb_of_stop fk norm(stp.current_state.current_score) t slope\n  end\n  stp.stopping_user_struct = Dict( :Hk => Hk)\n  return stp\nend","category":"page"},{"location":"gradient-lbfgs/","page":"Mix algorithms","title":"Mix algorithms","text":"We consider the following convex unconstrained problem model using ADNLPModels.jl and defines a related NLPStopping.","category":"page"},{"location":"gradient-lbfgs/","page":"Mix algorithms","title":"Mix algorithms","text":"fH(x) = (x[2]+x[1].^2-11).^2+(x[1]+x[2].^2-7).^2\nnlp = ADNLPModel(fH, [10., 20.])\nstp = NLPStopping(nlp, optimality_check = unconstrained_check, \n                 atol = 1e-6, rtol = 0.0, max_iter = 100)","category":"page"},{"location":"gradient-lbfgs/","page":"Mix algorithms","title":"Mix algorithms","text":"reinit!(stp, rstate = true, x = nlp.meta.x0)\nsteepest_descent(stp)\n\n@test status(stp) == :Optimal\n@test stp.listofstates == VoidListofStates()\n\n@show elapsed_time(stp)\n@show nlp.counters\n\nreinit!(stp, rstate = true, x = nlp.meta.x0, rcounters = true)\nbfgs_quasi_newton_armijo(stp)\n\n@test status(stp) == :Optimal\n@test stp.listofstates == VoidListofStates()\n\n@show elapsed_time(stp)\n@show nlp.counters\n\nNLPModels.reset!(nlp)\nstp_warm = NLPStopping(nlp, optimality_check = unconstrained_check, \n                      atol = 1e-6, rtol = 0.0, max_iter = 5, \n                      n_listofstates = 5) #shortcut for list = ListofStates(5, Val{NLPAtX{Float64,Array{Float64,1},Array{Float64,2}}}()))\nsteepest_descent(stp_warm)\n@test status(stp_warm) == :IterationLimit\n@test length(stp_warm.listofstates) == 5\n\nHwarm = I\nfor i=2:5\n  sk = stp_warm.listofstates.list[i][1].x - stp_warm.listofstates.list[i-1][1].x \n  yk = stp_warm.listofstates.list[i][1].gx - stp_warm.listofstates.list[i-1][1].gx \n  ρk = 1/dot(yk, sk)\n  if ρk > 0.0\n    global Hwarm = (I - ρk * sk * yk') * Hwarm * (I - ρk * yk * sk') + ρk * sk * sk'\n  end\nend\n\nreinit!(stp_warm)\nstp_warm.meta.max_iter = 100\nbfgs_quasi_newton_armijo(stp_warm, Hk = Hwarm)\nstatus(stp_warm)\n\n@show elapsed_time(stp_warm)\n@show nlp.counters","category":"page"},{"location":"fixed-point/#Example-of-a-fixed-point-algorithm","page":"A fixed point algorithm","title":"Example of a fixed point algorithm","text":"","category":"section"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"Stopping can also be used for fixed point methods Example here concerns the AlternatingDirections Algorithm to find a feasible point in the intersection of 2 convex sets A and B. This algorithm relies on a fixed point argument, hence it stopped if it finds a fixed point.","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"Example: A={ (x,y) | x=y} and B = {(x,y) | y=0} Clearly the unique intersection point is (0,0)","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"Note that in this case the projection on A and the projection on B are trivial","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"Takeaway: the 2nd scenario illustrates a situation where the algorithm stalls as it reached a personal success. (optimalsubpb is true)","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"using LinearAlgebra, NLPModels, Stopping, Test","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"Main algorithm","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"function AlternatingDirections(stp)\n\n xk = stp.current_state.x\n OK = update_and_start!(stp, cx = cons(stp.pb, x0))\n @show OK, xk\n\n while !OK\n\n  #First projection\n  xk1 = 0.5 * (xk[1] + xk[2]) * ones(2)\n  #Second projection\n  xk2 = [xk1[1],0.0]\n\n  #check if we have a fixed point\n  Fix = dot(xk-xk2,xk-xk2)\n  if Fix <= min(eps(Float64),stp.meta.atol) stp.meta.suboptimal = true end\n  #call the stopping\n  OK = update_and_stop!(stp, x = xk2, cx = cons(stp.pb, xk2))\n\n  xk = xk2\n  @show OK, xk\n end\n\n return stp\nend","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"We model the problem using the NLPModels without objective function Formulate the problem with NLPModels","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"c(x) = [x[1] - x[2], x[2]]\nlcon = [0.0, 0.0]\nucon = [0.0, 0.0]\nnlp = ADNLPModel(x->0.0, zeros(2), c=c, lcon=lcon, ucon=ucon)","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"1st scenario: we solve the problem","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"printstyled(\"1st scenario:\\n\")\n#Prepare the Stopping\nx0 = [0.0, 5.0]\nstate = NLPAtX(x0)\n#Recall that for the optimality_check function x is the pb and y is the state\n#Here we take the infinite norm of the residual.\nstop = NLPStopping(nlp, (x,y) -> norm(y.cx,Inf), state)\n\nAlternatingDirections(stop)\n@show status(stop)\n@test status(stop) == :Optimal","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"2nd scenario: the user gives an irrealistic optimality condition","category":"page"},{"location":"fixed-point/","page":"A fixed point algorithm","title":"A fixed point algorithm","text":"printstyled(\"2nd scenario:\\n\")\nreinit!(stop, rstate = true, x = x0)\nstop.optimality_check = (x,y) -> norm(y.cx,Inf)+0.5\n\nAlternatingDirections(stop)\n#In this scenario, the algorithm stops because it attains a fixed point\n#Hence, status is :SubOptimal.\n@show status(stop)\n@test status(stop) == :SubOptimal","category":"page"},{"location":"lastopping/#LinearAlgebraStopping:-A-Stopping-for-linear-algebra","page":"LAStopping","title":"LinearAlgebraStopping: A Stopping for linear algebra","text":"","category":"section"},{"location":"lastopping/","page":"LAStopping","title":"LAStopping","text":"The Stopping-structure can be adapted to any problem solved by iterative methods. We discuss here LAStopping a specialization of an AbstractStopping for linear systems: $ Ax=b \\text{ or } \\min_x \\frac{1}{2}\\|Ax - b\\|^2 $ . We highlight here the specifities of such instance:","category":"page"},{"location":"lastopping/","page":"LAStopping","title":"LAStopping","text":"The problem is either an LLSModel or Stopping.LinearSystem.\nThese two types of problems have some access on A, b and counters of evaluations. The matrix A can be either given as a sparse/dense matrix or a linear operator.\nDefault optimality functions are checking either the system directly or the normal equation.","category":"page"},{"location":"lastopping/","page":"LAStopping","title":"LAStopping","text":"#Problem definition:\nm, n = 200, 100 #size of A: m x n\nA    = 100 * rand(m, n) #It's a dense matrix :)\nxref = 100 * rand(n)\nb    = A * xref\n#Our initial guess\nx0 = zeros(n)\n\n#Two definitions of LAStopping: 1) for dense matrix:\nla_stop = LAStopping(A, b, GenericState(x0), \n                     max_iter = 150000, \n                     rtol = 1e-6, \n                     max_cntrs = init_max_counters_NLS(residual = 150000))\n#2) for a linear operator:\nop_stop = LAStopping(LinearSystem(LinearOperator(A), b), \n                     GenericState(x0), \n                     max_iter = 150000, \n                     rtol = 1e-6, \n                     max_cntrs = init_max_counters_linear_operators(nprod = 150000))","category":"page"},{"location":"stop-workflow/#Stopping-work-flow","page":"Stopping workflow","title":"Stopping-work flow","text":"","category":"section"},{"location":"stop-workflow/","page":"Stopping workflow","title":"Stopping workflow","text":"The table below depict the various checks done by the function stop! and their connection with the meta, current_state and current_state. The function entry correspond to the function used internally by stop!, they can be imported and redifined to be adapted for a specific problem, for instance NLPStopping for NLPModels. The remote_control entry corresponds to the attribute in the remote_control that could be set as true/false to activate/deactivate this check. The meta_status gives the attribute in the meta with the check's answer. Finally the last column corresponds to entries in the meta parametrizing this check.","category":"page"},{"location":"stop-workflow/","page":"Stopping workflow","title":"Stopping workflow","text":"Check description Function remote control meta statuses meta tolerances\nCheck unboundedness and the domain of x _unbounded_and_domain_x_check! unbounded_and_domain_x_check domainerror and unbounded_problem_x stp.meta.unbounded_x\nCheck the domain in state (NaN's ...) _domain_check domain_check domainerror \nCheck optimality _optimality_check! and _null_test optimality_check optimal See how to check optimality with Stopping\nCheck for infeasibility _infeasibility_check! infeasibility_check infeasible \nCheck for unboundedness in problem values _unbounded_problem_check! unbounded_problem_check unbounded_problem \nCheck time-limit _tired_check! tired_check tired start_time, max_time\nCheck for limits in resources _resources_check! resources_check resources \nCheck if algo is stalling _stalled_check! stalled_check stalled \nCount the number of stop! and limits _iteration_check! iteration_check iteration_limit max_iter\nCheck if the main_stp stops _main_pb_check! main_pb_check main_pb \nCallback user check _user_check! user_check stopbyuser user_check_func!","category":"page"},{"location":"stop-workflow/#FAQ:-Is-Stopping-initializing-meta.start_time-on-its-own?","page":"Stopping workflow","title":"FAQ: Is Stopping initializing meta.start_time on its own?","text":"","category":"section"},{"location":"stop-workflow/","page":"Stopping workflow","title":"Stopping workflow","text":"Yes, it does when you call start! as well as optimality0 if start! check the optimality.","category":"page"},{"location":"stop-workflow/#FAQ:-How-to-set-up-the-user_check?","page":"Stopping workflow","title":"FAQ: How to set-up the user_check?","text":"","category":"section"},{"location":"stop-workflow/","page":"Stopping workflow","title":"Stopping workflow","text":"Stopping call the user_check_func! defined in the meta.","category":"page"},{"location":"stop-workflow/#FAQ:-How-does-Stopping-check-the-optimality?","page":"Stopping workflow","title":"FAQ: How does Stopping check the optimality?","text":"","category":"section"},{"location":"stop-workflow/","page":"Stopping workflow","title":"Stopping workflow","text":"See the tutorial on this topic.","category":"page"},{"location":"howtostate/#How-to-State","page":"How to State","title":"How to State","text":"","category":"section"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"The data used through the algorithmic process in the Stopping framework are stored in a State.","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"We illustrate here the GenericState and its features.","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"using Test, Stopping","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"The GenericState contains only two entries:  a Vector x, and a Float current_time","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"state1 = GenericState(ones(2)) #takes a Vector as a mandatory input\nstate2 = GenericState(ones(2), current_time = 1.0)","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"By default if a non-mandatory entry is not specified it is void:","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"@test state1.current_time == nothing\n@test state2.current_time == 1.0","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"The GenericState has two functions: update! and reinit!. update! is used to update entries of the State:","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"update!(state1, current_time = 1.0)\n@test state1.current_time == 1.0","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"Note that the update select the relevant entries:","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"update!(state1, fx = 1.0) #does nothing as there are no fx entry\n@test state1.current_time == 1.0 && state1.x == ones(2)","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"The update! can be done only if the new entry is void or has the same type as the existing one.","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"update!(state1, current_time = 2) #does nothing as it is the wrong type\n@test state1.current_time == 1.0","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"One can force the update even if the type is not the same by turning the keyword convert as true (it is false by default).","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"update!(state1, convert = true, current_time = 2)\n@test state1.current_time == 2","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"Non-required entry in the State can always be set as void without convert.","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"update!(state1, current_time = nothing)\n@test state1.current_time == nothing","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"A shorter way to empty the State is to use the reinit! function. This function is particularly useful, when there are many entries.","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"reinit!(state2)\n@test state2.x == ones(2) && state2.current_time == nothing","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"If one wants to use reinit! with a different value of the mandatory entry:","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"reinit!(state2, zeros(2))\n@test state2.x == zeros(2) && state2.current_time == nothing","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"After reinitializing the State reinit! can update entries passed as keywords. either in the default call:","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"reinit!(state2, current_time = 1.0)\n@test state2.x == zeros(2) && state2.current_time == 1.0","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"or in the one changing x:","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"reinit!(state2, ones(2), current_time = 1.0)\n@test state2.x == ones(2) && state2.current_time == 1.0","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"The State has also a private function guaranteeing there are no NaN.","category":"page"},{"location":"howtostate/","page":"How to State","title":"How to State","text":"OK = Stopping._domain_check(state1) #function returns a boolean\n@test OK == false #no NaN\n\nupdate!(state1, current_time = NaN)\n@test Stopping._domain_check(state1) == true\n\n@test Stopping._domain_check(state2) == false\nupdate!(state2, x=[NaN, 0.0])\n@test Stopping._domain_check(state2) == true","category":"page"},{"location":"penalty/#Quadratic-penalty-algorithm","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"","category":"section"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"In this test problem we consider a quadratic penalty method. This example features an algorithm with the 3 steps: the penalization - the unconstrained min - the 1d min","category":"page"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"Note that there is no optimization of the evaluations here. The penalization gives an approximation of the gradients, multipliers...","category":"page"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"Note the use of a structure for the algorithmic parameters which is forwarded to all the 3 steps. If a parameter is not mentioned, then the default entry in the algorithm will be taken.","category":"page"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"include(\"uncons.jl\")","category":"page"},{"location":"penalty/#Quadratic-penalty-algorithm-2","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"","category":"section"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"fill_in! used instead of update! (works but usually more costly in evaluations) subproblems are solved via Newton method","category":"page"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"function penalty(stp :: NLPStopping; rho0 = 1.0, rho_min = 1e-10,\n                                     rho_update = 0.5, prms = nothing)\n\n #algorithm's parameters\n rho = rho0\n\n #First call to the stopping\n #Becareful here, some entries must be filled in first.\n fill_in!(stp, stp.current_state.x)\n OK = start!(stp)\n\n #prepare the subproblem stopping:\n sub_nlp_at_x = NLPAtX(stp.current_state.x)\n sub_pb  = ADNLPModel(x -> obj(stp.pb, x)\n                      + 1/rho * norm(max.(cons(stp.pb, x) - stp.pb.meta.ucon, 0.0))^2\n                      + 1/rho * norm(max.(- cons(stp.pb, x) + stp.pb.meta.lcon, 0.0))^2,  x0)\n sub_stp = NLPStopping(sub_pb, unconstrained_check,\n                               sub_nlp_at_x, main_stp = stp)\n\n #main loop\n while !OK\n\n  #solve the subproblem\n  reinit!(sub_stp)\n  sub_stp.meta.atol = min(rho, sub_stp.meta.atol)\n  global_newton(sub_stp, prms)\n\n  #Update all the entries of the State\n  fill_in!(stp, sub_stp.current_state.x)\n\n  #Either stop! is true OR the penalty parameter is too small\n  if rho < rho_min stp.meta.suboptimal = true end\n  OK = stop!(stp)\n\n  @show stp.meta.nb_of_stop, OK, rho\n\n  #update the penalty parameter if necessary\n  if !OK\n   rho = rho * rho_update\n   sub_stp.pb  = ADNLPModel(x -> obj(stp.pb, x)\n                            + 1/rho * norm(max.(cons(stp.pb, x) - stp.pb.meta.ucon, 0.0))^2\n                            + 1/rho * norm(max.(- cons(stp.pb, x) + stp.pb.meta.lcon, 0.0))^2,  x0)\n  end\n end\n\n return stp\nend","category":"page"},{"location":"penalty/#Quadratic-penalty-algorithm:-buffer-function","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm: buffer function","text":"","category":"section"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"function penalty(stp :: NLPStopping, prms)\n\n #extract required values in the prms file\n r0 = :rho0       ∈ fieldnames(typeof(prms)) ? prms.rho0       : 1.0\n rm = :rho_min    ∈ fieldnames(typeof(prms)) ? prms.rho_min    : 1e-10\n ru = :rho_update ∈ fieldnames(typeof(prms)) ? prms.rho_update : 0.5\n\n return penalty(stp, rho0 = r0, rho_min = rm, ru = 0.5, prms = prms)\nend","category":"page"},{"location":"penalty/#Algorithmic-parameters-structure","page":"Quadratic penalty algorithm","title":"Algorithmic parameters structure","text":"","category":"section"},{"location":"penalty/","page":"Quadratic penalty algorithm","title":"Quadratic penalty algorithm","text":"mutable struct Param\n\n    #parameters for the penalty\n    rho0       :: Float64 #initial value of the penalty parameter\n    rho_min    :: Float64 #smallest possible parameter\n    rho_update :: Float64 #update of the penalty parameter\n\n    #parameters of the unconstrained minimization\n    armijo_prm  :: Float64 #Armijo parameter\n    wolfe_prm   :: Float64 #Wolfe parameter\n    onedsolve   :: Function #1D solver\n    ls_func     :: Function\n\n    #parameters of the 1d minimization\n    back_update :: Float64 #backtracking update\n\n    function Param(;rho0        :: Float64 = 1.0,\n                    rho_min     :: Float64 = sqrt(eps(Float64)),\n                    rho_update  :: Float64 = 0.5,\n                    armijo_prm  :: Float64 = 0.01,\n                    wolfe_prm   :: Float64 = 0.99,\n                    onedsolve   :: Function = backtracking_ls,\n                    ls_func     :: Function = (x,y)-> armijo(x,y, τ₀ = armijo_prm),\n                    back_update :: Float64 = 0.5)\n        return new(rho0, rho_min, rho_update,\n                   armijo_prm, wolfe_prm, onedsolve, ls_func,\n                   back_update)\n    end\nend","category":"page"},{"location":"api/#State","page":"API","title":"State","text":"","category":"section"},{"location":"api/#Types","page":"API","title":"Types","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Stopping.GenericState\nStopping.ListofStates\nStopping.NLPAtX\nStopping.OneDAtX","category":"page"},{"location":"api/#Stopping.GenericState","page":"API","title":"Stopping.GenericState","text":"Type: GenericState\n\nMethods: update!, reinit!\n\nA generic State to describe the state of a problem at a point x.\n\nTracked data include:\n\nx             : current iterate\nd [opt]       : search direction\nres [opt]     : residual\ncurrent_time  : time\ncurrent_score : score\n\nConstructors:  GenericState(:: T, :: S; d :: T = _init_field(T), res :: T = _init_field(T), current_time :: Float64 = NaN) where {S, T <:AbstractVector}\n\nGenericState(:: T; d :: T = _init_field(T), res :: T = _init_field(T), current_time :: Float64 = NaN, current_score :: Union{T,eltype(T)} = _init_field(eltype(T))) where T <:AbstractVector\n\nNote: \n\nBy default, unknown entries are set using _init_field.\nBy default the type of current_score is eltype(x) and cannot be changed once the State is created.  To have a vectorized current_score of length n, try something like GenericState(x, Array{eltype(x),1}(undef, n)).\n\nExamples:   GenericState(x)     GenericState(x, Array{eltype(x),1}(undef, length(x)))      GenericState(x, current_time = 1.0)      GenericState(x, current_score = 1.0)   \n\nSee also: Stopping, NLPAtX\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.ListofStates","page":"API","title":"Stopping.ListofStates","text":"Type: list of States\n\nConstructor:\n\nListofStates(:: AbstractState)\n\nListofStates(n :: Int, :: Val{AbstractState})\n\nListofStates(n :: Int, list :: Array{AbstractState,1})\n\nListofStates(state :: S; n :: Int = -1, kwargs...)\n\nNote:\n\nIf n != -1, then it stores at most n AbstractState.\nListofStates recursively handles sub-list of states as the attribute list is\n\nan array of pair whose first component is a, AbstractState and the second component is a ListofStates (or VoidListofStates).\n\nExamples: ListofStates(state)     ListofStates(state, n = 2)     ListofStates(-1, Val{NLPAtX}())     ListofStates(-1, [(state1, VoidListofStates), (state2, VoidListofStates)], 2)    \n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.NLPAtX","page":"API","title":"Stopping.NLPAtX","text":"Type: NLPAtX\n\nMethods: update!, reinit!\n\nNLPAtX contains the information concerning a nonlinear optimization model at the iterate x.\n\nmin_{x ∈ ℜⁿ} f(x) subject to lcon <= c(x) <= ucon, lvar <= x <= uvar.\n\nTracked data include:\n\nx             : the current iterate\nfx [opt]      : function evaluation at x\ngx [opt]      : gradient evaluation at x\nHx [opt]      : hessian evaluation at x\nmu [opt]      : Lagrange multiplier of the bounds constraints\ncx [opt]      : evaluation of the constraint function at x\nJx [opt]      : jacobian matrix of the constraint function at x\nlambda        : Lagrange multiplier of the constraints\nd [opt]       : search direction\nres [opt]     : residual\ncurrent_time  : time\ncurrent_score : score\n\n(import the type NLPModels.Counters)\n\nConstructors:  NLPAtX(:: T, :: T, :: S; fx :: eltype(T) = _init_field(eltype(T)), gx :: T = _init_field(T), Hx :: Matrix{eltype(T)} = _init_field(Matrix{eltype(T)}), mu :: T = _init_field(T), cx :: T = _init_field(T), Jx :: Matrix{eltype(T)} = _init_field(Matrix{eltype(T)}), d :: T = _init_field(T), res :: T = _init_field(T), current_time :: Float64 = NaN) where {S, T <: AbstractVector}\n\nNLPAtX(:: T; fx :: eltype(T) = _init_field(eltype(T)), gx :: T = _init_field(T), Hx :: Matrix{eltype(T)} = _init_field(Matrix{eltype(T)}), mu :: T = _init_field(T), current_time :: Float64 = NaN, current_score :: Union{T,eltype(T)} = _init_field(eltype(T))) where {T <: AbstractVector}\n\nNLPAtX(:: T, :: T; fx :: eltype(T) = _init_field(eltype(T)), gx :: T = _init_field(T), Hx :: Matrix{eltype(T)} = _init_field(Matrix{eltype(T)}), mu :: T = _init_field(T), cx :: T = _init_field(T), Jx :: Matrix{eltype(T)} = _init_field(Matrix{eltype(T)}), d :: T = _init_field(T), res :: T = _init_field(T), current_time :: Float64  = NaN, current_score :: Union{T,eltype(T)} = _init_field(eltype(T))) where T <: AbstractVector\n\nNote:\n\nBy default, unknown entries are set using _init_field.  \nBy default the type of current_score is eltype(x) and cannot be changed once the State is created.    To have a vectorized current_score of length n, try something like GenericState(x, Array{eltype(x),1}(undef, n)).  \nAll these information (except for x and lambda) are optionnal and need to be update when  required. The update is done through the update! function.  \nx and lambda are mandatory entries. If no constraints lambda = [].  \nThe constructor check the size of the entries.  \n\nSee also: GenericState, update!, update_and_start!, update_and_stop!, reinit!\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.OneDAtX","page":"API","title":"Stopping.OneDAtX","text":"Type: OneDAtX\n\nMethods: update!, reinit!, copy\n\nA structure designed to track line search information from one iteration to another. Given f : ℜⁿ → ℜ, define h(θ) = f(x + θ*d) where x and d are vectors of same dimension and θ is a scalar, more specifically the step size.\n\nTracked data can include:\n\nx             : the current step size\nfx [opt]      : h(θ) at the current iteration\ngx [opt]      : h'(θ)\nf₀ [opt]      : h(0)\ng₀ [opt]      : h'(0)\nd [opt]       : search direction\nres [opt]     : residual\ncurrent_time  : the time at which the line search algorithm started.\ncurrent_score : the score at which the line search algorithm started.\n\nConstructors:  OneDAtX(:: T, :: S; fx :: T = _init_field(T), gx :: T = _init_field(T), f₀ :: T = _init_field(T), g₀ :: T = _init_field(T), current_time :: Float64 = NaN) where {S, T <: Number}\n\nOneDAtX(:: T; fx :: T = _init_field(T), gx :: T = _init_field(T), f₀ :: T = _init_field(T), g₀ :: T = _init_field(T), current_time :: Float64 = NaN, current_score :: T = _init_field(T))  where T <: Number\n\nNote: \n\nBy default, unknown entries are set using _init_field.  \nBy default the type of current_score is eltype(x) and cannot be changed once the State is created.  To have a vectorized current_score of length n, use OneDAtX(x, Array{eltype(x),1}(undef, n)).\n\n\n\n\n\n","category":"type"},{"location":"api/#General-Functions","page":"API","title":"General Functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Stopping.update!\nStopping.reinit!\nStopping.copy,\nStopping.compress_state!,\nStopping.copy_compress_state\nStopping.add_to_list!\nStopping.length\nStopping.print","category":"page"},{"location":"api/#Stopping.update!","page":"API","title":"Stopping.update!","text":"update!: generic update function for the State\n\nupdate!(:: AbstractState; convert = false, kwargs...)\n\nThe function compares the kwargs and the entries of the State. If the type of the kwargs is the same as the entry, then it is updated.\n\nSet kargs convert to true to update even incompatible types.\n\nExamples: update!(state1) update!(state1, current_time = 2.0) update!(state1, convert = true, current_time = 2.0)\n\nSee also: GenericState, reinit!, update_and_start!, update_and_stop!\n\n\n\n\n\n`update!(stp::AbstractStopping; kwargs...)`\n\nupdate!: generic update function for the Stopping\n\nShortcut for update!(stp.current_state; kwargs...)\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.reinit!","page":"API","title":"Stopping.reinit!","text":"reinit!: function that set all the entries at _init_field except the mandatory x.\n\nreinit!(:: AbstractState, :: T; kwargs...)\n\nNote: If x is given as a kargs it will be prioritized over the second argument.\n\nExamples: reinit!(state2, zeros(2)) reinit!(state2, zeros(2), current_time = 1.0)\n\nThere is a shorter version of reinit! reusing the x in the state\n\nreinit!(:: AbstractState; kwargs...)\n\nExamples: reinit!(state2) reinit!(state2, current_time = 1.0)\n\n\n\n\n\nreinit!: function that set all the entries at void except the mandatory x\n\nreinit!(:: NLPAtX, x :: AbstractVector, l :: AbstractVector; kwargs...)\n\nreinit!(:: NLPAtX; kwargs...)\n\nNote: if x or lambda are given as keyword arguments they will be prioritized over the existing x, lambda and the default Counters.\n\n\n\n\n\n`reinit!(:: AbstractStopping; rstate :: Bool = false, kwargs...)`\n\nReinitialize the meta-data in the Stopping.\n\nNote:\n\nIf rstate is set as true it reinitializes the current State\n\n(with the kwargs).\n\nIf rlist is set as true the list of states is also reinitialized, either\n\nset as a VoidListofStates if rstate is true or a list containing only the current state otherwise.\n\n\n\n\n\nFor NLPStopping, rcounters set as true also reinitialize the counters.\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.add_to_list!","page":"API","title":"Stopping.add_to_list!","text":"add_to_list!: add a State to the list of maximal size n. If a n+1-th State is added, the first one in the list is removed. The given is State is compressed before being added in the list (via State.copy_compress_state).\n\nadd_to_list!(:: AbstractListofStates, :: AbstractState; kwargs...)\n\nNote: \n\nkwargs are passed to the compress_state call.\ndoes nothing for VoidListofStates\n\nsee also: ListofStates, State.compress_state, State.copy_compress_state\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.length","page":"API","title":"Base.length","text":"length: return the number of States in the list.\n\nlength(:: ListofStates)\n\nsee also: print, addtolist!, ListofStates\n\n\n\n\n\n","category":"function"},{"location":"api/#Base.print","page":"API","title":"Base.print","text":"print: output formatting. return a DataFrame.\n\nprint(:: ListofStates; verbose :: Bool = true, print_sym :: Union{Nothing,Array{Symbol,1}})\n\nNote:\n\nset verbose to false to avoid printing.\nif print_sym is an Array of Symbol, only those symbols are printed. Note that\n\nthe returned DataFrame still contains all the columns.\n\nMore information about DataFrame: http://juliadata.github.io/DataFrames.jl\n\nsee also: add_to_list!, length, ListofStates\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping","page":"API","title":"Stopping","text":"","category":"section"},{"location":"api/#Types-2","page":"API","title":"Types","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Stopping.GenericStopping\nStopping.NLPStopping\nStopping.LAStopping\nStopping.LACounters\nStopping.StoppingMeta","category":"page"},{"location":"api/#Stopping.GenericStopping","page":"API","title":"Stopping.GenericStopping","text":"Type: GenericStopping\n\nMethods: start!, stop!, update_and_start!, update_and_stop!, fill_in!, reinit!, status\n\nA generic Stopping to solve instances with respect to some  optimality conditions. Optimality is decided by computing a score, which is then  tested to zero.\n\nTracked data include:\n\npb         : A problem\ncurrent_state : The information relative to the problem, see GenericState.\n(opt) meta : Metadata relative to a stopping criteria, see StoppingMeta.\n(opt) main_stp : Stopping of the main loop in case we consider a Stopping                      of a subproblem.                      If not a subproblem, then VoidStopping.\n(opt) listofstates : ListofStates designed to store the history of States.\n(opt) stopping_user_struct : Contains a structure designed by the user.\n\nConstructors: \n\nGenericStopping(pb, meta::AbstractStoppingMeta, stop_remote::AbstractStopRemoteControl, state::AbstractState; main_stp::AbstractStopping=VoidStopping(), list::AbstractListofStates = VoidListofStates(), user_struct::AbstractDict = Dict(), kwargs...)    The default constructor.\nGenericStopping(pb, meta::AbstractStoppingMeta, state::AbstractState; main_stp::AbstractStopping=VoidStopping(), list::AbstractListofStates = VoidListofStates(), user_struct::AbstractDict = Dict(), kwargs...)    The one passing the kwargs to the stop_remote.\nGenericStopping(pb, state::AbstractState; stop_remote::AbstractStopRemoteControl = StopRemoteControl(), main_stp::AbstractStopping=VoidStopping(), list::AbstractListofStates = VoidListofStates(), user_struct::AbstractDict = Dict(), kwargs...)    The one passing the kwargs to the meta.\nGenericStopping(pb, stop_remote::AbstractStopRemoteControl, state::AbstractState; main_stp::AbstractStopping=VoidStopping(), list::AbstractListofStates = VoidListofStates(), user_struct::AbstractDict = Dict(), kwargs...)    The one passing the kwargs to the meta.\nGenericStopping(pb, x; n_listofstates=, kwargs...)    The one setting up a default state using x, and initializing the list of states if n_listofstates>0. \n\nNote: Metadata can be provided by the user or created with the Stopping        constructor via kwargs. If a specific StoppingMeta is given and        kwargs are provided, the kwargs have priority.\n\nExamples:  GenericStopping(pb, GenericState(ones(2)), rtol = 1e-1)\n\nBesides optimality conditions, we consider classical emergency exit:\n\ndomain error        (for instance: NaN in x)\nunbounded problem   (not implemented)\nunbounded x         (x is too large)\ntired problem       (time limit attained)\nresources exhausted (not implemented)\nstalled problem     (not implemented)\niteration limit     (maximum number of iteration (i.e. nb of stop) attained)\nmain_pb limit       (tired or resources of main problem exhausted)\n\nThere is an additional default constructor which creates a Stopping with a default State.\n\nGenericStopping(:: Any, :: Union{Number, AbstractVector}; kwargs...)\n\nNote: Keywords arguments are forwarded to the classical constructor.\n\nExamples:  GenericStopping(pb, x0, rtol = 1e-1)\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.NLPStopping","page":"API","title":"Stopping.NLPStopping","text":"Type: NLPStopping\n\nMethods: start!, stop!, update_and_start!, update_and_stop!, fill_in!, reinit!, status,  KKT, unconstrained_check, unconstrained2nd_check, optim_check_bounded\n\nSpecialization of GenericStopping. Stopping structure for non-linear optimization models using NLPModels ( https://github.com/JuliaSmoothOptimizers/NLPModels.jl ).\n\nAttributes:\n\npb         : An AbstractNLPModel.\ncurrent_state      : The information relative to the problem, see GenericState or NLPAtX.\n(opt) meta : Metadata relative to stopping criteria, see StoppingMeta.\n(opt) main_stp : Stopping of the main loop in case we consider a Stopping                         of a subproblem.                         If not a subproblem, then VoidStopping.\n(opt) listofstates : ListofStates designed to store the history of States.\n(opt) stopping_user_struct : Contains any structure designed by the user.\n\nConstructors: \n\nNLPStopping(pb::AbstractNLPModel, meta::AbstractStoppingMeta, stop_remote::AbstractStopRemoteControl, state::AbstractState; main_stp::AbstractStopping=VoidStopping(), list::AbstractListofStates = VoidListofStates(), user_struct::AbstractDict = Dict(), kwargs...)    The default constructor.\nNLPStopping(pb::AbstractNLPModel, meta::AbstractStoppingMeta, state::AbstractState; main_stp::AbstractStopping=VoidStopping(), list::AbstractListofStates = VoidListofStates(), user_struct::AbstractDict = Dict(), kwargs...)    The one passing the kwargs to the stop_remote.\nGenericStopping(pb::AbstractNLPModel, state::AbstractState; stop_remote::AbstractStopRemoteControl = StopRemoteControl(), main_stp::AbstractStopping=VoidStopping(), list::AbstractListofStates = VoidListofStates(), user_struct::AbstractDict = Dict(), kwargs...)    The one passing the kwargs to the meta.\nGenericStopping(pb::AbstractNLPModel; n_listofstates=, kwargs...)    The one setting up a default state NLPAtX using pb.meta.x0, and initializing the list of states if n_listofstates>0. The optimality function is the function KKT unless optimality_check is in the kwargs.\n\nNotes:\n\nDesigned for NLPAtX State. Constructor checks that the State has the required entries.\n\n\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.LAStopping","page":"API","title":"Stopping.LAStopping","text":"Type: LAStopping\n\nMethods: start!, stop!, update_and_start!, update_and_stop!, fill_in!, reinit!, status,  linear_system_check, normal_equation_check\n\nSpecialization of GenericStopping. Stopping structure for linear algebra solving either\n\nAx = b\n\nor\n\nmin_x tfrac12Ax - b^2\n\nAttributes:\n\npb         : a problem using, for instance, either LLSModel (designed for linear least square problem, see https://github.com/JuliaSmoothOptimizers/LLSModels.jl ) or LinearSystem.\ncurrent_state      : The information relative to the problem, see GenericState.\n(opt) meta : Metadata relative to stopping criteria, see StoppingMeta.\n(opt) main_stp : Stopping of the main loop in case we consider a Stopping                         of a subproblem.                         If not a subproblem, then VoidStopping.\n(opt) listofstates : ListofStates designed to store the history of States.\n(opt) stopping_user_struct : Contains a structure designed by the user.\n\nConstructors: \n\nLAStopping(pb, meta::AbstractStoppingMeta, stop_remote::AbstractStopRemoteControl, state::AbstractState; main_stp::AbstractStopping=VoidStopping(), list::AbstractListofStates = VoidListofStates(), user_struct::AbstractDict = Dict(), zero_start::Bool = false)    The default constructor.\nLAStopping(pb, meta::AbstractStoppingMeta, state::AbstractState; main_stp::AbstractStopping=VoidStopping(), list::AbstractListofStates = VoidListofStates(), user_struct::AbstractDict = Dict(), zero_start::Bool = false, kwargs...)    The one passing the kwargs to the stop_remote.\nLAStopping(pb, state::AbstractState; stop_remote::AbstractStopRemoteControl = StopRemoteControl(), main_stp::AbstractStopping=VoidStopping(), list::AbstractListofStates = VoidListofStates(), user_struct::AbstractDict = Dict(), zero_start::Bool = false, kwargs...)    The one passing the kwargs to the meta.\nLAStopping(:: Union{AbstractLinearOperator, AbstractMatrix}, :: AbstractVector; sparse::Bool = true, n_listofstates::Int = 0, kwargs...)    The one setting up a default problem (sparse ? LLSModel(A, b) : LinearSystem(A, b)), a default GenericState using x, and initializing the list of states if n_listofstates>0. \nLAStopping(:: Union{AbstractLinearOperator, AbstractMatrix}, :: AbstractVector, :: AbstractState; sparse::Bool = true, kwargs...)    The one setting up a default problem (sparse ? LLSModel(A, b) : LinearSystem(A, b)). \n\nNotes:\n\nNo specific State targeted\nState don't necessarily keep track of evals\nEvals are checked only for pb.A being a LinearOperator\nzero_start is true if 0 is the initial guess (not check automatically)\nLLSModel counter follow NLSCounters (see init_max_counters_NLS)\nBy default, meta.max_cntrs is initialized with an NLSCounters\n\nSee also GenericStopping, NLPStopping, linear_system_check, normal_equation_check\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.LACounters","page":"API","title":"Stopping.LACounters","text":"Type: LACounters\n\n\n\n\n\n","category":"type"},{"location":"api/#Stopping.StoppingMeta","page":"API","title":"Stopping.StoppingMeta","text":"Type: StoppingMeta\n\nMethods: no methods.\n\nAttributes:\n\natol: absolute tolerance.\nrtol: relative tolerance.\noptimality0: optimality score at the initial guess.\ntol_check: Function of atol, rtol and optimality0 testing a score to zero.\ntol_check_neg: Function of atol, rtol and optimality0 testing a score to zero.\ncheck_pos: pre-allocation for positive tolerance\ncheck_neg: pre-allocation for negative tolerance\nrecomp_tol: true if tolerances are updated\noptimality_check: a stopping criterion via an admissibility function\nunbounded_threshold: threshold for unboundedness of the problem.\nunbounded_x: threshold for unboundedness of the iterate.\nmax_f: maximum number of function (and derivatives) evaluations.\nmax_cntrs: Dict contains the maximum number of evaluations\nmax_eval:  maximum number of function (and derivatives) evaluations.\nmax_iter: threshold on the number of stop! call/number of iteration.\nmax_time: time limit to let the algorithm run.\nnb_of_stop: keep track of the number of stop! call/iteration.\nstart_time: keep track of the time at the beginning.\nfail_sub_pb: status.\nunbounded: status.\nunbounded_pb: status.\ntired: status.\nstalled: status.\niteration_limit: status.\nresources: status.\noptimal: status.\ninfeasible: status.\nmain_pb: status.\ndomainerror: status.\nsuboptimal: status.\nstopbyuser: status.\nexception: status.\nmeta_user_struct:  Any\nuser_check_func!: Function (AbstractStopping, Bool) -> callback.\n\nStoppingMeta(;atol :: Number = 1.0e-6, rtol :: Number = 1.0e-15, optimality0 :: Number = 1.0, tol_check :: Function = (atol,rtol,opt0) -> max(atol,rtol*opt0), tol_check_neg :: Function = (atol,rtol,opt0) -> -max(atol,rtol*opt0), unbounded_threshold :: Number = 1.0e50, unbounded_x :: Number = 1.0e50, max_f :: Int = typemax(Int), max_eval :: Int = 20000, max_iter :: Int = 5000, max_time :: Number = 300.0, start_time :: Float64 = NaN, meta_user_struct :: Any = nothing, kwargs...)\n\nan alternative with constant tolerances:\n\nStoppingMeta(tol_check :: T, tol_check_neg :: T;atol :: Number = 1.0e-6, rtol :: Number = 1.0e-15, optimality0 :: Number = 1.0, unbounded_threshold :: Number = 1.0e50, unbounded_x :: Number = 1.0e50, max_f :: Int = typemax(Int), max_eval :: Int = 20000, max_iter :: Int = 5000, max_time :: Number = 300.0, start_time :: Float64 = NaN, meta_user_struct :: Any = nothing, kwargs...)\n\nNote:\n\nIt is a mutable struct, therefore we can modify elements of a StoppingMeta.\nThe nb_of_stop is incremented everytime stop! or update_and_stop! is called\nThe optimality0 is modified once at the beginning of the algorithm (start!)\nThe start_time is modified once at the beginning of the algorithm (start!)     if not precised before.\nThe different status: fail_sub_pb, unbounded, unbounded_pb, tired, stalled,     iteration_limit, resources, optimal, main_pb, domainerror, suboptimal, infeasible\nfail_sub_pb, suboptimal, and infeasible are modified by the algorithm.\noptimality_check takes two inputs (AbstractNLPModel, NLPAtX)\n\nand returns a Number or an AbstractVector to be compared to 0.\n\noptimality_check does not necessarily fill in the State.\n\nExamples: StoppingMeta(), StoppingMeta(1., -1.)\n\n\n\n\n\n","category":"type"},{"location":"api/#General-Functions-2","page":"API","title":"General Functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Stopping.start!\nStopping.update_and_start!\nStopping.stop!\nStopping.update_and_stop!\nStopping.reinit!\nStopping.fill_in!\nStopping.status\nStopping.init_max_counters\nStopping.init_max_counters_NLS\nStopping.init_max_counters_linear_operators","category":"page"},{"location":"api/#Stopping.start!","page":"API","title":"Stopping.start!","text":"`start!(stp::AbstractStopping; no_opt_check::Bool = false, kwargs...)`\n\nUpdate the Stopping and return true if we must stop.\n\nPurpose is to know if there is a need to even perform an optimization algorithm or if we are at an optimal solution from the beginning.  Set no_opt_check to true avoid checking optimality and domain errors.\n\nThe function start! successively calls: _domain_check(stp, x), _optimality_check!(stp, x), _null_test(stp, x) and  _user_check!(stp, x, true).\n\nNote: - start! initializes stp.meta.start_time (if not done before), stp.current_state.current_time and stp.meta.optimality0  (if no_opt_check is false).           - Keywords argument are passed to the _optimality_check! call.           - Compatible with the StopRemoteControl.   \n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.update_and_start!","page":"API","title":"Stopping.update_and_start!","text":"`update_and_start!(stp::AbstractStopping; no_opt_check::Bool = false, kwargs...)`\n\nUpdate values in the State and initialize the Stopping. Returns the optimality status of the problem as a boolean.\n\nNote: \n\nKwargs are forwarded to the update! call.  \nno_opt_check skip optimality check in start! (false by default).  \n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.stop!","page":"API","title":"Stopping.stop!","text":"`stop!(:: AbstractStopping; kwargs...)`\n\nUpdate the Stopping and return a boolean true if we must stop.\n\nIt serves the same purpose as start! in an algorithm; telling us if we stop the algorithm (because we have reached optimality or we loop infinitely, etc).\n\nThe function stop! successively calls: _domain_check, _optimality_check, _null_test, _unbounded_check!, _tired_check!, _resources_check!, _stalled_check!, _iteration_check!, _main_pb_check!, add_to_list!\n\nNote:\n\nkwargs are sent to the _optimality_check! call.\nIf listofstates != VoidListofStates, call add_to_list!.\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.update_and_stop!","page":"API","title":"Stopping.update_and_stop!","text":"`update_and_stop!(stp :: AbstractStopping; kwargs...)`\n\nUpdate the values in the state and return the optimality status of the problem as a boolean.\n\nNote: Kwargs are forwarded to the update! call.\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.fill_in!","page":"API","title":"Stopping.fill_in!","text":"`fill_in!(stp::AbstractStopping, x::T) where {T}`\n\nfill_in!: fill in the unspecified values of the AbstractState.\n\nNote: NotImplemented for Abstract/Generic-Stopping.\n\n\n\n\n\nfill_in!: (NLPStopping version) a function that fill in the required values in the NLPAtX.\n\nfill_in!( :: NLPStopping, :: Union{AbstractVector, Nothing}; fx :: Union{AbstractVector, Nothing} = nothing, gx :: Union{AbstractVector, Nothing} = nothing, Hx :: Union{MatrixType, Nothing} = nothing, cx :: Union{AbstractVector, Nothing} = nothing, Jx :: Union{MatrixType, Nothing} = nothing, lambda :: Union{AbstractVector, Nothing} = nothing, mu :: Union{AbstractVector, Nothing} = nothing, matrix_info :: Bool = true, kwargs...)\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.status","page":"API","title":"Stopping.status","text":"`status(:: AbstractStopping; list = false)`\n\nReturns the status of the algorithm:\n\nThe different statuses are:\n\nOptimal: reached an optimal solution.\nSubProblemFailure\nSubOptimal: reached an acceptable solution.\nUnbounded: current iterate too large in norm.\nUnboundedPb: unbouned problem.\nStalled: stalled algorithm.\nIterationLimit: too many iterations of the algorithm.\nTimeLimit: time limit.\nEvaluationLimit: too many ressources used,                         i.e. too many functions evaluations.\nResourcesOfMainProblemExhausted: in the case of a substopping, EvaluationLimit or TimeLimit for the main stopping.\nInfeasible: default return value, if nothing is done the problem is              considered feasible.\nStopByUser: stopped by the user.\nDomainError: there is a NaN somewhere.\nException: unhandled exception\nUnknwon: if stopped for reasons unknown by Stopping.\n\nNote:\n\nSet keyword argument list to true, to get an Array with all the statuses.   \nThe different statuses correspond to boolean values in the meta.   \n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.init_max_counters","page":"API","title":"Stopping.init_max_counters","text":"init_max_counters:  initialize the maximum number of evaluations on each of the functions present in the NLPModels.Counters, e.g.\n\ninit_max_counters(; allevals :: T = typemax(T), obj = allevals, grad = allevals, cons = allevals, jcon = allevals, jgrad = allevals, jac = allevals, jprod = allevals, jtprod = allevals, hess = allevals, hprod = allevals, jhprod = allevals, sum = 11 * allevals, kwargs...)\n\n:neval_sum is by default limited to |Counters| * allevals.\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.init_max_counters_NLS","page":"API","title":"Stopping.init_max_counters_NLS","text":"init_max_counters_NLS:  initialize the maximum number of evaluations on each of the functions present in the NLPModels.NLSCounters, e.g.\n\ninit_max_counters_NLS(; allevals = typemax(T), residual = allevals, jac_residual = allevals, jprod_residual = allevals, jtprod_residual = allevals, hess_residual = allevals, jhess_residual = allevals, hprod_residual = allevals, kwargs...)\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.init_max_counters_linear_operators","page":"API","title":"Stopping.init_max_counters_linear_operators","text":"init_max_counters_linear_operators: counters for LinearOperator\n\ninit_max_counters_linear_operators(; allevals :: T = 20000, nprod = allevals, ntprod = allevals, nctprod = allevals, sum = 11 * allevals)\n\n\n\n\n\n","category":"function"},{"location":"api/#Non-linear-admissibility-functions","page":"API","title":"Non-linear admissibility functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Stopping.KKT\nStopping.unconstrained_check\nStopping.unconstrained2nd_check\nStopping.optim_check_bounded","category":"page"},{"location":"api/#Stopping.KKT","page":"API","title":"Stopping.KKT","text":"`KKT( :: AbstractNLPModel, :: NLPAtX; pnorm :: Real = Inf, kwargs...)`\n\nCheck the KKT conditions.\n\nNote: state.gx is mandatory + if bounds state.mu + if constraints state.cx, state.Jx, state.lambda.\n\nSee also unconstrained_check, unconstrained2nd_check, optim_check_bounded\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.unconstrained_check","page":"API","title":"Stopping.unconstrained_check","text":"`unconstrained_check( :: AbstractNLPModel, :: NLPAtX; pnorm :: Real = Inf, kwargs...)`\n\nReturn the pnorm-norm of the gradient of the objective function.\n\nRequire state.gx (filled if not provided).\n\nSee also unconstrained2nd_check, optim_check_bounded, KKT\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.unconstrained2nd_check","page":"API","title":"Stopping.unconstrained2nd_check","text":"`unconstrained2nd_check( :: AbstractNLPModel, :: NLPAtX; pnorm :: Real = Inf, kwargs...)`\n\nCheck the pnorm-norm of the gradient and the smallest eigenvalue of the hessian.\n\nRequire state.gx and state.Hx (filled if not provided).\n\nSee also unconstrained_check, optim_check_bounded, KKT\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.optim_check_bounded","page":"API","title":"Stopping.optim_check_bounded","text":"`optim_check_bounded( :: AbstractNLPModel, :: NLPAtX; pnorm :: Real = Inf, kwargs...)`\n\nCheck the pnorm-norm of the gradient of the objective function projected over the bounds.\n\nRequire state.gx (filled if not provided).\n\nSee also unconstrained_check, unconstrained2nd_check, KKT\n\n\n\n\n\n","category":"function"},{"location":"api/#Linear-algebra-admissibility-functions","page":"API","title":"Linear algebra admissibility functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Stopping.linear_system_check\nStopping.normal_equation_check","category":"page"},{"location":"api/#Stopping.linear_system_check","page":"API","title":"Stopping.linear_system_check","text":"linear_system_check: return ||Ax-b||_p\n\nlinear_system_check(:: Union{LinearSystem, LLSModel}, :: AbstractState; pnorm :: Real = Inf, kwargs...)\n\nNote:\n\nReturns the p-norm of state.res\nstate.res is filled in if nothing.\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.normal_equation_check","page":"API","title":"Stopping.normal_equation_check","text":"normal_equation_check: return ||A'Ax-A'b||_p\n\nnormal_equation_check(:: Union{LinearSystem, LLSModel}, :: AbstractState; pnorm :: Real = Inf, kwargs...)\n\nNote: pb must have A and b entries\n\n\n\n\n\n","category":"function"},{"location":"api/#Line-search-admissibility-functions","page":"API","title":"Line search admissibility functions","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Stopping.armijo\nStopping.wolfe\nStopping.armijo_wolfe\nStopping.shamanskii_stop\nStopping.goldstein","category":"page"},{"location":"api/#Stopping.armijo","page":"API","title":"Stopping.armijo","text":"`armijo(h::Any, h_at_t::OneDAtX{S, T}; τ₀::T = T(0.01), kwargs...) where {S, T}`\n\nCheck if a step size is admissible according to the Armijo criterion.\n\nArmijo criterion: f(x + θd) - f(x) - τ₀ θ ∇f(x+θd)d < 0\n\nThis function returns the maximum between the left-hand side and 0.\n\nNote: fx, f₀ and g₀ are required in the OneDAtX.\n\nSee also wolfe, armijo_wolfe, shamanskii_stop, goldstein\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.wolfe","page":"API","title":"Stopping.wolfe","text":"`wolfe(h::Any, h_at_t::OneDAtX{S, T}; τ₁::T = T(0.99), kwargs...) where {S, T}`\n\nCheck if a step size is admissible according to the Wolfe criterion.\n\nStrong Wolfe criterion: |∇f(x+θd)| - τ₁||∇f(x)|| < 0.\n\nThis function returns the maximum between the left-hand side and 0.\n\nNote: gx and g₀ are required in the OneDAtX.\n\nSee also armijo, armijo_wolfe, shamanskii_stop, goldstein\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.armijo_wolfe","page":"API","title":"Stopping.armijo_wolfe","text":"`armijo_wolfe(h::Any, h_at_t::OneDAtX{S, T}; τ₀::T = T(0.01), τ₁::T = T(0.99), kwargs...) where {S, T}`\n\nCheck if a step size is admissible according to the Armijo and Wolfe criteria.\n\nNote: fx, f₀, gx and g₀ are required in the OneDAtX.\n\nSee also armijo, wolfe, shamanskii_stop, goldstein\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.shamanskii_stop","page":"API","title":"Stopping.shamanskii_stop","text":"`shamanskii_stop(h :: Any, h_at_t :: OneDAtX; γ :: Float64 = 1.0e-09, kwargs...)`\n\nCheck if a step size is admissible according to the \"Shamanskii\" criteria.\n\nThis criteria was proposed in:\n\nLampariello, F., & Sciandrone, M. (2001). Global convergence technique for the Newton method with periodic Hessian evaluation. Journal of optimization theory and applications, 111(2), 341-358.\n\nNote: \n\nh.d accessible (specific LineModel).\nfx, f₀ are required in the OneDAtX.\n\nSee also armijo, wolfe, armijo_wolfe, goldstein\n\n\n\n\n\n","category":"function"},{"location":"api/#Stopping.goldstein","page":"API","title":"Stopping.goldstein","text":"`goldstein(h::Any, h_at_t::OneDAtX{S, T}; τ₀::T = T(0.0001), τ₁::T = T(0.9999), kwargs...) where {S, T}`\n\nCheck if a step size is admissible according to the Goldstein criteria.\n\nNote: fx, f₀ and g₀ are required in the OneDAtX.\n\nSee also armijo, wolfe, armijo_wolfe, shamanskii_stop\n\n\n\n\n\n","category":"function"},{"location":"uncons/#Unconstrained-solver","page":"Unconstrained optimization algorithm","title":"Unconstrained solver","text":"","category":"section"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"In this test problem, we consider a globalized Newton method. The scenario considers two different stopping criteria to solve the linesearch.","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"i) This example illustrates how the \"structure\" handling the algorithmic parameters can be passed to the solver of the subproblem.","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"ii) This algorithm handles a sub-stopping defined by passing the stopping as a keyword argument. Note that when a stopping is used multiple times, it has to be reinitialized.","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"iii) It also shows how we can reuse the information and avoid unnecessary evals. Here, the objective function of the main problem and sub-problem are the same. Warning: the structure onedoptim however does not allow keeping the gradient of the main problem. This issue can be corrected by using a specialized State.","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"contains the rosenbrock and backtracking_ls functions, and the onedoptim struct:","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"include(\"backls.jl\")","category":"page"},{"location":"uncons/#Newton-method-with-LineSearch","page":"Unconstrained optimization algorithm","title":"Newton method with LineSearch","text":"","category":"section"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"function global_newton(stp       :: NLPStopping,\n                       onedsolve :: Function,\n                       ls_func   :: Function;\n                       prms = nothing)\n\n    #Notations\n    state = stp.current_state; nlp = stp.pb\n    #Initialization\n    xt = state.x; d = zeros(size(xt))\n\n    #First call\n    OK = update_and_start!(stp, x = xt, fx = obj(nlp, xt),\n                                gx = grad(nlp, xt), Hx = hess(nlp, xt))\n\n    #Initialize the sub-Stopping with the main Stopping as keyword argument\n    h = onedoptim(x -> obj(nlp, xt + x * d),\n                  x -> dot(d, grad(nlp, xt + x * d)))\n    lsstp = LS_Stopping(h, ls_func, LSAtT(1.0), main_stp = stp)\n\n    #main loop\n    while !OK\n        #Compute the Newton direction\n        d = (state.Hx + state.Hx' - diagm(0 => diag(state.Hx))) \\ (-state.gx)\n\n        #Prepare the substopping\n        #We reinitialize the stopping before each new use\n        #rstate = true, force a reinialization of the State as well\n        reinit!(lsstp, rstate = true, x = 1.0, g₀=-dot(state.gx,d), h₀=state.fx)\n        lsstp.pb = onedoptim(x -> obj(nlp, xt + x * d),\n                             x -> dot(d, grad(nlp, xt + x * d)))\n\n        #solve subproblem\n        onedsolve(lsstp, prms)\n\n        if status(lsstp) == :Optimal\n         alpha = lsstp.current_state.x\n         #update\n         xt = xt + alpha * d\n         #Since the onedoptim and the nlp have the same objective function,\n         #we save one evaluation.\n         update!(stp.current_state, fx = lsstp.current_state.ht)\n        else\n         stp.meta.fail_sub_pb = true\n        end\n\n        OK = update_and_stop!(stp, x = xt, gx = grad(nlp, xt), Hx = hess(nlp, xt))\n\n    end\n\n    return stp\nend","category":"page"},{"location":"uncons/#Newton-method-with-LineSearch-2","page":"Unconstrained optimization algorithm","title":"Newton method with LineSearch","text":"","category":"section"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"Buffer version","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"function global_newton(stp :: NLPStopping, prms)\n\n lf = :ls_func   ∈ fieldnames(typeof(prms)) ? prms.ls_func : armijo\n os = :onedsolve ∈ fieldnames(typeof(prms)) ? prms.onedsolve : backtracking_ls\n\n return global_newton(stp, os, lf; prms = prms)\nend","category":"page"},{"location":"uncons/","page":"Unconstrained optimization algorithm","title":"Unconstrained optimization algorithm","text":"mutable struct PrmUn\n\n    #parameters of the unconstrained minimization\n    armijo_prm  :: Float64 #Armijo parameter\n    wolfe_prm   :: Float64 #Wolfe parameter\n    onedsolve   :: Function #1D solver\n    ls_func     :: Function\n\n    #parameters of the 1d minimization\n    back_update :: Float64 #backtracking update\n\n    function PrmUn(;armijo_prm  :: Float64 = 0.01,\n                    wolfe_prm   :: Float64 = 0.99,\n                    onedsolve   :: Function = backtracking_ls,\n                    ls_func     :: Function = (x,y)-> armijo(x,y, τ₀ = armijo_prm),\n                    back_update :: Float64 = 0.5)\n        return new(armijo_prm,wolfe_prm,onedsolve,ls_func,back_update)\n    end\nend","category":"page"},{"location":"index_tuto/#Stopping.jl","page":"Readme","title":"Stopping.jl","text":"","category":"section"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"Documentation for Stopping.jl","category":"page"},{"location":"index_tuto/#Purpose","page":"Readme","title":"Purpose","text":"","category":"section"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"Tools to ease the uniformization of stopping criteria in iterative solvers.","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"When a solver is called on an optimization model, four outcomes may happen:","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"the approximate solution is obtained, the problem is considered solved\nthe problem is declared unsolvable (unboundedness, infeasibility ...)\nthe maximum available resources are not sufficient to compute the solution\nsome algorithm dependent failure happens","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"This tool eases the first three items above. It defines a type","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"mutable struct GenericStopping <: AbstractStopping\n    problem       :: Any                  # an arbitrary instance of a problem\n    meta          :: AbstractStoppingMeta # contains the used parameters and stopping status\n    current_state :: AbstractState        # Current information on the problem\n    main_stp :: Union{AbstractStopping, Nothing} # Stopping of the main problem, or nothing\n    listofstates :: Union{ListStates, Nothing}   # History of states\n    user_specific_struct :: Any                  # User-specific structure","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"The StoppingMeta provides default tolerances, maximum resources, ...  as well as (boolean) information on the result.","category":"page"},{"location":"index_tuto/#Your-Stopping-your-way","page":"Readme","title":"Your Stopping your way","text":"","category":"section"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"The GenericStopping (with GenericState) provides a complete structure to handle stopping criteria. Then, depending on the problem structure, you can specialize a new Stopping by redefining a State and some functions specific to your problem.","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"We provide some specialization of the GenericStopping for optimization:","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"NLPStopping with NLPAtX as a specialized State: for non-linear programming (based on NLPModels);\nLAStopping with GenericState: for linear algebra problems.\nLS_Stopping with LSAtT as a specialized State: for 1d optimization;\nmore to come...","category":"page"},{"location":"index_tuto/#Functions","page":"Readme","title":"Functions","text":"","category":"section"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"The tool provides two main functions:","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"start!(stp :: AbstractStopping) initializes the time and the tolerance at the starting point and check wether the initial guess is optimal.\nstop!(stp :: AbstractStopping) checks optimality of the current guess as well as failure of the system (unboundedness for instance) and maximum resources (number of evaluations of functions, elapsed time ...)","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"Stopping uses the informations furnished by the State to evaluate its functions. Communication between the two can be done through the following functions:","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"update_and_start!(stp :: AbstractStopping; kwargs...) updates the states with informations furnished as kwargs and then call start!.\nupdate_and_stop!(stp :: AbstractStopping; kwargs...) updates the states with informations furnished as kwargs and then call stop!.\nfill_in!(stp :: AbstractStopping, x :: Iterate) a function that fill in all the State with all the informations required to correctly evaluate the stopping functions. This can reveal useful, for instance, if the user do not trust the informations furnished by the algorithm in the State.\nreinit!(stp :: AbstractStopping) reinitialize the entries of","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"the Stopping to reuse for another call.","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"Consult the HowTo tutorial to learn more about the possibilities offered by Stopping.","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"You can also access other examples of algorithms in the test/examples folder, which for instance illustrate the strenght of Stopping with subproblems:","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"Consult the OptimSolver tutorial for more on how to use Stopping with nested algorithms.\nCheck the Benchmark tutorial to see how Stopping can combined with SolverBenchmark.jl.\nStopping can be adapted to closed solvers via a buffer function as in Buffer tutorial for an instance with Ipopt via NLPModelsIpopt.","category":"page"},{"location":"index_tuto/#How-to-install","page":"Readme","title":"How to install","text":"","category":"section"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"Install and test the Stopping package with the Julia package manager:","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"pkg> add Stopping\npkg> test Stopping","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"You can access the most up-to-date version of the Stopping package using:","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"pkg> add https://github.com/vepiteski/Stopping.jl\npkg> test Stopping\npkg> status Stopping","category":"page"},{"location":"index_tuto/#Example","page":"Readme","title":"Example","text":"","category":"section"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"As an example, a naive version of the Newton method is provided here. First we import the packages:","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"using LinearAlgebra, NLPModels, Stopping","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"We consider a quadratic test function, and create an uncontrained quadratic optimization problem using NLPModels:","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"A = rand(5, 5); Q = A' * A;\nf(x) = 0.5 * x' * Q * x\nnlp = ADNLPModel(f,  ones(5))","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"We now initialize the NLPStopping. First create a State.","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"nlp_at_x = NLPAtX(ones(5))","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"We use unconstrained_check as an optimality function","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"stop_nlp = NLPStopping(nlp, nlp_at_x, optimality_check = unconstrained_check)","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"Note that, since we used a default State, an alternative would have been:","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"stop_nlp = NLPStopping(nlp)","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"Now a basic version of Newton to illustrate how to use Stopping.","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"function newton(stp :: NLPStopping)\n\n    #Notations\n    pb = stp.pb; state = stp.current_state;\n    #Initialization\n    xt = state.x\n\n    #First, call start! to check optimality and set an initial configuration\n    #(start the time counter, set relative error ...)\n    OK = update_and_start!(stp, x = xt, gx = grad(pb, xt), Hx = hess(pb, xt))\n\n    while !OK\n        #Compute the Newton direction (state.Hx only has the lower triangular)\n        d = (state.Hx + state.Hx' - diagm(0 => diag(state.Hx))) \\ (- state.gx)\n        #Update the iterate\n        xt = xt + d\n        #Update the State and call the Stopping with stop!\n        OK = update_and_stop!(stp, x = xt, gx = grad(pb, xt), Hx = hess(pb, xt))\n    end\n\n    return stp\nend","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"Finally, we can call the algorithm with our Stopping:","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"stop_nlp = newton(stop_nlp)","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"and consult the Stopping to know what happened","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"#We can then ask stop_nlp the final status\n@test :Optimal in status(stop_nlp, list = true)\n#Explore the final values in stop_nlp.current_state\nprintstyled(\"Final solution is $(stop_nlp.current_state.x)\", color = :green)","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"We reached optimality, and thanks to the Stopping structure this simple looking algorithm verified at each step of the algorithm:","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"time limit has been respected;\nevaluations of the problem are not excessive;\nthe problem is not unbounded (w.r.t. x and f(x));\nthere is no NaN in x, f(x), g(x), H(x);\nthe maximum number of iteration (call to stop!) is limited.","category":"page"},{"location":"index_tuto/#Long-Term-Goals","page":"Readme","title":"Long-Term Goals","text":"","category":"section"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"Stopping is aimed as a tool for improving the reusability and robustness in the implementation of iterative algorithms. We warmly welcome any feedback or comment leading to potential improvements.","category":"page"},{"location":"index_tuto/","page":"Readme","title":"Readme","text":"Future work will address more sophisticated problems such as mixed-integer optimization problems, optimization with uncertainty. The list of suggested optimality functions will be enriched with state of the art conditions.","category":"page"},{"location":"linear-algebra/#Stopping-for-Linear-Algebra","page":"Solve linear algebra","title":"Stopping for Linear Algebra","text":"","category":"section"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"The Stopping structure eases the implementation of algorithms and the stopping criterion.","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"The following examples illustrate solver for linear algebra:","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"Ax = b ","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"where A is an m x n matrix and b a vector of size m.","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"This tutorial illustrates the different step in preparing the resolution of a new problem.","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"we create a LinearAlgebraProblem (that stores A, b)\nwe use the GenericState storing x and the current_time\nwe create a LinearAlgebraStopping\nthe optimality function linear_system_check!","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"using LinearAlgebra, Stopping, Test","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"m, n = 400, 200 #size of A: m x n\nA    = 100 * rand(m, n)\nxref = 100 * rand(n)\nb    = A * xref\n\n#Our initial guess\nx0 = zeros(n)","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"mutable struct LinearAlgebraProblem\n    A :: Any #matrix type\n    b :: Vector\nend","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"la_pb = LinearAlgebraProblem(A, b)\nla_state = GenericState(xref)\n\n@test norm(la_pb.A * xref - la_pb.b) <= 1e-6","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"mutable struct LinearAlgebraStopping <: AbstractStopping\n\n        # problem\n        pb :: LinearAlgebraProblem\n\n        # stopping criterion\n        optimality_check :: Function\n\n        # Common parameters\n        meta :: AbstractStoppingMeta\n\n        # current state of the problem\n        current_state :: AbstractState\n\n        # Stopping of the main problem, or nothing\n        main_stp :: Union{AbstractStopping, Nothing}\n\n        function LinearAlgebraStopping(pb               :: LinearAlgebraProblem,\n                                       optimality_check :: Function,\n                                       current_state    :: AbstractState; kwargs...)\n         return new(pb, linear_system_check!, StoppingMeta(; kwargs...), la_state, nothing)\n        end\nend\n\nimport Stopping._optimality_check\n\nfunction _optimality_check(stp  :: LinearAlgebraStopping; kwargs...)\n\n optimality = stp.optimality_check(stp.pb, stp.current_state; kwargs...)\n\n return optimality\nend\n","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"function linear_system_check!(pb    :: LinearAlgebraProblem,\n                              state :: AbstractState; kwargs...)\n return norm(pb.A * state.x - pb.b)\nend\n\n@test linear_system_check!(la_pb, la_state) == 0.0\nupdate!(la_state, x = x0)\n@test linear_system_check!(la_pb, la_state) != 0.0\n\nla_stop = LinearAlgebraStopping(la_pb, linear_system_check!, la_state,\n                                max_iter = 150000, rtol = 1e-6)","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"Randomized block Kaczmarz","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"function RandomizedBlockKaczmarz(stp :: AbstractStopping; kwargs...)\n\n    A,b = stp.pb.A, stp.pb.b\n    x0  = stp.current_state.x\n\n    m,n = size(A)\n    xk  = x0\n\n    OK = start!(stp)\n\n    while !OK\n\n     i  = Int(floor(rand() * m)+1) #rand a number between 1 and m\n     Ai = A[i,:]\n     xk  = Ai == 0 ? x0 : x0 - (dot(Ai,x0)-b[i])/dot(Ai,Ai) * Ai\n\n     OK = update_and_stop!(stp, x = xk)\n     x0  = xk\n\n    end\n\n return stp\nend","category":"page"},{"location":"linear-algebra/","page":"Solve linear algebra","title":"Solve linear algebra","text":"RandomizedBlockKaczmarz(la_stop)\n@test status(la_stop) == :Optimal","category":"page"},{"location":"idcard/#Stopping","page":"Stopping's ID","title":"Stopping","text":"","category":"section"},{"location":"idcard/","page":"Stopping's ID","title":"Stopping's ID","text":"A Stopping is an instance (a subtype) of an AbstractStopping. Such instances minimally contain:","category":"page"},{"location":"idcard/","page":"Stopping's ID","title":"Stopping's ID","text":"problem :: Any an arbitrary instance of a problem;\nmeta :: AbstractStoppingMeta contains the used parameters and stopping statuses;\ncurrent_state :: AbstractState current information/state of the problem.","category":"page"},{"location":"idcard/","page":"Stopping's ID","title":"Stopping's ID","text":"While the problem is up to the user, the meta and the current_state are specific features of Stopping.jl. The meta contains all the parameters relative to the stopping criteria (tolerances, limits ...). We implemented StoppingMeta() which offers a set of default parameters that can be easily modified with keyword arguments. See StoppingMeta for more detailed information. The native instances of AbstractStopping (GenericStopping, NLPStoppping, etc) contains more attributes (stop_remote, main_stp, listofstates, stopping_user_struct) that we will developed later on.","category":"page"},{"location":"idcard/","page":"Stopping's ID","title":"Stopping's ID","text":"The current_state contains all the information relative to a problem. We implemented a GenericState as an illustration of the behavior of such object that typically contains:","category":"page"},{"location":"idcard/","page":"Stopping's ID","title":"Stopping's ID","text":"x the current iterate;\nd the current direction;\nres the current residual;\ncurrent_time the current time;\ncurrent_score the current optimality score;\n... other information relative to the problems.","category":"page"},{"location":"idcard/","page":"Stopping's ID","title":"Stopping's ID","text":"When running the iterative loop, the State is updated and the Stopping make a decision based on this information.","category":"page"},{"location":"idcard/#Main-Methods","page":"Stopping's ID","title":"Main Methods","text":"","category":"section"},{"location":"idcard/","page":"Stopping's ID","title":"Stopping's ID","text":"Stopping's main behavior is represented by two functions:","category":"page"},{"location":"idcard/","page":"Stopping's ID","title":"Stopping's ID","text":"start!(:: AbstractStopping) initializes the time and the tolerance at the starting point and stopping criteria.\nstop!(:: AbstractStopping) checks stopping criteria","category":"page"},{"location":"idcard/","page":"Stopping's ID","title":"Stopping's ID","text":"Stopping uses the information furnished by the State to make a decision. Communication between the two can be done through the following functions:","category":"page"},{"location":"idcard/","page":"Stopping's ID","title":"Stopping's ID","text":"update_and_start!(stp :: AbstractStopping; kwargs...) updates the states with information furnished as kwargs and then call start!.\nupdate_and_stop!(stp :: AbstractStopping; kwargs...) updates the states with information furnished as kwargs and then call stop!.\nfill_in!(stp :: AbstractStopping, x :: xtype(stp.current_state)) a function that fills in all the State with all the information required to evaluate the stopping functions correctly. This can reveal useful, for instance, if the user do not trust the information furnished by the algorithm in the State.\nreinit!(stp :: AbstractStopping) reinitialize the entries of the Stopping to reuse for another call.","category":"page"},{"location":"idcard/#FAQ:-How-do-I-get-more-information?","page":"Stopping's ID","title":"FAQ: How do I get more information?","text":"","category":"section"},{"location":"idcard/","page":"Stopping's ID","title":"Stopping's ID","text":"As usual in Julia, we can use ? to get functions' documentation.","category":"page"},{"location":"idcard/","page":"Stopping's ID","title":"Stopping's ID","text":"? Stopping.stop!","category":"page"},{"location":"howtostop-nlp/#How-to-Stop-for-NLPs","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"","category":"section"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"The Stopping structure eases the implementation of algorithms and the stopping criterion.","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"We illustrate here the basic features of NLPStopping, which is a specialized version of the Stopping to the case where: pb is an AbstractNLPModel state shares the structure of the NLPAtX.","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"NLPModels is a package to handle non-linear (constrained) optimization. NLPStopping is following this approach.","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"using Test, NLPModels, Stopping","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"We first create a toy problem","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"f(x) = sum(x.^2)\nx0 = zeros(5)\nnlp = ADNLPModel(f, x0)\nnlp2 = ADNLPModel(f, x0, lvar = zeros(5), uvar = Inf * ones(5))\nnlp_at_x = NLPAtX(x0)\nx1 = ones(5)","category":"page"},{"location":"howtostop-nlp/#)-Initialize-the-NLPStopping.","page":"How to Stop for NLPs","title":"1) Initialize the NLPStopping.","text":"","category":"section"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"The specificity here is that the NLPStopping requires another mandatory input: optimality_check which is the function later used to compute the score. Recall that the score is then tested at 0, to declare optimality. Stopping provides a default KKT function.","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"stop_nlp = NLPStopping(nlp, (x,y) -> KKT(x,y), nlp_at_x)","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"Another approach is to use the lazy way:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"stop_nlp_lazy = NLPStopping(nlp2) #use nlp.meta.x0 as initial point\n@test stop_nlp_lazy.current_state.x == nlp2.meta.x0","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"###2) Fill in Before calling start! and stop! one should fill in current information in the State. -> the optimalitycheck then exploits this knowledge. As seen before, we by hand use updateandstart and updateandstop. Another way is to call the fillin! function:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"fill_in!(stop_nlp, x1, matrix_info = false)\n@test stop_nlp.current_state.x  == x1\n@test stop_nlp.current_state.fx == 5.\n@test stop_nlp.current_state.Hx == nothing","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"Note that since there are no constraints, c(x) and J(x) are not called:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"@test stop_nlp.current_state.Jx == nothing\n@test stop_nlp.current_state.cx == nothing","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"Since there are no bounds on x, the Lagrange multiplier is not updated:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"@test stop_nlp.current_state.mu == nothing","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"would give Hx if matrix_info = true","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"fill_in!(stop_nlp_lazy, x1)\n@test stop_nlp_lazy.current_state.Hx != nothing\n#stop_nlp_lazy.pb has bounds, so mu is a vector of size x\n@test size(x0) == size(stop_nlp_lazy.current_state.mu)","category":"page"},{"location":"howtostop-nlp/#)-Evaluations","page":"How to Stop for NLPs","title":"3) Evaluations","text":"","category":"section"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"Another particularity is that the NLPModels has a counter keeping track of the evaluations of each function. Similarly the NLPStopping has a dictionary keeping all the maximum number of evaluations:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"@test typeof(stop_nlp.max_cntrs) <: Dict\n#For instance the limit in evaluations of objective and gradient:\n@test stop_nlp.max_cntrs[:neval_obj] == 20000\n@test stop_nlp.max_cntrs[:neval_grad] == 20000","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"Limit can be set using initmaxcounters function:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"stop_nlp.max_cntrs = init_max_counters(obj = 3, grad = 0, hess = 0)\n@test stop_nlp.max_cntrs[:neval_obj] == 3\n@test stop_nlp.max_cntrs[:neval_grad] == 0\n\nOK = update_and_stop!(stop_nlp, evals = stop_nlp.pb.counters)\n@test OK == true\n@test stop_nlp.meta.resources == true\n@test status(stop_nlp) == :ResourcesExhausted","category":"page"},{"location":"howtostop-nlp/#)-Unbounded-problem","page":"How to Stop for NLPs","title":"4) Unbounded problem","text":"","category":"section"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"An additional feature of the NLPStopping is to provide an _unboundedproblemcheck whenever \\|c(x)\\| or -f(x) become too large.","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"stop_nlp.meta.unbounded_threshold = - 1.0 #by default 1.0e50\nstop!(stop_nlp)\n@test stop_nlp.meta.unbounded_pb == true\n@test stop_nlp.current_state.fx > stop_nlp.meta.unbounded_threshold\n@test stop_nlp.meta.resources == true #still true as the state has not changed","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"An advanced feature is the possibility to send keywords to optimality_check:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"optimality_fct_test = (x,y;a = 1.0) -> a","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"In this case, the optimality_check function used to compute the score may depend on a parameter (algorithm-dependent for instance)","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"stop_nlp_2 = NLPStopping(nlp, optimality_fct_test, nlp_at_x)\nfill_in!(stop_nlp_2, x0)\n\nOK = stop!(stop_nlp_2, a = 0.0)\n@test OK == true\n@test stop_nlp_2.meta.optimal == true","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"However, note that the same cannot be achieved with updateandstop!:","category":"page"},{"location":"howtostop-nlp/","page":"How to Stop for NLPs","title":"How to Stop for NLPs","text":"reinit!(stop_nlp_2)\nOK = update_and_stop!(stop_nlp_2, a = 0.0)\n@test OK == false","category":"page"},{"location":"backls/#Backtracking-Linesearch","page":"Backtracking linesearch algorithm","title":"Backtracking Linesearch","text":"","category":"section"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"In this test problem, we consider a backtracking algorithm for 1D optimization. The scenario considers three different stopping criterion to solve a specific problem.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"This example illustrates how to use a \"structure\" to handle the algorithmic parameters and unify the input. The function backtrackingls(stp :: LSStopping, prms) serves as a buffer for the real algorithm in the function backtrackingls(stp :: LSStopping; back_update :: Float64 = 0.5, prms = nothing)","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"It also shows that obsolete information in the State (after an update of x) must be removed by the algorithm. Otherwise, the optimality_check function cannot make the difference between valid and invalid entries.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"We create a basic structure to handle 1D optimization.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"We can also use the LineModel available in https://github.com/JuliaSmoothOptimizers/SolverTools.jl","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"mutable struct onedoptim\n    f :: Function\n    g :: Function\nend","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"We specialize three optimality_check functions for 1D optimization to the onedoptim type of problem.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"The default functions do not fill in automatically the necessary entries.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"import Stopping: armijo, wolfe, armijo_wolfe\n\nfunction armijo(h :: onedoptim, h_at_t :: LSAtT; τ₀ :: Float64 = 0.01, kwargs...)\n\n h_at_t.ht = h_at_t.ht == nothing ? h.f(h_at_t.x) : h_at_t.ht\n h_at_t.h₀ = h_at_t.h₀ == nothing ? h.f(0) : h_at_t.h₀\n h_at_t.g₀ = h_at_t.g₀ == nothing ? h.g(0) : h_at_t.g₀\n\n hgoal = h_at_t.ht - h_at_t.h₀ - h_at_t.g₀ * h_at_t.x * τ₀\n\n return max(hgoal, 0.0)\nend\n\nfunction wolfe(h :: onedoptim, h_at_t :: LSAtT; τ₁ :: Float64 = 0.99, kwargs...)\n\n h_at_t.gt = h_at_t.gt == nothing ? h.g(h_at_t.x) : h_at_t.gt\n h_at_t.g₀ = h_at_t.g₀ == nothing ? h.g(0) : h_at_t.g₀\n\n wolfe = τ₁ .* h_at_t.g₀ - abs(h_at_t.gt)\n return max(wolfe, 0.0)\nend\n\nfunction armijo_wolfe(h :: onedoptim, h_at_t :: LSAtT; τ₀ :: Float64 = 0.01, τ₁ :: Float64 = 0.99, kwargs...)\n\n h_at_t.ht = h_at_t.ht == nothing ? h.f(h_at_t.x) : h_at_t.ht\n h_at_t.h₀ = h_at_t.h₀ == nothing ? h.f(0) : h_at_t.h₀\n h_at_t.gt = h_at_t.gt == nothing ? h.g(h_at_t.x) : h_at_t.gt\n h_at_t.g₀ = h_at_t.g₀ == nothing ? h.g(0) : h_at_t.g₀\n\n return max(armijo(h, h_at_t, τ₀ = τ₀),wolfe(h, h_at_t, τ₁ = τ₁), 0.0)\nend","category":"page"},{"location":"backls/#backtracking-LineSearch","page":"Backtracking linesearch algorithm","title":"backtracking LineSearch","text":"","category":"section"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"The problem (stp.pb) is the 1d objective function","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"Requirement: g0 and h0 have been filled in the State.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"function backtracking_ls(stp :: LS_Stopping;\n                         back_update :: Float64 = 0.5,\n                         prms = nothing)\n\n state = stp.current_state; xt = state.x;\n\n #First call to stopping\n OK = start!(stp)\n\n #main loop\n while !OK\n\n  xt = xt * back_update\n\n  #after update the infos in the State are no longer valid (except h₀, g₀)\n  reinit!(state, xt, h₀ = stp.current_state.h₀, g₀ = stp.current_state.g₀)\n\n  #we call the stop!\n  OK = stop!(stp)\n\n end\n\n return stp\nend","category":"page"},{"location":"backls/#Buffer-to-handle-a-structure-containing-the-algorithmic-parameters.","page":"Backtracking linesearch algorithm","title":"Buffer to handle a structure containing the algorithmic parameters.","text":"","category":"section"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"function backtracking_ls(stp :: LS_Stopping, prms)\n\n #extract required values in the prms file\n bu = :back_update   ∈ fieldnames(typeof(prms)) ? prms.back_update : 0.5\n\n return backtracking_ls(stp :: LS_Stopping, back_update = bu; prms = prms)\nend","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"Scenario: optimization of the rosenbrock function at x0 along the opposite of the gradient.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"We also store all the algorithmic parameters in a structure.","category":"page"},{"location":"backls/","page":"Backtracking linesearch algorithm","title":"Backtracking linesearch algorithm","text":"mutable struct ParamLS\n\n    #parameters of the 1d minimization\n    back_update :: Float64 #backtracking update\n\n    function ParamLS(;back_update :: Float64 = 0.1)\n        return new(back_update)\n    end\nend","category":"page"},{"location":"example-basic-Newton/#Example-I:-Stopping-in-the-flow","page":"Stopping in action","title":"Example I: Stopping in the flow","text":"","category":"section"},{"location":"example-basic-Newton/","page":"Stopping in action","title":"Stopping in action","text":"We present here a typical iterative algorithm to illustrate how to use Stopping.","category":"page"},{"location":"example-basic-Newton/","page":"Stopping in action","title":"Stopping in action","text":"function rand_solver(stp :: AbstractStopping, x0 :: AbstractVector)\n\n    x = x0\n    #First, call start! to check optimality and set an initial configuration\n    OK = update_and_start!(stp, x = x)\n\n    while !OK\n        #Run some computations and update the iterate\n        d = rand(length(x))\n        x += d\n\n        #Update the State and call the Stopping with stop!\n        OK = update_and_stop!(stp, x = x, d = d)\n    end\n\n    return stp\nend","category":"page"},{"location":"example-basic-Newton/","page":"Stopping in action","title":"Stopping in action","text":"This example shows the most basic features of Stopping. It does many checks for you. In this innocent-looking algorithm, the call to update_and_start! and update_and_stop! will verifies unboundedness of x, the time spent in the algorithm, the number of iterations (= number of call to stop!), and the domain of x (in case some of its components become NaN for instance).","category":"page"},{"location":"example-basic-Newton/#FAQ:-How-can-I-disable-some-checks-done-by-Stopping?","page":"Stopping in action","title":"FAQ: How can I disable some checks done by Stopping?","text":"","category":"section"},{"location":"example-basic-Newton/","page":"Stopping in action","title":"Stopping in action","text":"The native instances of AbstractStopping available in Stopping.jl all contain an attribute stop_remote. This is a remote control for Stopping's checks.","category":"page"},{"location":"example-basic-Newton/","page":"Stopping in action","title":"Stopping in action","text":"typeof(stp.stop_remote) <: StopRemoteControl #stop_remote is an instance of StopRemoteControl","category":"page"},{"location":"example-basic-Newton/","page":"Stopping in action","title":"Stopping in action","text":"This attributes contains boolean values for each check done by Stopping, see","category":"page"},{"location":"example-basic-Newton/","page":"Stopping in action","title":"Stopping in action","text":"fieldnames(stp.stop_remote) #get all the attributes of the remote control","category":"page"},{"location":"example-basic-Newton/","page":"Stopping in action","title":"Stopping in action","text":"For instance, we can remove the unboundedness and domain check done on x by setting:","category":"page"},{"location":"example-basic-Newton/","page":"Stopping in action","title":"Stopping in action","text":"stp.stop_remote = StopRemoteControl(unbounded_and_domain_x_check = false)","category":"page"},{"location":"idcard-stoppingmeta/#Stopping's-attributes-ID:-StoppingMeta","page":"Meta's ID","title":"Stopping's attributes ID: StoppingMeta","text":"","category":"section"},{"location":"idcard-stoppingmeta/","page":"Meta's ID","title":"Meta's ID","text":"Usual instances of AbstractStopping contains a StoppingMeta <: AbstractStoppingMeta (stp.meta), which controls the various tolerances and thresholds used by the functions start! and stop!.","category":"page"},{"location":"idcard-stoppingmeta/","page":"Meta's ID","title":"Meta's ID","text":"atol                :: Number   = 1.0e-6\nrtol                :: Number   = 1.0e-15\noptimality0         :: Number   = 1.0\ntol_check           :: Function = (atol :: Number, rtol :: Number, opt0 :: Number) -> max(atol,rtol*opt0)\ntol_check_neg       :: Function = (atol :: Number, rtol :: Number, opt0 :: Number) -> - tol_check(atol,rtol,opt0)\noptimality_check    :: Function = (a,b) -> Inf\nrecomp_tol          :: Bool     = true\nunbounded_threshold :: Number   = 1.0e50, #typemax(Float64)\nunbounded_x         :: Number   = 1.0e50\nmax_f               :: Int      = typemax(Int)\nmax_cntrs           :: Dict{Symbol,Int} = Dict{Symbol,Int64}()\nmax_eval            :: Int      = 20000\nmax_iter            :: Int      = 5000\nmax_time            :: Float64  = 300.0\nstart_time          :: Float64  = NaN\nmeta_user_struct    :: Any      = nothing\nuser_check_func!    :: Function = (stp :: AbstractStopping, start :: Bool) -> nothing","category":"page"},{"location":"idcard-stoppingmeta/","page":"Meta's ID","title":"Meta's ID","text":"The default constructor for the meta uses above values, and they can all be modified using keywords","category":"page"},{"location":"idcard-stoppingmeta/","page":"Meta's ID","title":"Meta's ID","text":"meta = StoppingMeta(rtol = 0.0) #will set `rtol` as 0.0.","category":"page"},{"location":"idcard-stoppingmeta/","page":"Meta's ID","title":"Meta's ID","text":"StoppingMeta also contains the various status related to the checks:","category":"page"},{"location":"idcard-stoppingmeta/","page":"Meta's ID","title":"Meta's ID","text":"OK_check(meta) #returns true if one of the check is true.","category":"page"},{"location":"idcard-stoppingmeta/#FAQ:-Are-there-Type-constraints-when-initializing-a-StoppingMeta?","page":"Meta's ID","title":"FAQ: Are there Type constraints when initializing a StoppingMeta?","text":"","category":"section"},{"location":"idcard-stoppingmeta/","page":"Meta's ID","title":"Meta's ID","text":"An StoppingMeta{TolType, CheckType, MUS, IntType} is actually a paramtric type:","category":"page"},{"location":"idcard-stoppingmeta/","page":"Meta's ID","title":"Meta's ID","text":"checktype(meta) #CheckType: return type of `tol_check` and `tol_check_neg` \ntoltype(meta) #TolType: type of the tolerances\nmetausertype(meta) #MUS: type of the user-defined structure\ninttype(meta) #IntType: type of integer tolerances","category":"page"},{"location":"idcard-stoppingmeta/#FAQ:-What-is-user_check_func!?","page":"Meta's ID","title":"FAQ: What is user_check_func!?","text":"","category":"section"},{"location":"idcard-stoppingmeta/","page":"Meta's ID","title":"Meta's ID","text":"This is a callback function called in the execution of the function stop! or start!. This function takes two input stp <: AbstractStopping and a boolean set as true if called from start! and false if called from stop!. To eventually returns a stopping status, the function has to update stp.meta.stopbyuser.","category":"page"},{"location":"idcard-stoppingmeta/","page":"Meta's ID","title":"Meta's ID","text":"For instance, if one want to stop when log(x)  1 in stop!:","category":"page"},{"location":"idcard-stoppingmeta/","page":"Meta's ID","title":"Meta's ID","text":"function test(stp, start)\n  stp.meta.stopbyuser = !start && (log(stp.current_state.x) < 1)\nend\nuser_check_func! = test","category":"page"},{"location":"idcard-stoppingmeta/","page":"Meta's ID","title":"Meta's ID","text":"The exclamation mark (!) is a naming convention used when the function modifies input.","category":"page"},{"location":"active-set/#Active-set-algorithm","page":"Active set algorithm","title":"Active set algorithm","text":"","category":"section"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"In this test problem we consider an active-set method.","category":"page"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"Note that there is no optimization of the evaluations here.","category":"page"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"Note the use of a structure for the algorithmic parameters which is forwarded to all the 3 steps. If a parameter is not mentioned, then the default entry in the algorithm will be taken.","category":"page"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"include(\"penalty.jl\")","category":"page"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"First, we create a subtype of AbstractNLPModel to represent the unconstrained subproblem we \"solve\" at each iteration of the activeset.","category":"page"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"import NLPModels: obj, grad, hess, hprod\n\nmutable struct ActifNLP <: AbstractNLPModel\n nlp :: AbstractNLPModel\n x0  :: Vector #reference vector\n I   :: Vector #set of active indices\n Ic  :: Vector #set of inactive indices\n meta :: AbstractNLPModelMeta\n counters :: Counters\nend\n\nfunction obj(anlp :: ActifNLP, x :: Vector) t=anlp.x0;t[anlp.Ic]=x; return obj(anlp.nlp, t) end\nfunction grad(anlp :: ActifNLP, x :: Vector) t=anlp.x0;t[anlp.Ic]=x; return grad(anlp.nlp, t)[anlp.Ic] end\nfunction hess(anlp :: ActifNLP, x :: Vector) t=anlp.x0;t[anlp.Ic]=x; return hess(anlp.nlp, t)[anlp.Ic,anlp.Ic] end\nfunction hprod(anlp :: ActifNLP, x :: Vector, v :: Vector, y :: Vector) return hess(anlp, x) * v end","category":"page"},{"location":"active-set/#Active-set-algorithm-for-bound-constraints-optimization","page":"Active set algorithm","title":"Active-set algorithm for bound constraints optimization","text":"","category":"section"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"fill_in! used instead of update! (works but usually more costly in evaluations) subproblems are solved via Newton method","category":"page"},{"location":"active-set/","page":"Active set algorithm","title":"Active set algorithm","text":"function activeset(stp :: NLPStopping;\n                   active :: Float64 = stp.meta.tol_check(stp.meta.atol,stp.meta.rtol,stp.meta.optimality0),\n                   prms = nothing)\n\n xt = stp.current_state.x; n = length(xt); all = findall(xt .== xt)\n\n if maximum(vcat(max.(xt  - stp.pb.meta.uvar,0.0),max.(- xt  + stp.pb.meta.lvar,0.0))) > 0.0\n  #OK = true; stp.meta.fail_sub_pb = true\n  #xt is not feasible\n  xt = max.(min.(stp.current_state.x,  stp.pb.meta.uvar),  stp.pb.meta.lvar)\n end\n\n fill_in!(stp, xt)\n OK = start!(stp)\n\n Il = findall(abs.(- xt  + stp.pb.meta.lvar).<= active)\n Iu = findall(abs.(  xt  - stp.pb.meta.uvar).<= active)\n I = union(Il, Iu); Ic = setdiff(all, I)\n nI = max(0, length(xt) - length(Il) - length(Iu)) #lvar_i != uvar_i\n@show xt, I\nwhile !OK\n\n   #prepare the subproblem stopping:\n   subpb = ActifNLP(nlp, xt, I, Ic, NLPModelMeta(nI), Counters())\n   #the subproblem stops if he solved the unconstrained nlp or iterate is infeasible\n   feas(x,y) = maximum(vcat(max.(y.x  - stp.pb.meta.uvar[Ic],0.0),max.(- y.x  + stp.pb.meta.lvar[Ic],0.0)))\n   check_func(x,y) = feas(x,y) > 0.0 ? 0.0 : unconstrained_check(x,y)\n   substp = NLPStopping(subpb, check_func, NLPAtX(xt[Ic]), main_stp = stp)\n\n   #we solve the unconstrained subproblem:\n   global_newton(substp, prms)\n   @show status(substp, list = true)\n\n   if feas(substp.pb, substp.current_state) > 0.0 #new iterate is infeasible\n     #then we need to project\n     xt[Ic] = max.(min.(substp.current_state.x,  stp.pb.meta.uvar[Ic]),  stp.pb.meta.lvar[Ic])\n     #we keep track of the new active indices\n     Inew = setdiff(union(findall(abs.(- xt  + stp.pb.meta.lvar).<= active), findall(abs.(  x0  - stp.pb.meta.uvar).<= active)), I)\n   else\n     Inew = []\n   end\n\n   fill_in!(stp, xt) #the lazy update\n\n   OK = update_and_stop!(stp, evals = stp.pb.counters)\n\n   if !OK #we use a relaxation rule based on an approx. of Lagrange multipliers\n     Irmv = findall(stp.current_state.mu .<0.0)\n     I = union(setdiff(I, Irmv), Inew)\n     Ic = setdiff(all, I)\n   end\n @show xt, I\n end #end of main loop\n\n return stp\nend","category":"page"},{"location":"nlpstopping/#NLPStopping:-A-Stopping-for-NLPModels","page":"NLPStopping","title":"NLPStopping: A Stopping for NLPModels","text":"","category":"section"},{"location":"nlpstopping/","page":"NLPStopping","title":"NLPStopping","text":"The Stopping-structure can be adapted to any problem solved by iterative methods. We discuss here NLPStopping a specialization of an AbstractStopping for problems of type NLPModels. We highlight here the specifities of such instance:","category":"page"},{"location":"nlpstopping/","page":"NLPStopping","title":"NLPStopping","text":"The problem is an NLPModel\nThe problem has a funcion-evaluation counter, so we setup a maximum-counters structure in the meta.\nThe State is an NLPAtX with entries corresponding to usual information for nonlinear optimization models.\nThe unboundedness check verifies that the objective function is unbounded below for minimization problems, and above for maximization;\nThe problem is declared infeasibility if the score is Inf for minimization problems, and -Inf for maximization.","category":"page"},{"location":"nlpstopping/","page":"NLPStopping","title":"NLPStopping","text":"nlp = ADNLPModel(x->sum(x.^2), zeros(5))\nnlp_at_x = NLPAtX(zeros(5))\nmeta  = StoppingMeta(max_cntrs = init_max_counters())\nstp   = NLPStopping(pb, meta, state)","category":"page"},{"location":"nlpstopping/","page":"NLPStopping","title":"NLPStopping","text":"By default for NLPStopping the optimality function is a function checking the KKT conditions using information in the State. The function fill_in! computes all the missing entries in the State. This is an potentially expensive operation, but might be useful.","category":"page"},{"location":"howtostop-2/#How-to-Stop-2","page":"How to Stop 2","title":"How to Stop 2","text":"","category":"section"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"The Stopping structure eases the implementation of algorithms and the stopping criterion. We illustrate here the features of Stopping when the algorithm is used a subStopping.","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"using Test, Stopping","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"Assume we want to solve \"pb\" starting from \"x0\" and solving at each step of the algorithm the subproblem \"subpb\".  We can use this additional info to improve the stopping criterion.","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"x0 = ones(2)\npb = nothing\nsubpb = nothing\nsubsubpb = nothing","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"Initialize a Stopping for the main pb","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"main_stop = GenericStopping(pb, x0)","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"We can then, initialize another stopping to the subproblem, and providing the main_stop as a keyword argument:","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"sub_stop = GenericStopping(subpb, x0, main_stp = main_stop, tol_check = (atol, rtol, opt0) -> atol)","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"Note that by default main_stp is void","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"@test main_stop.main_stp == nothing","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"The only difference appears in the event of a call to stop!, which now also check the time and resources of the main_pb.","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"OK = start!(sub_stop)\n@test OK == false #no reason to stop just yet.","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"Assume time is exhausted for the main_stop","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"main_stop.meta.start_time = 0.0 #force a timing failure in the main problem\nstop!(sub_stop)\n\n@test status(sub_stop, list = true) == [:ResourcesOfMainProblemExhausted]\n@test sub_stop.meta.tired == false\n@test sub_stop.meta.main_pb == true","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"The same applies if there is now a third subproblem","category":"page"},{"location":"howtostop-2/","page":"How to Stop 2","title":"How to Stop 2","text":"reinit!(main_stop)\nreinit!(sub_stop)\nsubsub_stop = GenericStopping(subsubpb, x0, main_stp = sub_stop, tol_check = (atol, rtol, opt0) -> atol)\nmain_stop.meta.start_time = 0.0 #force a timing failure in the main problem\nstop!(subsub_stop)\n\n@test status(subsub_stop, list = true) == [:ResourcesOfMainProblemExhausted]\n@test subsub_stop.meta.tired   == false\n@test subsub_stop.meta.main_pb == true\n@test status(sub_stop, list = true) == [:ResourcesOfMainProblemExhausted]\n@test sub_stop.meta.tired   == false\n@test sub_stop.meta.main_pb == true\n@test status(main_stop, list = true) == [:Tired]\n@test main_stop.meta.tired   == true\n@test main_stop.meta.main_pb == false","category":"page"},{"location":"idcard-state/#State","page":"State's ID","title":"State","text":"","category":"section"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"As discussed before each Stopping contains a current_state <: AbstractState attribute containing the current information/state of the problem. When running the iterative loop, the State is updated and the Stopping make a decision based on this information.","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"The current_state contains all the information relative to a problem. We implemented three instances as an illustration:","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"GenericState ;\nNLPAtX representing the state of an NLPModel;\nOneDAtX for 1D optimization problems.","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"GenericState is an illustration of the behavior of such object that minimally contains:","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"x the current iterate;\nd the current direction;\nres the current residual;\ncurrent_time the current time;\ncurrent_score the current optimality score.","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"By convention, x and current_score are mandatory information, and the other attribute are initialized with keywords arguments:","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"GenericState(zeros(n), 0.0, d = zeros(n), current_time = NaN)","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"the alternative would be","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"GenericState(zeros(n), d = zeros(n), current_time = NaN)","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"Beyond the use inside Stopping, returning the State also provides the user the opportunity to use some of the information computed by the algorithm.","category":"page"},{"location":"idcard-state/#FAQ:-Are-there-Type-constraints-when-initializing-a-State?","page":"State's ID","title":"FAQ: Are there Type constraints when initializing a State?","text":"","category":"section"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"Yes, an AbstractState{S,T} is actually a paramtric type where S is the type of the current_score and T is the type of x.","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"x0, score0 = rand(n), Array{Float64,1}(undef, n)\nGenericState(x0, score0) #is an AbstractState{Array{Float64,1}, Array{Float64,1}}","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"By default, the current_score is a real number, hence","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"x0 = rand(n)\nGenericState(x0) #is an AbstractState{Float64, Array{Float64,1}}","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"These types can be obtained with the functions xtype and scoretype:","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"scoretype(stp.current_state)\nxtype(stp.current_state)","category":"page"},{"location":"idcard-state/#FAQ:-Can-I-design-a-tailored-State-for-my-problem?","page":"State's ID","title":"FAQ: Can I design a tailored State for my problem?","text":"","category":"section"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"NLPAtX is an illustration of a more evolved instance associated to NLPModels for nonlinear optimization models. It contains:","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"mutable struct \tNLPAtX{S, T <: AbstractVector, MT <: AbstractMatrix}  <: AbstractState{S, T}\n#Unconstrained State\n    x            :: T     # current point\n    fx           :: eltype(T) # objective function\n    gx           :: T  # gradient size: x\n    Hx           :: MT  # hessian size: |x| x |x|\n#Bounds State\n    mu           :: T # Lagrange multipliers with bounds size of |x|\n#Constrained State\n    cx           :: T # vector of constraints lc <= c(x) <= uc\n    Jx           :: MT  # jacobian matrix, size: |lambda| x |x|\n    lambda       :: T    # Lagrange multipliers\n\n    d            :: T #search direction\n    res          :: T #residual\n #Resources State\n    current_time   :: Float64\n    current_score  :: S\n    evals          :: Counters\n\n function NLPAtX(x             :: T,\n                 lambda        :: T,\n                 current_score :: S;\n                 fx            :: eltype(T) = _init_field(eltype(T)),\n                 gx            :: T = _init_field(T),\n                 Hx            :: AbstractMatrix = _init_field(Matrix{eltype(T)}),\n                 mu            :: T = _init_field(T),\n                 cx            :: T = _init_field(T),\n                 Jx            :: AbstractMatrix = _init_field(Matrix{eltype(T)}),\n                 d             :: T = _init_field(T),\n                 res           :: T = _init_field(T),\n                 current_time  :: Float64 = NaN,\n                 evals         :: Counters = Counters()\n                 ) where {S, T <: AbstractVector}\n\n  _size_check(x, lambda, fx, gx, Hx, mu, cx, Jx)\n\n  return new{S, T, Matrix{eltype(T)}}(x, fx, gx, Hx, mu, cx, Jx, lambda, d, \n                                      res, current_time, current_score, evals)\n end\nend","category":"page"},{"location":"idcard-state/","page":"State's ID","title":"State's ID","text":"_init_field(T) initializes a value for a given type guaranteing type stability and minimal storage.","category":"page"},{"location":"run-optimsolver/#Run-optimization-algorithms","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"","category":"section"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"The Stopping structure eases the implementation of algorithms and the stopping criterion.","category":"page"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"The following examples illustrate solver for optimization:","category":"page"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"a backtracking 1D optimization solver\na globalized Newton for unconstrained optimization solver\na bound constraint active-set algorithm\na quadratic penalty algorithm for non-linear optimization","category":"page"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"using LinearAlgebra, NLPModels, Stopping, Test\n\ninclude(\"../test-stopping/rosenbrock.jl\")","category":"page"},{"location":"run-optimsolver/#Part-1/4","page":"Run optimization algorithms","title":"Part 1/4","text":"","category":"section"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"printstyled(\"How to solve 1D optim problem: \\n\", color = :red)\ninclude(\"backls.jl\")","category":"page"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"printstyled(\"1D Optimization: backtracking tutorial.\\n\", color = :green)\n\nx0 = 1.5*ones(6)\nnlp = ADNLPModel(rosenbrock,  x0)\ng0 = grad(nlp,x0)\nh = onedoptim(x -> obj(nlp, x0 - x * g0), x -> - dot(g0,grad(nlp,x0 - x * g0)))","category":"page"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"SCENARIO: We create 3 stopping: Define the LSAtT with mandatory entries g₀ and h₀.","category":"page"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"lsatx  = LSAtT(1.0, h₀ = obj(nlp, x0), g₀ = -dot(grad(nlp, x0),grad(nlp, x0)))\nlsstp  = LS_Stopping(h, (x,y)-> armijo(x,y, τ₀ = 0.01), lsatx)\nlsatx2 = LSAtT(1.0, h₀ = obj(nlp, x0), g₀ = -dot(grad(nlp, x0),grad(nlp, x0)))\nlsstp2 = LS_Stopping(h, (x,y)-> wolfe(x,y, τ₁ = 0.99), lsatx2)\nlsatx3 = LSAtT(1.0, h₀ = obj(nlp, x0), g₀ = -dot(grad(nlp, x0),grad(nlp, x0)))\nlsstp3 = LS_Stopping(h, (x,y)-> armijo_wolfe(x,y, τ₀ = 0.01, τ₁ = 0.99), lsatx3)\n\nparameters = ParamLS(back_update = 0.5)\n\nprintstyled(\"backtracking line search with Armijo:\\n\", color = :green)\nbacktracking_ls(lsstp, parameters)\n@show status(lsstp)\n@show lsstp.meta.nb_of_stop\n@show lsstp.current_state.x\n\nprintstyled(\"backtracking line search with Wolfe:\\n\", color = :green)\nbacktracking_ls(lsstp2, parameters)\n@show status(lsstp2)\n@show lsstp2.meta.nb_of_stop\n@show lsstp2.current_state.x\n\nprintstyled(\"backtracking line search with Armijo-Wolfe:\\n\", color = :green)\nbacktracking_ls(lsstp3, parameters)\n@show status(lsstp3)\n@show lsstp3.meta.nb_of_stop\n@show lsstp3.current_state.x","category":"page"},{"location":"run-optimsolver/#Part-2/4","page":"Run optimization algorithms","title":"Part 2/4","text":"","category":"section"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"printstyled(\"How to solve unconstrained optim problem: \\n\", color = :red)\ninclude(\"uncons.jl\")\n\nprintstyled(\"Unconstrained Optimization: globalized Newton.\\n\", color = :green)\n\nx0 = 1.5*ones(6)\nnlp = ADNLPModel(rosenbrock,  x0)\n\n# We use the default builder using the KKT optimality function (which does not\n# automatically fill in the State)\nstop_nlp = NLPStopping(nlp)\nparameters = PrmUn()\n\nprintstyled(\"Newton method with Armijo linesearch.\\n\", color = :green)\nglobal_newton(stop_nlp, parameters)\n@show status(stop_nlp)\n#We can check afterwards, the score\n@show Stopping.KKT(stop_nlp.pb, stop_nlp.current_state)\n@show stop_nlp.meta.nb_of_stop\n\nprintstyled(\"Newton method with Armijo-Wolfe linesearch.\\n\", color = :green)\nreinit!(stop_nlp, rstate = true, x = x0)\nreset!(stop_nlp.pb) #reinitialize the counters of the NLP\nparameters.ls_func = (x,y)-> armijo_wolfe(x,y, τ₀ = parameters.armijo_prm,\n                                               τ₁ = parameters.wolfe_prm)\n\nglobal_newton(stop_nlp, parameters)\n@show status(stop_nlp)\n#We can check afterwards, the score\n@show Stopping.KKT(stop_nlp.pb, stop_nlp.current_state)\n@show stop_nlp.meta.nb_of_stop","category":"page"},{"location":"run-optimsolver/#Part-3/4","page":"Run optimization algorithms","title":"Part 3/4","text":"","category":"section"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"printstyled(\"How to solve bound constrained optim problem: \\n\", color = :red)\ninclude(\"activeset.jl\")\n\nprintstyled(\"Constrained optimization: active-set algorithm tutorial.\\n\", color = :green)\nx0 = 1.5*ones(6);x0[6]=1.0\nnlp_bnd = ADNLPModel(rosenbrock,  x0,\n                 lvar = fill(-10.0,size(x0)), uvar = fill(1.5,size(x0)))\n\nnlp_bnd_at_x = NLPAtX(x0)\nstop_nlp_c = NLPStopping(nlp_bnd, max_iter = 10)\n\nactiveset(stop_nlp_c)\n@show status(stop_nlp_c)","category":"page"},{"location":"run-optimsolver/#Part-4/4","page":"Run optimization algorithms","title":"Part 4/4","text":"","category":"section"},{"location":"run-optimsolver/","page":"Run optimization algorithms","title":"Run optimization algorithms","text":"printstyled(\"How to solve nonlinear optim problem: \\n\", color = :red)\ninclude(\"penalty.jl\")\n\nprintstyled(\"Constrained optimization: quadratic penalty tutorial.\\n\", color = :green)\nx0 = 1.5*ones(6)\nc(x) = [sum(x)]\nnlp2 = ADNLPModel(rosenbrock,  x0,\n                 lvar = fill(-10.0,size(x0)), uvar = fill(10.0,size(x0)),\n                 y0 = [0.0], c = c, lcon = [-Inf], ucon = [5.])\n\nnlp_at_x_c = NLPAtX(x0, zeros(nlp2.meta.ncon))\nstop_nlp_c = NLPStopping(nlp2, (x,y) -> KKT(x,y), nlp_at_x_c, atol = 1e-3,\n                                max_cntrs = init_max_counters(obj = 400000, cons = 800000, sum = 1000000))\n\npenalty(stop_nlp_c)\n@show status(stop_nlp_c)\n\n#We can check afterwards, the score\n@show KKT(stop_nlp_c.pb, stop_nlp_c.current_state)","category":"page"},{"location":"howtostate-nlp/#How-to-State-for-NLPs","page":"How to State for NLPs","title":"How to State for NLPs","text":"","category":"section"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"The data used through the algorithmic process in the Stopping framework are stored in a State. We illustrate here the NLPAtX which is a specialization of the State for non-linear programming.","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"using Test, NLPModels, Stopping","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"Formulate the problem with NLPModels:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"include(\"../test-stopping/rosenbrock.jl\")\nx0   = ones(6)\ny0   = ones(1)\nc(x) = [x[1] - x[2]]\nlcon = [0.0]\nucon = [0.0]","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"We can create a NLPAtX for constrained optimization. Here we provide y0 = [1.0]. Note that the default value is [0.0].","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"nlp = ADNLPModel(x -> rosenbrock(x), x0, y0 = y0,\n                 c = c, lcon = lcon, ucon = ucon,\n                 lvar = zeros(6), uvar = Inf * ones(6))","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"We can create a NLPAtX for bounds-constrained optimization:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"nlp2 = ADNLPModel(x -> rosenbrock(x), x0,\n                 lvar = zeros(6), uvar = Inf * ones(6))","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"We can create a NLPAtX for unconstrained optimization:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"nlp3 = ADNLPModel(x -> rosenbrock(x), x0)","category":"page"},{"location":"howtostate-nlp/#I.-Initialize-a-NLPAtX:","page":"How to State for NLPs","title":"I. Initialize a NLPAtX:","text":"","category":"section"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"There are two main constructor for the States. The unconstrained:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"state_unc = NLPAtX(x0)","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"The constrained:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"state_con = NLPAtX(x0, y0)","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"By default, all the values in the State are set to nothing except x and lambda In the unconstrained case lambda is a vector of length 0.","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"@test !(state_unc.lambda == nothing)","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"From the default initialization, all the other entries are void:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"@test state_unc.mu == nothing && state_con.mu == nothing\n@test state_unc.fx == nothing && state_con.fx == nothing","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"An exception is the counters which is initialized as a default Counters:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"@test (sum_counters(state_unc.evals) + sum_counters(state_con.evals)) == 0","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"Note that the constructor proceeds to a size checking on gx, Hx, mu, cx, Jx. It returns an error if this test fails.","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"try\n  NLPAtX(x0, Jx = ones(1,1))\n  @test false\ncatch\n  #printstyled(\"NLPAtX(x0, Jx = ones(1,1)) is invalid as length(lambda)=0\\n\")\n  @test true\nend","category":"page"},{"location":"howtostate-nlp/#II.-Update-the-entries","page":"How to State for NLPs","title":"II. Update the entries","text":"","category":"section"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"At the creation of a NLPAtX, keyword arguments populate the state:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"state_bnd = NLPAtX(x0, mu = zeros(6))\n@test state_bnd.mu == zeros(6) #initialize multipliers with bounds constraints","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"The NLPAtX has two functions: update! and reinit! The update! has the same behavior as in the GenericState:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"update!(state_bnd, fx = 1.0, blah = 1) #update! ignores unnecessary keywords\n@test state_bnd.mu == zeros(6) && state_bnd.fx == 1.0 && state_bnd.x == x0","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"reinit! by default reuse x and lambda and reset all the entries at their default values (void or empty Counters):","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"reinit!(state_bnd, mu = ones(6))\n@test state_bnd.mu == ones(6) && state_bnd.fx == nothing\n@test state_bnd.x == x0 && state_bnd.lambda == zeros(0)","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"Trying to inherit reinit!(AbstractState, Vector) would not work here as lambda is a mandatory entry.","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"try\n reinit!(state_bnd, 2 * ones(6))\n @test false\ncatch\n @test true\nend","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"However, we can specify both entries","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"reinit!(state_bnd, 2 * ones(6), zeros(0))\n@test state_bnd.x == 2*ones(6) && state_bnd.lambda == zeros(0)\n@test state_bnd.mu == nothing && sum_counters(state_bnd.evals) == 0","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"Giving a new Counters update as well:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"test = Counters(); setfield!(test, :neval_obj, 102)\nreinit!(state_bnd, evals = test)\n@test getfield(state_bnd.evals, :neval_obj) == 102\n@test sum_counters(state_bnd.evals) - 102 == 0","category":"page"},{"location":"howtostate-nlp/#III.-Domain-Error","page":"How to State for NLPs","title":"III. Domain Error","text":"","category":"section"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"Similar to the GenericState we can use domain_check to verify there are no NaN","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"@test Stopping._domain_check(state_bnd) == false\nupdate!(state_bnd, fx = NaN)\n@test Stopping._domain_check(state_bnd) == true","category":"page"},{"location":"howtostate-nlp/#IV.-Use-the-NLPAtX","page":"How to State for NLPs","title":"IV. Use the NLPAtX","text":"","category":"section"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"For algorithmic use, it might be conveninent to fill in all the entries of then State. In this case, we can use the Stopping:","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"stop = NLPStopping(nlp, (x,y) -> unconstrained_check(x,y), state_unc)","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"Note that the fillin! can receive known informations via keywords. If we don't want to store the hessian matrix, we turn the keyword matrixinfo as false.","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"fill_in!(stop, x0, matrix_info = false)","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"@test stop.current_state.Hx == nothing","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"We can now use the updated step in the algorithmic procedure","category":"page"},{"location":"howtostate-nlp/","page":"How to State for NLPs","title":"How to State for NLPs","text":"@test start!(stop) #return true","category":"page"},{"location":"benchmark/#Benchmark","page":"Benchmark optimization algorithms","title":"Benchmark","text":"","category":"section"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"https://juliasmoothoptimizers.github.io/SolverBenchmark.jl/latest/tutorial/ In this tutorial we illustrate the main uses of SolverBenchmark.","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"The Julia file corresponding to this tutorial can be found here.","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"using LinearAlgebra, NLPModels, Stopping\n\ninclude(\"backls.jl\")\ninclude(\"uncons.jl\")","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"using DataFrames, Printf, SolverBenchmark","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"CUTEst is a collection of test problems","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"using CUTEst","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"problems_unconstrained = CUTEst.select(contype=\"unc\")\nn = length(problems_unconstrained) #240","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"printstyled(\"Benchmark solvers: \\n\", color = :green)\n\n#Names of 3 solvers:\nnames = [:armijo, :wolfe, :armijo_wolfe]\np1 = PrmUn(); p2 = PrmUn(ls_func = wolfe); p3 = PrmUn(ls_func = armijo_wolfe)\nparamDict = Dict(:armijo => p1, :wolfe => p2, :armijo_wolfe => p3)\n#Initialization of the DataFrame for n problems.\nstats = Dict(name => DataFrame(:id => 1:n,\n         :name => [@sprintf(\"prob%s\", problems_unconstrained[i]) for i = 1:n],\n         :nvar => zeros(Int64, n),\n         :status => [:Unknown for i = 1:n],\n         :f => NaN*ones(n),\n         :t => NaN*ones(n),\n         :iter => zeros(Int64, n),\n         :eval_f => zeros(Int64, n),\n         :eval_g => zeros(Int64, n),\n         :eval_H => zeros(Int64, n),\n         :score => NaN*ones(n)) for name in names)","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"for i=1:n\n  nlp_cutest = CUTEst.CUTEstModel(problems_unconstrained[i])\n  @show i, problems_unconstrained[i], nlp_cutest.meta.nvar\n  #update the stopping with the new problem\n  stop_nlp = NLPStopping(nlp_cutest,\n                         unconstrained_check,\n                         NLPAtX(nlp_cutest.meta.x0),\n                         max_iter = 20)\n\n  for name in names\n\n    #solve the problem\n    global_newton(stop_nlp, paramDict[name])\n\n    #update the stats from the Stopping\n    stats[name].nvar[i] = nlp_cutest.meta.nvar\n    stats[name].status[i] = status(stop_nlp)\n    stats[name].f[i] = stop_nlp.current_state.fx == nothing ? NaN : stop_nlp.current_state.fx\n    stats[name].t[i] = stop_nlp.current_state.current_time == nothing ? NaN : stop_nlp.current_state.current_time - stop_nlp.meta.start_time\n    stats[name].iter[i] = stop_nlp.meta.nb_of_stop\n    stats[name].score[i] = unconstrained_check(nlp_cutest, stop_nlp.current_state)\n    stats[name].eval_f[i] = getfield(stop_nlp.current_state.evals, :neval_obj)\n    stats[name].eval_g[i] = getfield(stop_nlp.current_state.evals, :neval_grad)\n    stats[name].eval_H[i] = getfield(stop_nlp.current_state.evals, :neval_hess)\n\n    #reinitialize the Stopping and the nlp\n    reinit!(stop_nlp, rstate = true, x = nlp_cutest.meta.x0)\n    reset!(stop_nlp.pb)\n  end\n\n  #finalize nlp\n  finalize(nlp_cutest)\nend #end of main loop","category":"page"},{"location":"benchmark/","page":"Benchmark optimization algorithms","title":"Benchmark optimization algorithms","text":"for name in names\n@show stats[name]\nend","category":"page"},{"location":"#Stopping.jl","page":"Home","title":"Stopping.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package provides general tools for the uniformization of stopping criteria for iterative solvers. When calling an iterative solver, four outcomes may happen:","category":"page"},{"location":"","page":"Home","title":"Home","text":"An approximate solution is obtained;\nThe problem is declared unsolvable (unboundedness, infeasibility, etc);\nThe maximum available resources are not sufficient to compute the solution;\nAn algorithm's dependent failure happens.","category":"page"},{"location":"","page":"Home","title":"Home","text":"There are many advantages in using Stopping:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Make your code more readable by outsourcing some tests to Stopping;\nLet the user a hand on the stopping criteria;\nEncourage reusability of codes.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Stopping.jl offers several advanced facilities, but a basic usage is already beneficial for your code.","category":"page"},{"location":"#How-to-install","page":"Home","title":"How to install","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Install and test the Stopping package with the Julia package manager:","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add Stopping\npkg> test Stopping","category":"page"},{"location":"","page":"Home","title":"Home","text":"You can access the most up-to-date version of the Stopping package using:","category":"page"},{"location":"","page":"Home","title":"Home","text":"pkg> add https://github.com/vepiteski/Stopping.jl\npkg> test Stopping","category":"page"},{"location":"","page":"Home","title":"Home","text":"Stopping.jl most evolved facilities are based on JuliaSmoothOptimizers' tools.","category":"page"},{"location":"#Stopping.jl-in-action","page":"Home","title":"Stopping.jl in action","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Stopping.jl is already used in other Julia packages:","category":"page"},{"location":"","page":"Home","title":"Home","text":"StoppingInterface.jl: an interface between Stopping.jl and the outside world;\nMPCCSolver.jl: solver for mathematical programs with complementarity constraints;\nFletcherPenaltyNLPSolver: solver for nonlinear optimization models with Fletcher's penalty method;\n...","category":"page"},{"location":"overfitting/#Handle-unrelated-stopping-criteria","page":"Overfitting","title":"Handle unrelated stopping criteria","text":"","category":"section"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"In this tutorial, we present the use of Stopping to specify an \"unrelated\" stopping criterion. A typical example is the so-called case of \"overfitting\",  where the optimization process is actually designed to approximate another problem.","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"using ADNLPModels, LinearAlgebra, NLPModels, Plots, Printf, Random, Stopping","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"In this tutorial, we will use the classical steepest descent method with an Armijo line-search.","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"import Stopping.armijo\nfunction armijo(xk, dk, fk, slope, f)\n  t = 1.0\n  fk_new = f(xk + dk)\n  while f(xk + t * dk) > fk + 1.0e-4 * t * slope\n    t /= 1.5\n    fk_new = f(xk + t * dk)\n  end\n  return t, fk_new\nend\n\nfunction steepest_descent(stp :: NLPStopping)\n\n  xk = stp.current_state.x\n  fk, gk = objgrad(stp.pb, xk)\n\n  OK = update_and_start!(stp, fx = fk, gx = gk)\n\n  @printf \"%2s %9s %7s %7s %7s\\n\" \"k\" \"fk\" \"||∇f(x)||\" \"t\" \"λ\"\n  @printf \"%2d %7.1e %7.1e\\n\" stp.meta.nb_of_stop fk norm(stp.current_state.current_score)\n  while !OK\n    dk = - gk\n    slope = dot(dk, gk)\n    t, fk = armijo(xk, dk, fk, slope, x->obj(stp.pb, x))\n    xk += t * dk\n    fk, gk = objgrad(stp.pb, xk)\n    \n    OK = update_and_stop!(stp, x = xk, fx = fk, gx = gk)\n\n    @printf \"%2d %9.2e %7.1e %7.1e %7.1e\\n\" stp.meta.nb_of_stop fk norm(stp.current_state.current_score) t slope\n  end\n  return stp\nend","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"We also generate randomly some data.","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"Random.seed!(1234)\nm, n = 50, 10\nA  = rand(m, n)\nb  = A * ones(n)\nD  = vcat(A, A) + vcat(zeros(m,n), rand(m,n))\nDb = vcat(b, b)\nrperm = shuffle(1:2m)\nDr = D[rperm,:]\nDbr = Db[rperm,:]","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"We initialize two different problems evaluating respectively a training set, and a test set.","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"f(x, A, b, λ) = norm(A * x - b)^2 + λ * norm(x)^2\ntrain_pb = ADNLPModel(x -> f(x, Dr[1:m,:], Dbr[1:m], 1e-2), zeros(n))\ntest_pb = ADNLPModel(x -> f(x, Dr[m+1:2m,:], Dbr[m+1:2m], 0.0), zeros(n))","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"In this tutorial, the motivation is to use the solver on the test_pb, and track the efficiency of the computed solution on the train_pb. We specialize the stopping structure to store the objective function of both problems in the stopping_user_struct, and evaluate them in the stp.meta.user_check_func!.","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"train_check(stp, b) = begin \n  stp.stopping_user_struct[:test_obj][stp.meta.nb_of_stop+1] = obj(stp.stopping_user_struct[:test], stp.current_state.x)\n  stp.stopping_user_struct[:train_obj][stp.meta.nb_of_stop+1] = obj(stp.pb, stp.current_state.x)\nend\ntrain_obj = NaN * ones(101)\ntest_obj  = NaN * ones(101)\ntrain_stp = NLPStopping(train_pb, user_struct = Dict(:test => test_pb, :train_obj => train_obj, :test_obj => test_obj), user_check_func! = train_check, max_iter = 100)","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"We now run the steepest descent algorithm with the train_stp stopping.","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"steepest_descent(train_stp)","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"On the following plot in logarithmic scale, we can see that after a number of iterations, the progress made by the solver are no longer improving the other problem.","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"#hcat(log.(train_stp.stopping_user_struct[:train_obj]), log.(train_stp.stopping_user_struct[:test_obj]))\nplot(log.(train_stp.stopping_user_struct[:train_obj]), label=[\"train obj\"])\nplot!(log.(train_stp.stopping_user_struct[:test_obj]), label=[\"test obj\"], title=\"overfitting\")","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"(Image: )","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"To overcome this issue, one possibility is to stop the solver when the second is no longer being minimized. The only modification is to set the entry meta.stopbyuser to true.","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"train_check_opt(stp, b) = begin \n  k = stp.meta.nb_of_stop\n  stp.stopping_user_struct[:test_obj][k+1] = obj(stp.stopping_user_struct[:test], stp.current_state.x)\n  stp.stopping_user_struct[:train_obj][k+1] = obj(stp.pb, stp.current_state.x)\n  diff = k!=0 && stp.stopping_user_struct[:test_obj][k+1] - stp.stopping_user_struct[:train_obj][k+1] > 10\n  inc  = k!=0 && stp.stopping_user_struct[:test_obj][k+1] > stp.stopping_user_struct[:test_obj][k]\n  if diff && inc\n    stp.meta.stopbyuser = true\n  end\nend\ntrain_stp.meta.user_check_func! = train_check_opt\nreset!(train_stp.pb)\nreinit!(train_stp, rstate=true, x = zeros(10))\nsteepest_descent(train_stp)","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"nb_iter = train_stp.meta.nb_of_stop\nhcat(log.(train_stp.stopping_user_struct[:train_obj][1:nb_iter+1]), log.(train_stp.stopping_user_struct[:test_obj][1:nb_iter+1]))\nplot(log.(train_stp.stopping_user_struct[:train_obj][1:nb_iter+1]), label=[\"train obj\"])\nplot!(log.(train_stp.stopping_user_struct[:test_obj][1:nb_iter+1]), label=[\"test obj\"], title=\"overfitting\")","category":"page"},{"location":"overfitting/","page":"Overfitting","title":"Overfitting","text":"(Image: )","category":"page"},{"location":"howstopcheckoptimality/#How-Stopping-checks-for-optimality","page":"Optimality in Stopping","title":"How Stopping checks for optimality","text":"","category":"section"},{"location":"howstopcheckoptimality/","page":"Optimality in Stopping","title":"Optimality in Stopping","text":"The solver can let Stopping handles the optimality checks. We see here how it works and how to tune it in.","category":"page"},{"location":"howstopcheckoptimality/","page":"Optimality in Stopping","title":"Optimality in Stopping","text":"First, the function stop! computes a score using optimality_check function given in the meta. The keywords argument given in stop! are passed to this function.","category":"page"},{"location":"howstopcheckoptimality/","page":"Optimality in Stopping","title":"Optimality in Stopping","text":"#Compute the score if !src.optimality_check\nscore = stp.meta.optimality_check(stp.pb, stp.current_state; kwargs...))","category":"page"},{"location":"howstopcheckoptimality/","page":"Optimality in Stopping","title":"Optimality in Stopping","text":"The score is then stored in stp.current_state.current_score. If the score doesn't contain any NaN, Stopping proceeds and test whether it is within tolerances given as functions in meta.tol_check and meta.tol_check_neg.","category":"page"},{"location":"howstopcheckoptimality/","page":"Optimality in Stopping","title":"Optimality in Stopping","text":"#Compute the tolerances\ncheck_pos, check_neg = tol_check(stp.meta)\n#Test the score vs the tolerances\noptimal = _inequality_check(optimality, check_pos, check_neg)","category":"page"},{"location":"howstopcheckoptimality/","page":"Optimality in Stopping","title":"Optimality in Stopping","text":"So, overall Stopping does:","category":"page"},{"location":"howstopcheckoptimality/","page":"Optimality in Stopping","title":"Optimality in Stopping","text":"check_pos = stp.meta.tol_check(stp.meta.atol, stp.meta.rtol, stp.meta.optimality0)\ncheck_neg = stp.meta.tol_check_neg(stp.meta.atol, stp.meta.rtol, stp.meta.optimality0)\nscore     = stp.meta.optimality_check(stp.pb, stp.current_state)\ncheck_pos ≤ score ≤ check_neg","category":"page"},{"location":"howstopcheckoptimality/#FAQ:-Does-it-work-for-vector-scores-as-well?","page":"Optimality in Stopping","title":"FAQ: Does it work for vector scores as well?","text":"","category":"section"},{"location":"howstopcheckoptimality/","page":"Optimality in Stopping","title":"Optimality in Stopping","text":"The type of the score and tolerances are respectively initialized in the State and the Meta at the initialization of the Stopping. Hence one can use vectorized scores as long as they can be compared with the tolerances. For instance:","category":"page"},{"location":"howstopcheckoptimality/","page":"Optimality in Stopping","title":"Optimality in Stopping","text":"The score is a vector and tolerances are vectors of the same length or numbers.\nThe score is a tuple and tolerances are tuple or a number.","category":"page"},{"location":"howstopcheckoptimality/#FAQ:-How-do-I-implement-AND-and-OR-conditions?","page":"Optimality in Stopping","title":"FAQ: How do I implement AND and OR conditions?","text":"","category":"section"},{"location":"howstopcheckoptimality/","page":"Optimality in Stopping","title":"Optimality in Stopping","text":"The concatenation of two scores (AND condition) that need to be tested to zero can be represented as a vector. The disjunction of two score (OR condition) are represented as tuple.","category":"page"},{"location":"howstopcheckoptimality/#FAQ:-Do-Stopping-really-computes-the-tolerances-each-time?","page":"Optimality in Stopping","title":"FAQ: Do Stopping really computes the tolerances each time?","text":"","category":"section"},{"location":"howstopcheckoptimality/","page":"Optimality in Stopping","title":"Optimality in Stopping","text":"It does unless meta.recomp_tol is set as true. This entry can be set as true from the beginning as the tol_check functions are evaluated once at the initialization of the meta.","category":"page"}]
}
